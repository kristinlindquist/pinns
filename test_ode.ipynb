{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser('ODE Test')\n",
    "# See https://github.com/rtqichen/torchdiffeq/tree/master for all methods, especially fixed step\n",
    "parser.add_argument('--method', type=str, choices=['adaptive_heun', 'bosh3', 'dopri5', 'dopri8', 'fehlberg2'], default='dopri5')\n",
    "parser.add_argument('--data_size', type=int, default=1000)\n",
    "parser.add_argument('--batch_time', type=int, default=10)\n",
    "parser.add_argument('--batch_size', type=int, default=26)\n",
    "parser.add_argument('--iterations', type=int, default=1000)\n",
    "parser.add_argument('--test_freq', type=int, default=20)\n",
    "parser.add_argument('--adjoint', action='store_true', default=False)\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "if args.adjoint:\n",
    "    from torchdiffeq import odeint_adjoint as odeint\n",
    "else:\n",
    "    from torchdiffeq import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(true_y: torch.Tensor, pred_y: torch.Tensor, learned_op):\n",
    "    t_np = t.cpu().numpy()\n",
    "    true_y_np = true_y.cpu().numpy()\n",
    "    pred_y_np = pred_y.cpu().numpy()\n",
    "\n",
    "    # Clear previous contents\n",
    "    ax_traj.cla()\n",
    "    ax_phase.cla()\n",
    "    ax_vecfield.cla()\n",
    "\n",
    "    # Trajectories\n",
    "    ax_traj.set_title('Trajectory')\n",
    "    ax_traj.set_xlabel('Time')\n",
    "    ax_traj.set_ylabel('Position')\n",
    "    ax_traj.plot(t_np, true_y_np[:, 0, 0], 'g-', label='True X')\n",
    "    ax_traj.plot(t_np, true_y_np[:, 0, 1], 'g-', label='True Y')\n",
    "    ax_traj.plot(t_np, pred_y_np[:, 0, 0], 'b--', label='Pred X')\n",
    "    ax_traj.plot(t_np, pred_y_np[:, 0, 1], 'b--', label='Pred Y')\n",
    "    ax_traj.set_xlim(t_np.min(), t_np.max())\n",
    "    ax_traj.set_ylim(-2, 2)\n",
    "    ax_traj.legend()\n",
    "\n",
    "    # Phase Spaces\n",
    "    ax_phase.set_title('Phase Space')\n",
    "    ax_phase.set_xlabel('Position')\n",
    "    ax_phase.set_ylabel('Momentum')\n",
    "    ax_phase.plot(true_y_np[:, 0, 0], true_y_np[:, 0, 1], 'g-')\n",
    "    ax_phase.plot(pred_y_np[:, 0, 0], pred_y_np[:, 0, 1], 'b--')\n",
    "    ax_phase.set_xlim(-2, 2)\n",
    "    ax_phase.set_ylim(-2, 2)\n",
    "\n",
    "    # Vector Field\n",
    "    ax_vecfield.set_title('Vector Field')\n",
    "    ax_vecfield.set_xlabel('X')\n",
    "    ax_vecfield.set_ylabel('Y')\n",
    "    y, x = np.mgrid[-2:2:21j, -2:2:21j]\n",
    "    dydt = learned_op(0, torch.Tensor(np.stack([x, y], -1).reshape(21 * 21, 2)).to(device)).cpu().detach().numpy()\n",
    "    mag = np.sqrt(dydt[:, 0]**2 + dydt[:, 1]**2).reshape(-1, 1)\n",
    "    dydt = (dydt / mag)\n",
    "    dydt = dydt.reshape(21, 21, 2)\n",
    "\n",
    "    ax_vecfield.streamplot(x, y, dydt[:, :, 0], dydt[:, :, 1], color=\"black\")\n",
    "    ax_vecfield.set_xlim(-2, 2)\n",
    "    ax_vecfield.set_ylim(-2, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Hyper-network allowing f(z(t), t) to change with time.\n",
    "\n",
    "    Adapted from the NumPy implementation at:\n",
    "    https://gist.github.com/rtqichen/91924063aa4cc95e7ef30b3a5491cc52\n",
    "    \"\"\"\n",
    "    def __init__(self, in_out_dim: int, hidden_dim: int, width: int):\n",
    "        super().__init__()\n",
    "\n",
    "        blocksize = in_out_dim * width\n",
    "\n",
    "        self.fc1 = nn.Linear(1, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 3 * blocksize + width)\n",
    "\n",
    "        self.in_out_dim = in_out_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.width = width\n",
    "        self.blocksize = blocksize\n",
    "\n",
    "    def forward(self, t):\n",
    "        # predict params\n",
    "        params = t.reshape(1, 1)\n",
    "        params = torch.tanh(self.fc1(params))\n",
    "        params = torch.tanh(self.fc2(params))\n",
    "        params = self.fc3(params)\n",
    "\n",
    "        params = params.reshape(-1)\n",
    "        W = params[:self.blocksize].reshape(self.width, self.in_out_dim, 1)\n",
    "        U = params[self.blocksize:2*self.blocksize].reshape(self.width, 1, self.in_out_dim)\n",
    "        G = params[2*self.blocksize:3*self.blocksize].reshape(self.width, 1, self.in_out_dim)\n",
    "        B = params[3*self.blocksize:3*self.blocksize+self.width].reshape(self.width, 1, 1)\n",
    "        return [W, U, G, B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self, in_out_dim: int = 2, hidden_dim: int = 35, width: int = 50):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.width = width\n",
    "        self.hyper_net = HyperNetwork(in_out_dim, hidden_dim, width)\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        W, U, G, B = self.hyper_net(t)\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            y.requires_grad_(True)\n",
    "            Y = torch.unsqueeze(y, 0) # 1 x batch_size x 1 x in_out_dim\n",
    "            U = U * torch.sigmoid(G)\n",
    "\n",
    "            h = torch.tanh(torch.matmul(Y, W.unsqueeze(-3))).mean(0) #  + B.unsqueeze(-3)\n",
    "            print(\"hhhhhhhh\", h.shape)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch() -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    s = torch.from_numpy(\n",
    "        np.random.choice(\n",
    "            np.arange(args.data_size - args.batch_time, dtype=np.int64),\n",
    "            args.batch_size,\n",
    "            replace=False\n",
    "        )\n",
    "    )\n",
    "    batch_y0 = true_y[s]  # (M, D)\n",
    "    batch_t = t[:args.batch_time]  # (T)\n",
    "    batch_y = torch.stack([true_y[s + i] for i in range(args.batch_time)], dim=0)  # (T, M, D)\n",
    "    return batch_y0.to(device), batch_t.to(device), batch_y.to(device)\n",
    "        \n",
    "device = torch.device('cpu')\n",
    "true_y0 = torch.tensor([[2., 0.]]).to(device)\n",
    "t = torch.linspace(0., args.batch_size, args.data_size).to(device)\n",
    "true_A = torch.tensor([[-0.1, 2.0], [-2.0, -0.1]]).to(device)\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def forward(self, t, y):\n",
    "        return torch.mm(y**3, true_A)\n",
    "\n",
    "with torch.no_grad():\n",
    "    true_y = odeint(Lambda(), true_y0, t, method=args.method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZES torch.Size([26, 1, 2]) torch.Size([10, 26, 1, 2]) torch.Size([10])\n",
      "hhhhhhhh torch.Size([26, 1, 1])\n",
      "hhhhhhhh torch.Size([26, 1, 1])\n",
      "hhhhhhhh torch.Size([26, 1, 1])\n",
      "hhhhhhhh torch.Size([26, 1, 1])\n",
      "hhhhhhhh torch.Size([26, 1, 1])\n",
      "hhhhhhhh torch.Size([26, 1, 1])\n",
      "hhhhhhhh torch.Size([26, 1, 1])\n",
      "hhhhhhhh torch.Size([26, 1, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[26, 1, 2]' is invalid for input of size 26",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     visualize(true_y, pred_y, learned_op)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 31\u001b[0m     viz_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_y0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     ani \u001b[38;5;241m=\u001b[39m FuncAnimation(\n\u001b[1;32m     34\u001b[0m         fig,\n\u001b[1;32m     35\u001b[0m         viz_update,\n\u001b[1;32m     36\u001b[0m         frames\u001b[38;5;241m=\u001b[39mviz_frames,\n\u001b[1;32m     37\u001b[0m         repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     39\u001b[0m     html_animation \u001b[38;5;241m=\u001b[39m HTML(ani\u001b[38;5;241m.\u001b[39mto_jshtml())\n",
      "Cell \u001b[0;32mIn[30], line 14\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(optimizer, true_y0, t)\u001b[0m\n\u001b[1;32m     12\u001b[0m batch_y0, batch_t, batch_y \u001b[38;5;241m=\u001b[39m get_batch()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSIZES\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_y0\u001b[38;5;241m.\u001b[39msize(), batch_y\u001b[38;5;241m.\u001b[39msize(), batch_t\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m---> 14\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearned_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_t\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mabs(pred_y \u001b[38;5;241m-\u001b[39m batch_y))\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchdiffeq/_impl/odeint.py:77\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     74\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchdiffeq/_impl/solvers.py:30\u001b[0m, in \u001b[0;36mAdaptiveStepsizeODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_integrate(t)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[0;32m---> 30\u001b[0m     solution[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_advance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchdiffeq/_impl/rk_common.py:194\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._advance\u001b[0;34m(self, next_t)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m next_t \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m n_steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_num_steps exceeded (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_steps)\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adaptive_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrk_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     n_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _interp_evaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39minterp_coeff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrk_state\u001b[38;5;241m.\u001b[39mt1, next_t)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchdiffeq/_impl/rk_common.py:276\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._adaptive_step\u001b[0;34m(self, rk_state)\u001b[0m\n\u001b[1;32m    274\u001b[0m t_next \u001b[38;5;241m=\u001b[39m t1\n\u001b[1;32m    275\u001b[0m y_next \u001b[38;5;241m=\u001b[39m y1\n\u001b[0;32m--> 276\u001b[0m interp_coeff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interp_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_next\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_step_t:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_step_index \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_t) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchdiffeq/_impl/rk_common.py:298\u001b[0m, in \u001b[0;36mRKAdaptiveStepsizeODESolver._interp_fit\u001b[0;34m(self, y0, y1, k, dt)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit an interpolating polynomial to the results of a Runge-Kutta step.\"\"\"\u001b[39;00m\n\u001b[1;32m    297\u001b[0m dt \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mtype_as(y0)\n\u001b[0;32m--> 298\u001b[0m y_mid \u001b[38;5;241m=\u001b[39m y0 \u001b[38;5;241m+\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43my0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m f0 \u001b[38;5;241m=\u001b[39m k[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    300\u001b[0m f1 \u001b[38;5;241m=\u001b[39m k[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[26, 1, 2]' is invalid for input of size 26"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+AAAAFlCAYAAABrxYI/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhUElEQVR4nO3df2zc5X0H8I/t4DOo2IRlcX7MNIOO0hZIaEI8QxGi8moJlC5/TPWgSrKIH6PNEI21lYRAXEobZwxQpBIakcLoH2VJiwBVTWTKvEYVxVPUJJboSEA00GRVbZJ12FlobWJ/90eEXTfnJOfEj+3j9ZLuD3/7PHfPB7vv6O0735VkWZYFAAAAMKZKx/sAAAAA8GGggAMAAEACCjgAAAAkoIADAABAAgo4AAAAJKCAAwAAQAIKOAAAACSggAMAAEACCjgAAAAkoIADAABAAgUX8J/+9KexaNGimDVrVpSUlMQLL7xwyj07duyIT3/605HL5eJjH/tYPP3006M4KsDEJh8B8pOPAMcVXMCPHj0ac+fOjY0bN57W+rfeeituuummuOGGG6KjoyO+8pWvxG233RYvvvhiwYcFmMjkI0B+8hHguJIsy7JRby4pieeffz4WL1484pp77rkntm3bFr/4xS8Gr/3t3/5tvPvuu9Ha2jrahwaY0OQjQH7yEfgwmzLWD9De3h719fXDrjU0NMRXvvKVEff09vZGb2/v4NcDAwPx29/+Nv7kT/4kSkpKxuqoQJHKsiyOHDkSs2bNitLSifPWF/IRGG/yEWBkY5GRY17AOzs7o7q6eti16urq6Onpid/97ndx7rnnnrCnpaUlHnjggbE+GvAhc/DgwfizP/uz8T7GIPkITBTyEWBkZzMjx7yAj8bq1aujqalp8Ovu7u646KKL4uDBg1FZWTmOJwMmo56enqipqYnzzz9/vI9yxuQjcDbJR4CRjUVGjnkBnzFjRnR1dQ271tXVFZWVlXl/exkRkcvlIpfLnXC9srJSgAKjNtFegigfgYlCPgKM7Gxm5Jj/sU9dXV20tbUNu/bSSy9FXV3dWD80wIQmHwHyk49AsSq4gP/f//1fdHR0REdHR0Qc/5iIjo6OOHDgQEQcf/nP0qVLB9ffeeedsX///vjqV78a+/bti8cffzy+//3vx8qVK8/OBAAThHwEyE8+AhxXcAH/+c9/HldddVVcddVVERHR1NQUV111VaxduzYiIn7zm98MhmlExJ//+Z/Htm3b4qWXXoq5c+fGI488Et/5zneioaHhLI0AMDHIR4D85CPAcWf0OeCp9PT0RFVVVXR3d/sbHqBgxZwhxTwbMPaKOUOKeTYgjbHIkYnzgY8AAABQxBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgARGVcA3btwYc+bMiYqKiqitrY2dO3eedP2GDRvi4x//eJx77rlRU1MTK1eujN///vejOjDARCYfAfKTjwCjKOBbt26NpqamaG5ujt27d8fcuXOjoaEh3nnnnbzrn3nmmVi1alU0NzfH3r1748knn4ytW7fGvffee8aHB5hI5CNAfvIR4LiCC/ijjz4at99+eyxfvjw++clPxqZNm+K8886Lp556Ku/6V155Ja699tq45ZZbYs6cOfG5z30ubr755lP+1hNgspGPAPnJR4DjCirgfX19sWvXrqivrx+6g9LSqK+vj/b29rx7rrnmmti1a9dgYO7fvz+2b98eN95444iP09vbGz09PcNuABOZfATITz4CDJlSyOLDhw9Hf39/VFdXD7teXV0d+/bty7vnlltuicOHD8dnPvOZyLIsjh07FnfeeedJX0LU0tISDzzwQCFHAxhX8hEgP/kIMGTM3wV9x44dsW7dunj88cdj9+7d8dxzz8W2bdviwQcfHHHP6tWro7u7e/B28ODBsT4mQHLyESA/+QgUq4KeAZ82bVqUlZVFV1fXsOtdXV0xY8aMvHvuv//+WLJkSdx2220REXHFFVfE0aNH44477og1a9ZEaemJvwPI5XKRy+UKORrAuJKPAPnJR4AhBT0DXl5eHvPnz4+2trbBawMDA9HW1hZ1dXV597z33nsnhGRZWVlERGRZVuh5ASYk+QiQn3wEGFLQM+AREU1NTbFs2bJYsGBBLFy4MDZs2BBHjx6N5cuXR0TE0qVLY/bs2dHS0hIREYsWLYpHH300rrrqqqitrY0333wz7r///li0aNFgkAIUA/kIkJ98BDiu4ALe2NgYhw4dirVr10ZnZ2fMmzcvWltbB99Y48CBA8N+Y3nfffdFSUlJ3HffffHrX/86/vRP/zQWLVoU3/zmN8/eFAATgHwEyE8+AhxXkk2C1/H09PREVVVVdHd3R2Vl5XgfB5hkijlDink2YOwVc4YU82xAGmORI2P+LugAAACAAg4AAABJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJjKqAb9y4MebMmRMVFRVRW1sbO3fuPOn6d999N1asWBEzZ86MXC4Xl156aWzfvn1UBwaYyOQjQH7yESBiSqEbtm7dGk1NTbFp06aora2NDRs2RENDQ7z++usxffr0E9b39fXFX/3VX8X06dPj2WefjdmzZ8evfvWruOCCC87G+QEmDPkIkJ98BDiuJMuyrJANtbW1cfXVV8djjz0WEREDAwNRU1MTd911V6xateqE9Zs2bYp/+Zd/iX379sU555wzqkP29PREVVVVdHd3R2Vl5ajuA/jwSpUh8hGYbOQjwMjGIkcKegl6X19f7Nq1K+rr64fuoLQ06uvro729Pe+eH/7wh1FXVxcrVqyI6urquPzyy2PdunXR398/4uP09vZGT0/PsBvARCYfAfKTjwBDCirghw8fjv7+/qiurh52vbq6Ojo7O/Pu2b9/fzz77LPR398f27dvj/vvvz8eeeSR+MY3vjHi47S0tERVVdXgraamppBjAiQnHwHyk48AQ8b8XdAHBgZi+vTp8cQTT8T8+fOjsbEx1qxZE5s2bRpxz+rVq6O7u3vwdvDgwbE+JkBy8hEgP/kIFKuC3oRt2rRpUVZWFl1dXcOud3V1xYwZM/LumTlzZpxzzjlRVlY2eO0Tn/hEdHZ2Rl9fX5SXl5+wJ5fLRS6XK+RoAONKPgLkJx8BhhT0DHh5eXnMnz8/2traBq8NDAxEW1tb1NXV5d1z7bXXxptvvhkDAwOD1954442YOXNm3vAEmIzkI0B+8hFgSMEvQW9qaorNmzfHd7/73di7d2986UtfiqNHj8by5csjImLp0qWxevXqwfVf+tKX4re//W3cfffd8cYbb8S2bdti3bp1sWLFirM3BcAEIB8B8pOPAMcV/DngjY2NcejQoVi7dm10dnbGvHnzorW1dfCNNQ4cOBClpUO9vqamJl588cVYuXJlXHnllTF79uy4++6745577jl7UwBMAPIRID/5CHBcwZ8DPh58jiNwJoo5Q4p5NmDsFXOGFPNsQBrj/jngAAAAwOgo4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJjKqAb9y4MebMmRMVFRVRW1sbO3fuPK19W7ZsiZKSkli8ePFoHhZgwpOPAPnJR4BRFPCtW7dGU1NTNDc3x+7du2Pu3LnR0NAQ77zzzkn3vf322/GP//iPcd111436sAATmXwEyE8+AhxXcAF/9NFH4/bbb4/ly5fHJz/5ydi0aVOcd9558dRTT424p7+/P774xS/GAw88EBdffPEZHRhgopKPAPnJR4DjCirgfX19sWvXrqivrx+6g9LSqK+vj/b29hH3ff3rX4/p06fHrbfeelqP09vbGz09PcNuABOZfATITz4CDCmogB8+fDj6+/ujurp62PXq6uro7OzMu+fll1+OJ598MjZv3nzaj9PS0hJVVVWDt5qamkKOCZCcfATITz4CDBnTd0E/cuRILFmyJDZv3hzTpk077X2rV6+O7u7uwdvBgwfH8JQA6clHgPzkI1DMphSyeNq0aVFWVhZdXV3Drnd1dcWMGTNOWP/LX/4y3n777Vi0aNHgtYGBgeMPPGVKvP7663HJJZecsC+Xy0UulyvkaADjSj4C5CcfAYYU9Ax4eXl5zJ8/P9ra2gavDQwMRFtbW9TV1Z2w/rLLLotXX301Ojo6Bm+f//zn44YbboiOjg4vDQKKhnwEyE8+Agwp6BnwiIimpqZYtmxZLFiwIBYuXBgbNmyIo0ePxvLlyyMiYunSpTF79uxoaWmJioqKuPzyy4ftv+CCCyIiTrgOMNnJR4D85CPAcQUX8MbGxjh06FCsXbs2Ojs7Y968edHa2jr4xhoHDhyI0tIx/dNygAlJPgLkJx8BjivJsiwb70OcSk9PT1RVVUV3d3dUVlaO93GASaaYM6SYZwPGXjFnSDHPBqQxFjniV40AAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACSjgAAAAkIACDgAAAAko4AAAAJCAAg4AAAAJKOAAAACQgAIOAAAACYyqgG/cuDHmzJkTFRUVUVtbGzt37hxx7ebNm+O6666LqVOnxtSpU6O+vv6k6wEmM/kIkJ98BBhFAd+6dWs0NTVFc3Nz7N69O+bOnRsNDQ3xzjvv5F2/Y8eOuPnmm+MnP/lJtLe3R01NTXzuc5+LX//612d8eICJRD4C5CcfAY4rybIsK2RDbW1tXH311fHYY49FRMTAwEDU1NTEXXfdFatWrTrl/v7+/pg6dWo89thjsXTp0tN6zJ6enqiqqoru7u6orKws5LgAyTJEPgKTjXwEGNlY5EhBz4D39fXFrl27or6+fugOSkujvr4+2tvbT+s+3nvvvXj//ffjwgsvLOykABOYfATITz4CDJlSyOLDhw9Hf39/VFdXD7teXV0d+/btO637uOeee2LWrFnDQviP9fb2Rm9v7+DXPT09hRwTIDn5CJCffAQYkvRd0NevXx9btmyJ559/PioqKkZc19LSElVVVYO3mpqahKcESE8+AuQnH4FiUlABnzZtWpSVlUVXV9ew611dXTFjxoyT7n344Ydj/fr18eMf/ziuvPLKk65dvXp1dHd3D94OHjxYyDEBkpOPAPnJR4AhBRXw8vLymD9/frS1tQ1eGxgYiLa2tqirqxtx30MPPRQPPvhgtLa2xoIFC075OLlcLiorK4fdACYy+QiQn3wEGFLQ34BHRDQ1NcWyZctiwYIFsXDhwtiwYUMcPXo0li9fHhERS5cujdmzZ0dLS0tERPzzP/9zrF27Np555pmYM2dOdHZ2RkTERz7ykfjIRz5yFkcBGF/yESA/+QhwXMEFvLGxMQ4dOhRr166Nzs7OmDdvXrS2tg6+scaBAweitHToifVvf/vb0dfXF3/zN38z7H6am5vja1/72pmdHmACkY8A+clHgOMK/hzw8eBzHIEzUcwZUsyzAWOvmDOkmGcD0hj3zwEHAAAARkcBBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhAAQcAAIAEFHAAAABIQAEHAACABBRwAAAASEABBwAAgAQUcAAAAEhgVAV848aNMWfOnKioqIja2trYuXPnSdf/4Ac/iMsuuywqKiriiiuuiO3bt4/qsAATnXwEyE8+AoyigG/dujWampqiubk5du/eHXPnzo2GhoZ455138q5/5ZVX4uabb45bb7019uzZE4sXL47FixfHL37xizM+PMBEIh8B8pOPAMeVZFmWFbKhtrY2rr766njsscciImJgYCBqamrirrvuilWrVp2wvrGxMY4ePRo/+tGPBq/95V/+ZcybNy82bdp0Wo/Z09MTVVVV0d3dHZWVlYUcFyBZhshHYLKRjwAjG4scmVLI4r6+vti1a1esXr168FppaWnU19dHe3t73j3t7e3R1NQ07FpDQ0O88MILIz5Ob29v9Pb2Dn7d3d0dEcf/AwAU6oPsKPD3jQWRj8BkJB8BRjYWGVlQAT98+HD09/dHdXX1sOvV1dWxb9++vHs6Ozvzru/s7BzxcVpaWuKBBx444XpNTU0hxwUY5n/+53+iqqpqTO5bPgKTmXwEGNnZzMiCCngqq1evHvZbz3fffTc++tGPxoEDB8bsH4fx0NPTEzU1NXHw4MGie2mU2SanYp2tu7s7LrroorjwwgvH+yhn7MOSjxHF+/NYrHNFmG0yko+TU7H+PEYU72zFOldEcc82FhlZUAGfNm1alJWVRVdX17DrXV1dMWPGjLx7ZsyYUdD6iIhcLhe5XO6E61VVVUX3TY2IqKysLMq5Isw2WRXrbKWlY/fJi/Jx7BTrz2OxzhVhtslIPk5OxfrzGFG8sxXrXBHFPdvZzMiC7qm8vDzmz58fbW1tg9cGBgaira0t6urq8u6pq6sbtj4i4qWXXhpxPcBkJB8B8pOPAEMKfgl6U1NTLFu2LBYsWBALFy6MDRs2xNGjR2P58uUREbF06dKYPXt2tLS0RETE3XffHddff3088sgjcdNNN8WWLVvi5z//eTzxxBNndxKAcSYfAfKTjwDHFVzAGxsb49ChQ7F27dro7OyMefPmRWtr6+AbZRw4cGDYU/TXXHNNPPPMM3HffffFvffeG3/xF38RL7zwQlx++eWn/Zi5XC6am5vzvqxoMivWuSLMNlkV62yp5pKPZ1exzlasc0WYbTKSj5OT2SafYp0rwmyFKvhzwAEAAIDCjd07bgAAAACDFHAAAABIQAEHAACABBRwAAAASGDCFPCNGzfGnDlzoqKiImpra2Pnzp0nXf+DH/wgLrvssqioqIgrrrgitm/fnuikhSlkrs2bN8d1110XU6dOjalTp0Z9ff0p/zuMp0K/Zx/YsmVLlJSUxOLFi8f2gGeg0NnefffdWLFiRcycOTNyuVxceumlE/JnstC5NmzYEB//+Mfj3HPPjZqamli5cmX8/ve/T3Ta0/fTn/40Fi1aFLNmzYqSkpJ44YUXTrlnx44d8elPfzpyuVx87GMfi6effnrMzzlaxZqPEcWbkfJxyGTJx4jizEj5OJx8nBiKNSPl4xD5eBLZBLBly5asvLw8e+qpp7L/+q//ym6//fbsggsuyLq6uvKu/9nPfpaVlZVlDz30UPbaa69l9913X3bOOedkr776auKTn1yhc91yyy3Zxo0bsz179mR79+7N/u7v/i6rqqrK/vu//zvxyU+t0Nk+8NZbb2WzZ8/Orrvuuuyv//qv0xy2QIXO1tvbmy1YsCC78cYbs5dffjl76623sh07dmQdHR2JT35yhc71ve99L8vlctn3vve97K233spefPHFbObMmdnKlSsTn/zUtm/fnq1ZsyZ77rnnsojInn/++ZOu379/f3beeedlTU1N2WuvvZZ961vfysrKyrLW1tY0By5AseZjlhVvRsrHIZMlH7OseDNSPg6RjxNDsWakfBwiH09uQhTwhQsXZitWrBj8ur+/P5s1a1bW0tKSd/0XvvCF7Kabbhp2rba2Nvv7v//7MT1noQqd648dO3YsO//887Pvfve7Y3XEURvNbMeOHcuuueaa7Dvf+U62bNmyCRmeWVb4bN/+9reziy++OOvr60t1xFEpdK4VK1Zkn/3sZ4dda2pqyq699toxPeeZOp0A/epXv5p96lOfGnatsbExa2hoGMOTjU6x5mOWFW9GyschkyUfs+zDkZHyUT5OBMWakfJxiHw8uXF/CXpfX1/s2rUr6uvrB6+VlpZGfX19tLe3593T3t4+bH1ERENDw4jrx8No5vpj7733Xrz//vtx4YUXjtUxR2W0s33961+P6dOnx6233primKMymtl++MMfRl1dXaxYsSKqq6vj8ssvj3Xr1kV/f3+qY5/SaOa65pprYteuXYMvMdq/f39s3749brzxxiRnHkuTIUMiijcfI4o3I+XjcJMhHyNk5B8q5gwp5tn+2ETMx4jizUj5OJx8PLkpZ/NQo3H48OHo7++P6urqYderq6tj3759efd0dnbmXd/Z2Tlm5yzUaOb6Y/fcc0/MmjXrhG/0eBvNbC+//HI8+eST0dHRkeCEozea2fbv3x//8R//EV/84hdj+/bt8eabb8aXv/zleP/996O5uTnFsU9pNHPdcsstcfjw4fjMZz4TWZbFsWPH4s4774x77703xZHH1EgZ0tPTE7/73e/i3HPPHaeTDVes+RhRvBkpH4ebDPkYISP/kHwcf8WajxHFm5HycTj5eHLj/gw4+a1fvz62bNkSzz//fFRUVIz3cc7IkSNHYsmSJbF58+aYNm3aeB/nrBsYGIjp06fHE088EfPnz4/GxsZYs2ZNbNq0abyPdkZ27NgR69ati8cffzx2794dzz33XGzbti0efPDB8T4aFE1GysfJS0YyURVLPkYUd0bKxw+vcX8GfNq0aVFWVhZdXV3Drnd1dcWMGTPy7pkxY0ZB68fDaOb6wMMPPxzr16+Pf//3f48rr7xyLI85KoXO9stf/jLefvvtWLRo0eC1gYGBiIiYMmVKvP7663HJJZeM7aFP02i+bzNnzoxzzjknysrKBq994hOfiM7Ozujr64vy8vIxPfPpGM1c999/fyxZsiRuu+22iIi44oor4ujRo3HHHXfEmjVrorR08v7+bqQMqaysnDDP7kQUbz5GFG9GysfhJkM+RsjIPyQfx1+x5mNE8WakfBxOPp7cuE9fXl4e8+fPj7a2tsFrAwMD0dbWFnV1dXn31NXVDVsfEfHSSy+NuH48jGauiIiHHnooHnzwwWhtbY0FCxakOGrBCp3tsssui1dffTU6OjoGb5///OfjhhtuiI6OjqipqUl5/JMazfft2muvjTfffHPwH4SIiDfeeCNmzpw5YcJzNHO99957JwTkB/9IHH+vislrMmRIRPHmY0TxZqR8HG4y5GOEjPxDxZwhxTxbxMTPx4jizUj5OJx8PIWC3rJtjGzZsiXL5XLZ008/nb322mvZHXfckV1wwQVZZ2dnlmVZtmTJkmzVqlWD63/2s59lU6ZMyR5++OFs7969WXNz84T8GIlC51q/fn1WXl6ePfvss9lvfvObwduRI0fGa4QRFTrbH5uo72CZZYXPduDAgez888/P/uEf/iF7/fXXsx/96EfZ9OnTs2984xvjNUJehc7V3NycnX/++dm//du/Zfv3789+/OMfZ5dcckn2hS98YbxGGNGRI0eyPXv2ZHv27MkiInv00UezPXv2ZL/61a+yLMuyVatWZUuWLBlc/8HHSPzTP/1Ttnfv3mzjxo0T+mN2ijEfs6x4M1I+Tr58zLLizUj5KB8nmmLNSPkoH0/XhCjgWZZl3/rWt7KLLrooKy8vzxYuXJj953/+5+D/dv3112fLli0btv773/9+dumll2bl5eXZpz71qWzbtm2JT3x6Cpnrox/9aBYRJ9yam5vTH/w0FPo9+0MTNTw/UOhsr7zySlZbW5vlcrns4osvzr75zW9mx44dS3zqUytkrvfffz/72te+ll1yySVZRUVFVlNTk335y1/O/vd//zf9wU/hJz/5Sd7/73wwz7Jly7Lrr7/+hD3z5s3LysvLs4svvjj713/91+TnPl3Fmo9ZVrwZKR+HTJZ8zLLizEj5uGzYevk4MRRrRsrH4+TjyZVk2SR+HQAAAABMEuP+N+AAAADwYaCAAwAAQAIKOAAAACSggAMAAEACCjgAAAAkoIADAABAAgo4AAAAJKCAAwAAQAIKOAAAACSggAMAAEACCjgAAAAkoIADAABAAv8PErIwn8QKNHkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from functools import partial\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig, (ax_traj, ax_phase, ax_vecfield) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "learned_op = ODEFunc().to(device)\n",
    "optimizer = optim.RMSprop(learned_op.parameters(), lr=1e-3)\n",
    "\n",
    "def train_loop(optimizer, true_y0, t):\n",
    "    for itr in range(1, args.iterations + 1):\n",
    "        optimizer.zero_grad()\n",
    "        batch_y0, batch_t, batch_y = get_batch()\n",
    "        print(\"SIZES\", batch_y0.size(), batch_y.size(), batch_t.size())\n",
    "        pred_y = odeint(learned_op, batch_y0, batch_t).to(device)\n",
    "        loss = torch.mean(torch.abs(pred_y - batch_y))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % args.test_freq == 0:\n",
    "            with torch.no_grad():\n",
    "                test_pred_y = odeint(learned_op, true_y0, t)\n",
    "                test_loss = torch.mean(torch.abs(test_pred_y - true_y))\n",
    "                print(f'Total Loss {test_loss.item()}')\n",
    "                yield true_y, test_pred_y\n",
    "\n",
    "def viz_update(frame):\n",
    "    true_y, pred_y = frame\n",
    "    visualize(true_y, pred_y, learned_op)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    viz_frames = list(train_loop(optimizer, true_y0, t))\n",
    "\n",
    "    ani = FuncAnimation(\n",
    "        fig,\n",
    "        viz_update,\n",
    "        frames=viz_frames,\n",
    "        repeat=False\n",
    "    )\n",
    "    html_animation = HTML(ani.to_jshtml())\n",
    "    display(html_animation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
