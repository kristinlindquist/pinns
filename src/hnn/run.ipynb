{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate\n",
    "import torch\n",
    "import sys  \n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from hnn.simulation import get_dataset, get_field, get_trajectory, get_vector_field, integrate_model\n",
    "from hnn.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description=None)\n",
    "    parser.add_argument('--input_dim', default=2, type=int, help='dimensionality of input tensor')\n",
    "    parser.add_argument('--hidden_dim', default=200, type=int, help='hidden dimension of mlp')\n",
    "    parser.add_argument('--learn_rate', default=1e-3, type=float, help='learning rate')\n",
    "    parser.add_argument('--total_steps', default=2000, type=int, help='number of gradient steps')\n",
    "    parser.add_argument('--name', default='pend', type=str, help='only one option right now')\n",
    "    parser.add_argument('--field_type', default='solenoidal', type=str, help='type of vector field to learn')\n",
    "    parser.set_defaults(feature=True)\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristinlindquist/development/pinns/src/hnn/../hnn/train.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(data[\"x\"], requires_grad=True, dtype=torch.float32)\n",
      "/Users/kristinlindquist/development/pinns/src/hnn/../hnn/train.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x = torch.tensor(data[\"test_x\"], requires_grad=True, dtype=torch.float32)\n",
      "/Users/kristinlindquist/development/pinns/src/hnn/../hnn/train.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dxdt = torch.tensor(data[\"dx\"], requires_grad=True, dtype=torch.float32)\n",
      "/Users/kristinlindquist/development/pinns/src/hnn/../hnn/train.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_dxdt = torch.tensor(data[\"test_dx\"], requires_grad=True, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X has grad? False\n",
      "X has grad? False\n",
      "step 0, train_loss 6.1798e+00, test_loss 6.6746e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1, train_loss 5.7570e+00, test_loss 6.4878e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 2, train_loss 5.4049e+00, test_loss 6.2779e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 3, train_loss 5.0936e+00, test_loss 6.0322e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 4, train_loss 4.8002e+00, test_loss 5.7505e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 5, train_loss 4.5122e+00, test_loss 5.4414e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 6, train_loss 4.2255e+00, test_loss 5.1170e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 7, train_loss 3.9413e+00, test_loss 4.7891e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 8, train_loss 3.6622e+00, test_loss 4.4677e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 9, train_loss 3.3908e+00, test_loss 4.1599e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 10, train_loss 3.1281e+00, test_loss 3.8700e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 11, train_loss 2.8741e+00, test_loss 3.5997e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 12, train_loss 2.6286e+00, test_loss 3.3496e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 13, train_loss 2.3914e+00, test_loss 3.1194e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 14, train_loss 2.1636e+00, test_loss 2.9089e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 15, train_loss 1.9467e+00, test_loss 2.7176e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 16, train_loss 1.7431e+00, test_loss 2.5452e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 17, train_loss 1.5549e+00, test_loss 2.3911e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 18, train_loss 1.3835e+00, test_loss 2.2544e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 19, train_loss 1.2294e+00, test_loss 2.1338e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 20, train_loss 1.0922e+00, test_loss 2.0279e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 21, train_loss 9.7060e-01, test_loss 1.9350e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 22, train_loss 8.6341e-01, test_loss 1.8536e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 23, train_loss 7.6949e-01, test_loss 1.7816e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 24, train_loss 6.8782e-01, test_loss 1.7164e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 25, train_loss 6.1715e-01, test_loss 1.6548e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 26, train_loss 5.5573e-01, test_loss 1.5938e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 27, train_loss 5.0139e-01, test_loss 1.5317e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 28, train_loss 4.5217e-01, test_loss 1.4690e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 29, train_loss 4.0717e-01, test_loss 1.4083e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 30, train_loss 3.6689e-01, test_loss 1.3538e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 31, train_loss 3.3277e-01, test_loss 1.3087e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 32, train_loss 3.0610e-01, test_loss 1.2743e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 33, train_loss 2.8696e-01, test_loss 1.2489e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 34, train_loss 2.7386e-01, test_loss 1.2298e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 35, train_loss 2.6433e-01, test_loss 1.2137e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 36, train_loss 2.5589e-01, test_loss 1.1987e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 37, train_loss 2.4672e-01, test_loss 1.1842e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 38, train_loss 2.3593e-01, test_loss 1.1702e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 39, train_loss 2.2359e-01, test_loss 1.1572e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 40, train_loss 2.1058e-01, test_loss 1.1453e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 41, train_loss 1.9804e-01, test_loss 1.1343e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 42, train_loss 1.8668e-01, test_loss 1.1229e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 43, train_loss 1.7630e-01, test_loss 1.1099e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 44, train_loss 1.6614e-01, test_loss 1.0947e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 45, train_loss 1.5559e-01, test_loss 1.0777e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 46, train_loss 1.4478e-01, test_loss 1.0601e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 47, train_loss 1.3439e-01, test_loss 1.0435e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 48, train_loss 1.2512e-01, test_loss 1.0291e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 49, train_loss 1.1728e-01, test_loss 1.0174e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 50, train_loss 1.1074e-01, test_loss 1.0083e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 51, train_loss 1.0512e-01, test_loss 1.0011e+00\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 52, train_loss 9.9999e-02, test_loss 9.9476e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 53, train_loss 9.5015e-02, test_loss 9.8866e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 54, train_loss 9.0038e-02, test_loss 9.8247e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 55, train_loss 8.5200e-02, test_loss 9.7630e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 56, train_loss 8.0778e-02, test_loss 9.7039e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 57, train_loss 7.6959e-02, test_loss 9.6477e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 58, train_loss 7.3675e-02, test_loss 9.5925e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 59, train_loss 7.0663e-02, test_loss 9.5361e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 60, train_loss 6.7681e-02, test_loss 9.4775e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 61, train_loss 6.4684e-02, test_loss 9.4174e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 62, train_loss 6.1819e-02, test_loss 9.3572e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 63, train_loss 5.9285e-02, test_loss 9.2978e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 64, train_loss 5.7195e-02, test_loss 9.2396e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 65, train_loss 5.5517e-02, test_loss 9.1834e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 66, train_loss 5.4100e-02, test_loss 9.1298e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 67, train_loss 5.2751e-02, test_loss 9.0801e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 68, train_loss 5.1335e-02, test_loss 9.0354e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 69, train_loss 4.9841e-02, test_loss 8.9957e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 70, train_loss 4.8367e-02, test_loss 8.9596e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 71, train_loss 4.7027e-02, test_loss 8.9246e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 72, train_loss 4.5853e-02, test_loss 8.8875e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 73, train_loss 4.4777e-02, test_loss 8.8461e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 74, train_loss 4.3704e-02, test_loss 8.8004e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 75, train_loss 4.2593e-02, test_loss 8.7524e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 76, train_loss 4.1479e-02, test_loss 8.7048e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 77, train_loss 4.0438e-02, test_loss 8.6601e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 78, train_loss 3.9526e-02, test_loss 8.6193e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 79, train_loss 3.8752e-02, test_loss 8.5817e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 80, train_loss 3.8085e-02, test_loss 8.5457e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 81, train_loss 3.7477e-02, test_loss 8.5097e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 82, train_loss 3.6894e-02, test_loss 8.4729e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 83, train_loss 3.6333e-02, test_loss 8.4355e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 84, train_loss 3.5815e-02, test_loss 8.3981e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 85, train_loss 3.5348e-02, test_loss 8.3616e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 86, train_loss 3.4920e-02, test_loss 8.3261e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 87, train_loss 3.4504e-02, test_loss 8.2918e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 88, train_loss 3.4082e-02, test_loss 8.2585e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 89, train_loss 3.3661e-02, test_loss 8.2261e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 90, train_loss 3.3256e-02, test_loss 8.1944e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 91, train_loss 3.2881e-02, test_loss 8.1636e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 92, train_loss 3.2533e-02, test_loss 8.1341e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 93, train_loss 3.2205e-02, test_loss 8.1066e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 94, train_loss 3.1889e-02, test_loss 8.0817e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 95, train_loss 3.1582e-02, test_loss 8.0595e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 96, train_loss 3.1290e-02, test_loss 8.0397e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 97, train_loss 3.1021e-02, test_loss 8.0214e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 98, train_loss 3.0775e-02, test_loss 8.0035e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 99, train_loss 3.0542e-02, test_loss 7.9854e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 100, train_loss 3.0311e-02, test_loss 7.9669e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 101, train_loss 3.0079e-02, test_loss 7.9485e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 102, train_loss 2.9852e-02, test_loss 7.9308e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 103, train_loss 2.9635e-02, test_loss 7.9144e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 104, train_loss 2.9432e-02, test_loss 7.8993e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 105, train_loss 2.9238e-02, test_loss 7.8851e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 106, train_loss 2.9051e-02, test_loss 7.8711e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 107, train_loss 2.8867e-02, test_loss 7.8569e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 108, train_loss 2.8688e-02, test_loss 7.8422e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 109, train_loss 2.8519e-02, test_loss 7.8272e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 110, train_loss 2.8359e-02, test_loss 7.8120e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 111, train_loss 2.8208e-02, test_loss 7.7969e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 112, train_loss 2.8062e-02, test_loss 7.7821e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 113, train_loss 2.7918e-02, test_loss 7.7675e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 114, train_loss 2.7778e-02, test_loss 7.7527e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 115, train_loss 2.7642e-02, test_loss 7.7376e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 116, train_loss 2.7512e-02, test_loss 7.7221e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 117, train_loss 2.7387e-02, test_loss 7.7064e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 118, train_loss 2.7266e-02, test_loss 7.6908e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 119, train_loss 2.7147e-02, test_loss 7.6757e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 120, train_loss 2.7033e-02, test_loss 7.6612e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 121, train_loss 2.6922e-02, test_loss 7.6474e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 122, train_loss 2.6817e-02, test_loss 7.6339e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 123, train_loss 2.6714e-02, test_loss 7.6205e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 124, train_loss 2.6614e-02, test_loss 7.6072e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 125, train_loss 2.6517e-02, test_loss 7.5939e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 126, train_loss 2.6422e-02, test_loss 7.5810e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 127, train_loss 2.6330e-02, test_loss 7.5684e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 128, train_loss 2.6241e-02, test_loss 7.5564e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 129, train_loss 2.6154e-02, test_loss 7.5448e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 130, train_loss 2.6069e-02, test_loss 7.5335e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 131, train_loss 2.5986e-02, test_loss 7.5223e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 132, train_loss 2.5906e-02, test_loss 7.5111e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 133, train_loss 2.5828e-02, test_loss 7.5000e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 134, train_loss 2.5753e-02, test_loss 7.4891e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 135, train_loss 2.5680e-02, test_loss 7.4786e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 136, train_loss 2.5609e-02, test_loss 7.4684e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 137, train_loss 2.5539e-02, test_loss 7.4585e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 138, train_loss 2.5471e-02, test_loss 7.4487e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 139, train_loss 2.5406e-02, test_loss 7.4390e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 140, train_loss 2.5341e-02, test_loss 7.4294e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 141, train_loss 2.5278e-02, test_loss 7.4198e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 142, train_loss 2.5217e-02, test_loss 7.4105e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 143, train_loss 2.5157e-02, test_loss 7.4015e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 144, train_loss 2.5098e-02, test_loss 7.3927e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 145, train_loss 2.5041e-02, test_loss 7.3842e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 146, train_loss 2.4985e-02, test_loss 7.3759e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 147, train_loss 2.4930e-02, test_loss 7.3677e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 148, train_loss 2.4876e-02, test_loss 7.3598e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 149, train_loss 2.4824e-02, test_loss 7.3522e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 150, train_loss 2.4772e-02, test_loss 7.3449e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 151, train_loss 2.4722e-02, test_loss 7.3379e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 152, train_loss 2.4672e-02, test_loss 7.3313e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 153, train_loss 2.4623e-02, test_loss 7.3249e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 154, train_loss 2.4575e-02, test_loss 7.3186e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 155, train_loss 2.4528e-02, test_loss 7.3125e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 156, train_loss 2.4482e-02, test_loss 7.3065e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 157, train_loss 2.4436e-02, test_loss 7.3008e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 158, train_loss 2.4391e-02, test_loss 7.2953e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 159, train_loss 2.4347e-02, test_loss 7.2899e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 160, train_loss 2.4303e-02, test_loss 7.2847e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 161, train_loss 2.4261e-02, test_loss 7.2796e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 162, train_loss 2.4218e-02, test_loss 7.2746e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 163, train_loss 2.4176e-02, test_loss 7.2697e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 164, train_loss 2.4135e-02, test_loss 7.2649e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 165, train_loss 2.4095e-02, test_loss 7.2603e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 166, train_loss 2.4055e-02, test_loss 7.2558e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 167, train_loss 2.4015e-02, test_loss 7.2514e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 168, train_loss 2.3976e-02, test_loss 7.2470e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 169, train_loss 2.3937e-02, test_loss 7.2428e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 170, train_loss 2.3899e-02, test_loss 7.2386e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 171, train_loss 2.3861e-02, test_loss 7.2345e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 172, train_loss 2.3824e-02, test_loss 7.2305e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 173, train_loss 2.3787e-02, test_loss 7.2267e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 174, train_loss 2.3751e-02, test_loss 7.2230e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 175, train_loss 2.3714e-02, test_loss 7.2194e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 176, train_loss 2.3679e-02, test_loss 7.2159e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 177, train_loss 2.3643e-02, test_loss 7.2124e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 178, train_loss 2.3608e-02, test_loss 7.2091e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 179, train_loss 2.3574e-02, test_loss 7.2059e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 180, train_loss 2.3539e-02, test_loss 7.2027e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 181, train_loss 2.3505e-02, test_loss 7.1996e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 182, train_loss 2.3471e-02, test_loss 7.1966e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 183, train_loss 2.3438e-02, test_loss 7.1936e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 184, train_loss 2.3405e-02, test_loss 7.1907e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 185, train_loss 2.3372e-02, test_loss 7.1878e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 186, train_loss 2.3340e-02, test_loss 7.1850e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 187, train_loss 2.3307e-02, test_loss 7.1822e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 188, train_loss 2.3275e-02, test_loss 7.1795e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 189, train_loss 2.3244e-02, test_loss 7.1769e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 190, train_loss 2.3212e-02, test_loss 7.1743e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 191, train_loss 2.3181e-02, test_loss 7.1717e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 192, train_loss 2.3150e-02, test_loss 7.1691e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 193, train_loss 2.3119e-02, test_loss 7.1666e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 194, train_loss 2.3088e-02, test_loss 7.1642e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 195, train_loss 2.3058e-02, test_loss 7.1618e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 196, train_loss 2.3028e-02, test_loss 7.1595e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 197, train_loss 2.2998e-02, test_loss 7.1571e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 198, train_loss 2.2968e-02, test_loss 7.1549e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 199, train_loss 2.2938e-02, test_loss 7.1527e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 200, train_loss 2.2909e-02, test_loss 7.1505e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 201, train_loss 2.2880e-02, test_loss 7.1484e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 202, train_loss 2.2851e-02, test_loss 7.1463e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 203, train_loss 2.2822e-02, test_loss 7.1443e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 204, train_loss 2.2793e-02, test_loss 7.1423e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 205, train_loss 2.2764e-02, test_loss 7.1404e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 206, train_loss 2.2736e-02, test_loss 7.1385e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 207, train_loss 2.2708e-02, test_loss 7.1367e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 208, train_loss 2.2679e-02, test_loss 7.1349e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 209, train_loss 2.2651e-02, test_loss 7.1332e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 210, train_loss 2.2623e-02, test_loss 7.1315e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 211, train_loss 2.2595e-02, test_loss 7.1299e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 212, train_loss 2.2568e-02, test_loss 7.1283e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 213, train_loss 2.2540e-02, test_loss 7.1268e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 214, train_loss 2.2512e-02, test_loss 7.1253e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 215, train_loss 2.2485e-02, test_loss 7.1239e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 216, train_loss 2.2457e-02, test_loss 7.1226e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 217, train_loss 2.2430e-02, test_loss 7.1213e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 218, train_loss 2.2403e-02, test_loss 7.1200e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 219, train_loss 2.2375e-02, test_loss 7.1188e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 220, train_loss 2.2348e-02, test_loss 7.1177e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 221, train_loss 2.2321e-02, test_loss 7.1166e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 222, train_loss 2.2294e-02, test_loss 7.1156e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 223, train_loss 2.2267e-02, test_loss 7.1146e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 224, train_loss 2.2240e-02, test_loss 7.1137e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 225, train_loss 2.2213e-02, test_loss 7.1129e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 226, train_loss 2.2186e-02, test_loss 7.1120e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 227, train_loss 2.2159e-02, test_loss 7.1113e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 228, train_loss 2.2132e-02, test_loss 7.1106e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 229, train_loss 2.2105e-02, test_loss 7.1099e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 230, train_loss 2.2078e-02, test_loss 7.1093e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 231, train_loss 2.2052e-02, test_loss 7.1088e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 232, train_loss 2.2025e-02, test_loss 7.1082e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 233, train_loss 2.1998e-02, test_loss 7.1078e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 234, train_loss 2.1971e-02, test_loss 7.1074e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 235, train_loss 2.1944e-02, test_loss 7.1070e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 236, train_loss 2.1917e-02, test_loss 7.1067e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 237, train_loss 2.1890e-02, test_loss 7.1065e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 238, train_loss 2.1863e-02, test_loss 7.1063e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 239, train_loss 2.1836e-02, test_loss 7.1062e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 240, train_loss 2.1809e-02, test_loss 7.1061e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 241, train_loss 2.1782e-02, test_loss 7.1060e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 242, train_loss 2.1755e-02, test_loss 7.1060e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 243, train_loss 2.1727e-02, test_loss 7.1060e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 244, train_loss 2.1700e-02, test_loss 7.1061e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 245, train_loss 2.1673e-02, test_loss 7.1063e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 246, train_loss 2.1646e-02, test_loss 7.1064e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 247, train_loss 2.1618e-02, test_loss 7.1067e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 248, train_loss 2.1591e-02, test_loss 7.1069e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 249, train_loss 2.1563e-02, test_loss 7.1072e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 250, train_loss 2.1536e-02, test_loss 7.1076e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 251, train_loss 2.1508e-02, test_loss 7.1080e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 252, train_loss 2.1480e-02, test_loss 7.1084e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 253, train_loss 2.1452e-02, test_loss 7.1089e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 254, train_loss 2.1424e-02, test_loss 7.1094e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 255, train_loss 2.1396e-02, test_loss 7.1100e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 256, train_loss 2.1368e-02, test_loss 7.1105e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 257, train_loss 2.1340e-02, test_loss 7.1112e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 258, train_loss 2.1312e-02, test_loss 7.1118e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 259, train_loss 2.1284e-02, test_loss 7.1125e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 260, train_loss 2.1255e-02, test_loss 7.1132e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 261, train_loss 2.1227e-02, test_loss 7.1140e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 262, train_loss 2.1198e-02, test_loss 7.1148e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 263, train_loss 2.1170e-02, test_loss 7.1156e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 264, train_loss 2.1141e-02, test_loss 7.1164e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 265, train_loss 2.1112e-02, test_loss 7.1173e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 266, train_loss 2.1083e-02, test_loss 7.1182e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 267, train_loss 2.1054e-02, test_loss 7.1191e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 268, train_loss 2.1025e-02, test_loss 7.1200e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 269, train_loss 2.0996e-02, test_loss 7.1210e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 270, train_loss 2.0967e-02, test_loss 7.1220e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 271, train_loss 2.0937e-02, test_loss 7.1230e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 272, train_loss 2.0908e-02, test_loss 7.1240e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 273, train_loss 2.0878e-02, test_loss 7.1250e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 274, train_loss 2.0849e-02, test_loss 7.1261e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 275, train_loss 2.0819e-02, test_loss 7.1272e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 276, train_loss 2.0789e-02, test_loss 7.1282e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 277, train_loss 2.0759e-02, test_loss 7.1293e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 278, train_loss 2.0729e-02, test_loss 7.1305e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 279, train_loss 2.0698e-02, test_loss 7.1316e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 280, train_loss 2.0668e-02, test_loss 7.1327e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 281, train_loss 2.0637e-02, test_loss 7.1339e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 282, train_loss 2.0607e-02, test_loss 7.1350e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 283, train_loss 2.0576e-02, test_loss 7.1362e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 284, train_loss 2.0545e-02, test_loss 7.1374e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 285, train_loss 2.0514e-02, test_loss 7.1386e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 286, train_loss 2.0483e-02, test_loss 7.1398e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 287, train_loss 2.0451e-02, test_loss 7.1410e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 288, train_loss 2.0420e-02, test_loss 7.1422e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 289, train_loss 2.0388e-02, test_loss 7.1434e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 290, train_loss 2.0356e-02, test_loss 7.1447e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 291, train_loss 2.0324e-02, test_loss 7.1459e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 292, train_loss 2.0292e-02, test_loss 7.1472e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 293, train_loss 2.0260e-02, test_loss 7.1484e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 294, train_loss 2.0228e-02, test_loss 7.1497e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 295, train_loss 2.0195e-02, test_loss 7.1510e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 296, train_loss 2.0162e-02, test_loss 7.1523e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 297, train_loss 2.0130e-02, test_loss 7.1536e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 298, train_loss 2.0097e-02, test_loss 7.1548e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 299, train_loss 2.0064e-02, test_loss 7.1561e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 300, train_loss 2.0030e-02, test_loss 7.1575e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 301, train_loss 1.9997e-02, test_loss 7.1588e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 302, train_loss 1.9964e-02, test_loss 7.1601e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 303, train_loss 1.9931e-02, test_loss 7.1614e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 304, train_loss 1.9897e-02, test_loss 7.1627e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 305, train_loss 1.9864e-02, test_loss 7.1641e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 306, train_loss 1.9830e-02, test_loss 7.1654e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 307, train_loss 1.9796e-02, test_loss 7.1667e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 308, train_loss 1.9763e-02, test_loss 7.1681e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 309, train_loss 1.9729e-02, test_loss 7.1694e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 310, train_loss 1.9696e-02, test_loss 7.1708e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 311, train_loss 1.9662e-02, test_loss 7.1721e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 312, train_loss 1.9628e-02, test_loss 7.1735e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 313, train_loss 1.9594e-02, test_loss 7.1749e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 314, train_loss 1.9561e-02, test_loss 7.1762e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 315, train_loss 1.9527e-02, test_loss 7.1776e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 316, train_loss 1.9493e-02, test_loss 7.1789e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 317, train_loss 1.9460e-02, test_loss 7.1803e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 318, train_loss 1.9426e-02, test_loss 7.1816e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 319, train_loss 1.9392e-02, test_loss 7.1830e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 320, train_loss 1.9358e-02, test_loss 7.1844e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 321, train_loss 1.9325e-02, test_loss 7.1857e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 322, train_loss 1.9291e-02, test_loss 7.1871e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 323, train_loss 1.9257e-02, test_loss 7.1885e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 324, train_loss 1.9224e-02, test_loss 7.1898e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 325, train_loss 1.9190e-02, test_loss 7.1912e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 326, train_loss 1.9157e-02, test_loss 7.1926e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 327, train_loss 1.9123e-02, test_loss 7.1940e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 328, train_loss 1.9090e-02, test_loss 7.1954e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 329, train_loss 1.9057e-02, test_loss 7.1968e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 330, train_loss 1.9024e-02, test_loss 7.1982e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 331, train_loss 1.8991e-02, test_loss 7.1996e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 332, train_loss 1.8958e-02, test_loss 7.2011e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 333, train_loss 1.8925e-02, test_loss 7.2025e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 334, train_loss 1.8892e-02, test_loss 7.2040e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 335, train_loss 1.8859e-02, test_loss 7.2056e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 336, train_loss 1.8827e-02, test_loss 7.2071e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 337, train_loss 1.8795e-02, test_loss 7.2087e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 338, train_loss 1.8762e-02, test_loss 7.2103e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 339, train_loss 1.8730e-02, test_loss 7.2120e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 340, train_loss 1.8699e-02, test_loss 7.2137e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 341, train_loss 1.8667e-02, test_loss 7.2154e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 342, train_loss 1.8636e-02, test_loss 7.2172e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 343, train_loss 1.8604e-02, test_loss 7.2190e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 344, train_loss 1.8573e-02, test_loss 7.2209e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 345, train_loss 1.8542e-02, test_loss 7.2228e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 346, train_loss 1.8512e-02, test_loss 7.2247e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 347, train_loss 1.8481e-02, test_loss 7.2267e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 348, train_loss 1.8451e-02, test_loss 7.2287e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 349, train_loss 1.8421e-02, test_loss 7.2308e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 350, train_loss 1.8392e-02, test_loss 7.2329e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 351, train_loss 1.8362e-02, test_loss 7.2351e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 352, train_loss 1.8333e-02, test_loss 7.2373e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 353, train_loss 1.8304e-02, test_loss 7.2395e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 354, train_loss 1.8275e-02, test_loss 7.2418e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 355, train_loss 1.8247e-02, test_loss 7.2441e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 356, train_loss 1.8219e-02, test_loss 7.2464e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 357, train_loss 1.8191e-02, test_loss 7.2488e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 358, train_loss 1.8163e-02, test_loss 7.2511e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 359, train_loss 1.8136e-02, test_loss 7.2535e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 360, train_loss 1.8109e-02, test_loss 7.2560e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 361, train_loss 1.8082e-02, test_loss 7.2584e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 362, train_loss 1.8056e-02, test_loss 7.2608e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 363, train_loss 1.8030e-02, test_loss 7.2633e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 364, train_loss 1.8004e-02, test_loss 7.2658e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 365, train_loss 1.7978e-02, test_loss 7.2683e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 366, train_loss 1.7953e-02, test_loss 7.2708e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 367, train_loss 1.7928e-02, test_loss 7.2733e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 368, train_loss 1.7903e-02, test_loss 7.2758e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 369, train_loss 1.7878e-02, test_loss 7.2783e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 370, train_loss 1.7854e-02, test_loss 7.2808e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 371, train_loss 1.7830e-02, test_loss 7.2833e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 372, train_loss 1.7806e-02, test_loss 7.2859e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 373, train_loss 1.7783e-02, test_loss 7.2884e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 374, train_loss 1.7760e-02, test_loss 7.2909e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 375, train_loss 1.7737e-02, test_loss 7.2934e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 376, train_loss 1.7714e-02, test_loss 7.2959e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 377, train_loss 1.7692e-02, test_loss 7.2984e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 378, train_loss 1.7669e-02, test_loss 7.3009e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 379, train_loss 1.7647e-02, test_loss 7.3034e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 380, train_loss 1.7625e-02, test_loss 7.3058e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 381, train_loss 1.7604e-02, test_loss 7.3083e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 382, train_loss 1.7583e-02, test_loss 7.3107e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 383, train_loss 1.7561e-02, test_loss 7.3132e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 384, train_loss 1.7540e-02, test_loss 7.3156e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 385, train_loss 1.7520e-02, test_loss 7.3180e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 386, train_loss 1.7499e-02, test_loss 7.3204e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 387, train_loss 1.7479e-02, test_loss 7.3228e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 388, train_loss 1.7458e-02, test_loss 7.3251e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 389, train_loss 1.7438e-02, test_loss 7.3274e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 390, train_loss 1.7418e-02, test_loss 7.3298e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 391, train_loss 1.7399e-02, test_loss 7.3320e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 392, train_loss 1.7379e-02, test_loss 7.3343e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 393, train_loss 1.7360e-02, test_loss 7.3366e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 394, train_loss 1.7340e-02, test_loss 7.3388e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 395, train_loss 1.7321e-02, test_loss 7.3410e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 396, train_loss 1.7302e-02, test_loss 7.3431e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 397, train_loss 1.7283e-02, test_loss 7.3453e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 398, train_loss 1.7264e-02, test_loss 7.3474e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 399, train_loss 1.7246e-02, test_loss 7.3495e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 400, train_loss 1.7227e-02, test_loss 7.3515e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 401, train_loss 1.7208e-02, test_loss 7.3536e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 402, train_loss 1.7190e-02, test_loss 7.3556e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 403, train_loss 1.7172e-02, test_loss 7.3575e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 404, train_loss 1.7153e-02, test_loss 7.3595e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 405, train_loss 1.7135e-02, test_loss 7.3614e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 406, train_loss 1.7117e-02, test_loss 7.3633e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 407, train_loss 1.7099e-02, test_loss 7.3651e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 408, train_loss 1.7081e-02, test_loss 7.3669e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 409, train_loss 1.7063e-02, test_loss 7.3687e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 410, train_loss 1.7045e-02, test_loss 7.3705e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 411, train_loss 1.7027e-02, test_loss 7.3722e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 412, train_loss 1.7009e-02, test_loss 7.3739e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 413, train_loss 1.6992e-02, test_loss 7.3755e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 414, train_loss 1.6974e-02, test_loss 7.3772e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 415, train_loss 1.6956e-02, test_loss 7.3788e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 416, train_loss 1.6938e-02, test_loss 7.3803e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 417, train_loss 1.6921e-02, test_loss 7.3819e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 418, train_loss 1.6903e-02, test_loss 7.3834e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 419, train_loss 1.6885e-02, test_loss 7.3849e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 420, train_loss 1.6868e-02, test_loss 7.3863e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 421, train_loss 1.6850e-02, test_loss 7.3877e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 422, train_loss 1.6832e-02, test_loss 7.3891e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 423, train_loss 1.6815e-02, test_loss 7.3905e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 424, train_loss 1.6797e-02, test_loss 7.3918e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 425, train_loss 1.6780e-02, test_loss 7.3931e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 426, train_loss 1.6762e-02, test_loss 7.3944e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 427, train_loss 1.6744e-02, test_loss 7.3957e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 428, train_loss 1.6726e-02, test_loss 7.3969e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 429, train_loss 1.6709e-02, test_loss 7.3981e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 430, train_loss 1.6691e-02, test_loss 7.3993e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 431, train_loss 1.6673e-02, test_loss 7.4004e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 432, train_loss 1.6656e-02, test_loss 7.4016e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 433, train_loss 1.6638e-02, test_loss 7.4027e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 434, train_loss 1.6620e-02, test_loss 7.4038e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 435, train_loss 1.6602e-02, test_loss 7.4049e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 436, train_loss 1.6584e-02, test_loss 7.4059e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 437, train_loss 1.6566e-02, test_loss 7.4070e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 438, train_loss 1.6548e-02, test_loss 7.4080e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 439, train_loss 1.6530e-02, test_loss 7.4090e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 440, train_loss 1.6512e-02, test_loss 7.4100e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 441, train_loss 1.6494e-02, test_loss 7.4109e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 442, train_loss 1.6476e-02, test_loss 7.4119e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 443, train_loss 1.6458e-02, test_loss 7.4129e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 444, train_loss 1.6440e-02, test_loss 7.4138e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 445, train_loss 1.6422e-02, test_loss 7.4147e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 446, train_loss 1.6404e-02, test_loss 7.4156e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 447, train_loss 1.6386e-02, test_loss 7.4166e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 448, train_loss 1.6367e-02, test_loss 7.4175e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 449, train_loss 1.6349e-02, test_loss 7.4184e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 450, train_loss 1.6331e-02, test_loss 7.4193e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 451, train_loss 1.6313e-02, test_loss 7.4202e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 452, train_loss 1.6294e-02, test_loss 7.4211e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 453, train_loss 1.6276e-02, test_loss 7.4220e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 454, train_loss 1.6258e-02, test_loss 7.4228e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 455, train_loss 1.6239e-02, test_loss 7.4237e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 456, train_loss 1.6221e-02, test_loss 7.4246e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 457, train_loss 1.6202e-02, test_loss 7.4255e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 458, train_loss 1.6184e-02, test_loss 7.4264e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 459, train_loss 1.6166e-02, test_loss 7.4274e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 460, train_loss 1.6147e-02, test_loss 7.4283e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 461, train_loss 1.6129e-02, test_loss 7.4292e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 462, train_loss 1.6110e-02, test_loss 7.4301e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 463, train_loss 1.6092e-02, test_loss 7.4311e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 464, train_loss 1.6073e-02, test_loss 7.4320e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 465, train_loss 1.6054e-02, test_loss 7.4330e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 466, train_loss 1.6036e-02, test_loss 7.4339e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 467, train_loss 1.6017e-02, test_loss 7.4349e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 468, train_loss 1.5999e-02, test_loss 7.4359e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 469, train_loss 1.5980e-02, test_loss 7.4369e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 470, train_loss 1.5962e-02, test_loss 7.4379e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 471, train_loss 1.5943e-02, test_loss 7.4389e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 472, train_loss 1.5924e-02, test_loss 7.4399e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 473, train_loss 1.5906e-02, test_loss 7.4410e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 474, train_loss 1.5887e-02, test_loss 7.4420e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 475, train_loss 1.5869e-02, test_loss 7.4431e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 476, train_loss 1.5850e-02, test_loss 7.4442e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 477, train_loss 1.5831e-02, test_loss 7.4453e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 478, train_loss 1.5813e-02, test_loss 7.4464e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 479, train_loss 1.5794e-02, test_loss 7.4475e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 480, train_loss 1.5776e-02, test_loss 7.4486e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 481, train_loss 1.5757e-02, test_loss 7.4497e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 482, train_loss 1.5738e-02, test_loss 7.4509e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 483, train_loss 1.5720e-02, test_loss 7.4520e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 484, train_loss 1.5701e-02, test_loss 7.4532e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 485, train_loss 1.5682e-02, test_loss 7.4543e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 486, train_loss 1.5664e-02, test_loss 7.4555e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 487, train_loss 1.5645e-02, test_loss 7.4567e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 488, train_loss 1.5627e-02, test_loss 7.4579e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 489, train_loss 1.5608e-02, test_loss 7.4591e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 490, train_loss 1.5590e-02, test_loss 7.4603e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 491, train_loss 1.5571e-02, test_loss 7.4615e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 492, train_loss 1.5553e-02, test_loss 7.4628e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 493, train_loss 1.5534e-02, test_loss 7.4640e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 494, train_loss 1.5516e-02, test_loss 7.4652e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 495, train_loss 1.5497e-02, test_loss 7.4665e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 496, train_loss 1.5479e-02, test_loss 7.4677e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 497, train_loss 1.5460e-02, test_loss 7.4690e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 498, train_loss 1.5442e-02, test_loss 7.4702e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 499, train_loss 1.5423e-02, test_loss 7.4715e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 500, train_loss 1.5405e-02, test_loss 7.4728e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 501, train_loss 1.5386e-02, test_loss 7.4741e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 502, train_loss 1.5368e-02, test_loss 7.4754e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 503, train_loss 1.5350e-02, test_loss 7.4767e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 504, train_loss 1.5331e-02, test_loss 7.4780e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 505, train_loss 1.5313e-02, test_loss 7.4793e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 506, train_loss 1.5295e-02, test_loss 7.4806e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 507, train_loss 1.5276e-02, test_loss 7.4819e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 508, train_loss 1.5258e-02, test_loss 7.4832e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 509, train_loss 1.5240e-02, test_loss 7.4845e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 510, train_loss 1.5222e-02, test_loss 7.4859e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 511, train_loss 1.5203e-02, test_loss 7.4872e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 512, train_loss 1.5185e-02, test_loss 7.4886e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 513, train_loss 1.5167e-02, test_loss 7.4899e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 514, train_loss 1.5149e-02, test_loss 7.4913e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 515, train_loss 1.5130e-02, test_loss 7.4927e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 516, train_loss 1.5112e-02, test_loss 7.4940e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 517, train_loss 1.5094e-02, test_loss 7.4954e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 518, train_loss 1.5076e-02, test_loss 7.4968e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 519, train_loss 1.5058e-02, test_loss 7.4982e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 520, train_loss 1.5040e-02, test_loss 7.4996e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 521, train_loss 1.5021e-02, test_loss 7.5010e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 522, train_loss 1.5003e-02, test_loss 7.5025e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 523, train_loss 1.4985e-02, test_loss 7.5039e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 524, train_loss 1.4967e-02, test_loss 7.5053e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 525, train_loss 1.4949e-02, test_loss 7.5068e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 526, train_loss 1.4930e-02, test_loss 7.5082e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 527, train_loss 1.4912e-02, test_loss 7.5097e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 528, train_loss 1.4894e-02, test_loss 7.5112e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 529, train_loss 1.4876e-02, test_loss 7.5126e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 530, train_loss 1.4857e-02, test_loss 7.5141e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 531, train_loss 1.4839e-02, test_loss 7.5156e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 532, train_loss 1.4821e-02, test_loss 7.5171e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 533, train_loss 1.4802e-02, test_loss 7.5186e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 534, train_loss 1.4784e-02, test_loss 7.5201e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 535, train_loss 1.4766e-02, test_loss 7.5216e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 536, train_loss 1.4747e-02, test_loss 7.5232e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 537, train_loss 1.4729e-02, test_loss 7.5247e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 538, train_loss 1.4710e-02, test_loss 7.5262e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 539, train_loss 1.4692e-02, test_loss 7.5278e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 540, train_loss 1.4673e-02, test_loss 7.5293e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 541, train_loss 1.4654e-02, test_loss 7.5309e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 542, train_loss 1.4635e-02, test_loss 7.5324e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 543, train_loss 1.4617e-02, test_loss 7.5340e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 544, train_loss 1.4598e-02, test_loss 7.5356e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 545, train_loss 1.4579e-02, test_loss 7.5372e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 546, train_loss 1.4560e-02, test_loss 7.5387e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 547, train_loss 1.4540e-02, test_loss 7.5403e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 548, train_loss 1.4521e-02, test_loss 7.5419e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 549, train_loss 1.4502e-02, test_loss 7.5435e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 550, train_loss 1.4483e-02, test_loss 7.5451e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 551, train_loss 1.4463e-02, test_loss 7.5467e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 552, train_loss 1.4444e-02, test_loss 7.5483e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 553, train_loss 1.4424e-02, test_loss 7.5499e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 554, train_loss 1.4404e-02, test_loss 7.5516e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 555, train_loss 1.4384e-02, test_loss 7.5532e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 556, train_loss 1.4364e-02, test_loss 7.5548e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 557, train_loss 1.4344e-02, test_loss 7.5565e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 558, train_loss 1.4324e-02, test_loss 7.5581e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 559, train_loss 1.4304e-02, test_loss 7.5598e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 560, train_loss 1.4284e-02, test_loss 7.5614e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 561, train_loss 1.4263e-02, test_loss 7.5631e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 562, train_loss 1.4243e-02, test_loss 7.5647e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 563, train_loss 1.4222e-02, test_loss 7.5664e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 564, train_loss 1.4201e-02, test_loss 7.5681e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 565, train_loss 1.4180e-02, test_loss 7.5698e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 566, train_loss 1.4159e-02, test_loss 7.5715e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 567, train_loss 1.4138e-02, test_loss 7.5732e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 568, train_loss 1.4117e-02, test_loss 7.5749e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 569, train_loss 1.4096e-02, test_loss 7.5767e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 570, train_loss 1.4074e-02, test_loss 7.5784e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 571, train_loss 1.4053e-02, test_loss 7.5802e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 572, train_loss 1.4031e-02, test_loss 7.5819e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 573, train_loss 1.4009e-02, test_loss 7.5837e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 574, train_loss 1.3987e-02, test_loss 7.5855e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 575, train_loss 1.3965e-02, test_loss 7.5873e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 576, train_loss 1.3943e-02, test_loss 7.5892e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 577, train_loss 1.3921e-02, test_loss 7.5910e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 578, train_loss 1.3899e-02, test_loss 7.5929e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 579, train_loss 1.3877e-02, test_loss 7.5947e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 580, train_loss 1.3854e-02, test_loss 7.5966e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 581, train_loss 1.3831e-02, test_loss 7.5985e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 582, train_loss 1.3809e-02, test_loss 7.6005e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 583, train_loss 1.3786e-02, test_loss 7.6024e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 584, train_loss 1.3763e-02, test_loss 7.6044e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 585, train_loss 1.3740e-02, test_loss 7.6064e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 586, train_loss 1.3717e-02, test_loss 7.6084e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 587, train_loss 1.3693e-02, test_loss 7.6104e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 588, train_loss 1.3670e-02, test_loss 7.6124e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 589, train_loss 1.3646e-02, test_loss 7.6145e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 590, train_loss 1.3623e-02, test_loss 7.6166e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 591, train_loss 1.3599e-02, test_loss 7.6187e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 592, train_loss 1.3575e-02, test_loss 7.6208e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 593, train_loss 1.3551e-02, test_loss 7.6229e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 594, train_loss 1.3527e-02, test_loss 7.6251e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 595, train_loss 1.3502e-02, test_loss 7.6272e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 596, train_loss 1.3478e-02, test_loss 7.6294e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 597, train_loss 1.3453e-02, test_loss 7.6316e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 598, train_loss 1.3428e-02, test_loss 7.6338e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 599, train_loss 1.3403e-02, test_loss 7.6361e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 600, train_loss 1.3378e-02, test_loss 7.6383e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 601, train_loss 1.3352e-02, test_loss 7.6406e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 602, train_loss 1.3326e-02, test_loss 7.6429e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 603, train_loss 1.3301e-02, test_loss 7.6452e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 604, train_loss 1.3275e-02, test_loss 7.6476e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 605, train_loss 1.3248e-02, test_loss 7.6499e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 606, train_loss 1.3222e-02, test_loss 7.6523e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 607, train_loss 1.3195e-02, test_loss 7.6547e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 608, train_loss 1.3169e-02, test_loss 7.6571e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 609, train_loss 1.3142e-02, test_loss 7.6596e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 610, train_loss 1.3114e-02, test_loss 7.6621e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 611, train_loss 1.3087e-02, test_loss 7.6646e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 612, train_loss 1.3059e-02, test_loss 7.6672e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 613, train_loss 1.3031e-02, test_loss 7.6698e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 614, train_loss 1.3003e-02, test_loss 7.6724e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 615, train_loss 1.2975e-02, test_loss 7.6750e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 616, train_loss 1.2946e-02, test_loss 7.6777e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 617, train_loss 1.2917e-02, test_loss 7.6804e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 618, train_loss 1.2888e-02, test_loss 7.6832e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 619, train_loss 1.2859e-02, test_loss 7.6860e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 620, train_loss 1.2829e-02, test_loss 7.6888e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 621, train_loss 1.2799e-02, test_loss 7.6917e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 622, train_loss 1.2769e-02, test_loss 7.6946e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 623, train_loss 1.2739e-02, test_loss 7.6976e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 624, train_loss 1.2708e-02, test_loss 7.7006e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 625, train_loss 1.2677e-02, test_loss 7.7037e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 626, train_loss 1.2646e-02, test_loss 7.7068e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 627, train_loss 1.2615e-02, test_loss 7.7100e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 628, train_loss 1.2583e-02, test_loss 7.7132e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 629, train_loss 1.2551e-02, test_loss 7.7165e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 630, train_loss 1.2519e-02, test_loss 7.7198e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 631, train_loss 1.2486e-02, test_loss 7.7232e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 632, train_loss 1.2454e-02, test_loss 7.7267e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 633, train_loss 1.2421e-02, test_loss 7.7302e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 634, train_loss 1.2387e-02, test_loss 7.7337e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 635, train_loss 1.2354e-02, test_loss 7.7373e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 636, train_loss 1.2320e-02, test_loss 7.7410e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 637, train_loss 1.2286e-02, test_loss 7.7447e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 638, train_loss 1.2252e-02, test_loss 7.7485e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 639, train_loss 1.2218e-02, test_loss 7.7524e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 640, train_loss 1.2183e-02, test_loss 7.7563e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 641, train_loss 1.2149e-02, test_loss 7.7602e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 642, train_loss 1.2114e-02, test_loss 7.7643e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 643, train_loss 1.2079e-02, test_loss 7.7683e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 644, train_loss 1.2043e-02, test_loss 7.7725e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 645, train_loss 1.2008e-02, test_loss 7.7767e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 646, train_loss 1.1972e-02, test_loss 7.7809e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 647, train_loss 1.1936e-02, test_loss 7.7852e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 648, train_loss 1.1900e-02, test_loss 7.7896e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 649, train_loss 1.1864e-02, test_loss 7.7940e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 650, train_loss 1.1828e-02, test_loss 7.7985e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 651, train_loss 1.1792e-02, test_loss 7.8030e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 652, train_loss 1.1756e-02, test_loss 7.8076e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 653, train_loss 1.1719e-02, test_loss 7.8122e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 654, train_loss 1.1683e-02, test_loss 7.8169e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 655, train_loss 1.1646e-02, test_loss 7.8217e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 656, train_loss 1.1610e-02, test_loss 7.8264e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 657, train_loss 1.1574e-02, test_loss 7.8313e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 658, train_loss 1.1537e-02, test_loss 7.8361e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 659, train_loss 1.1501e-02, test_loss 7.8411e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 660, train_loss 1.1464e-02, test_loss 7.8460e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 661, train_loss 1.1428e-02, test_loss 7.8510e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 662, train_loss 1.1392e-02, test_loss 7.8561e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 663, train_loss 1.1356e-02, test_loss 7.8611e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 664, train_loss 1.1320e-02, test_loss 7.8663e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 665, train_loss 1.1284e-02, test_loss 7.8714e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 666, train_loss 1.1249e-02, test_loss 7.8766e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 667, train_loss 1.1213e-02, test_loss 7.8818e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 668, train_loss 1.1178e-02, test_loss 7.8870e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 669, train_loss 1.1143e-02, test_loss 7.8923e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 670, train_loss 1.1108e-02, test_loss 7.8976e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 671, train_loss 1.1074e-02, test_loss 7.9029e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 672, train_loss 1.1039e-02, test_loss 7.9082e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 673, train_loss 1.1005e-02, test_loss 7.9135e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 674, train_loss 1.0971e-02, test_loss 7.9189e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 675, train_loss 1.0938e-02, test_loss 7.9243e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 676, train_loss 1.0905e-02, test_loss 7.9296e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 677, train_loss 1.0872e-02, test_loss 7.9350e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 678, train_loss 1.0839e-02, test_loss 7.9404e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 679, train_loss 1.0807e-02, test_loss 7.9458e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 680, train_loss 1.0775e-02, test_loss 7.9512e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 681, train_loss 1.0744e-02, test_loss 7.9565e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 682, train_loss 1.0713e-02, test_loss 7.9619e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 683, train_loss 1.0682e-02, test_loss 7.9673e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 684, train_loss 1.0652e-02, test_loss 7.9726e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 685, train_loss 1.0622e-02, test_loss 7.9780e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 686, train_loss 1.0592e-02, test_loss 7.9833e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 687, train_loss 1.0563e-02, test_loss 7.9886e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 688, train_loss 1.0534e-02, test_loss 7.9938e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 689, train_loss 1.0505e-02, test_loss 7.9991e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 690, train_loss 1.0477e-02, test_loss 8.0043e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 691, train_loss 1.0450e-02, test_loss 8.0095e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 692, train_loss 1.0422e-02, test_loss 8.0146e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 693, train_loss 1.0395e-02, test_loss 8.0198e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 694, train_loss 1.0369e-02, test_loss 8.0249e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 695, train_loss 1.0343e-02, test_loss 8.0299e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 696, train_loss 1.0317e-02, test_loss 8.0349e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 697, train_loss 1.0291e-02, test_loss 8.0399e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 698, train_loss 1.0266e-02, test_loss 8.0448e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 699, train_loss 1.0241e-02, test_loss 8.0496e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 700, train_loss 1.0217e-02, test_loss 8.0545e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 701, train_loss 1.0193e-02, test_loss 8.0592e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 702, train_loss 1.0169e-02, test_loss 8.0639e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 703, train_loss 1.0146e-02, test_loss 8.0686e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 704, train_loss 1.0123e-02, test_loss 8.0732e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 705, train_loss 1.0100e-02, test_loss 8.0777e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 706, train_loss 1.0078e-02, test_loss 8.0822e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 707, train_loss 1.0056e-02, test_loss 8.0867e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 708, train_loss 1.0034e-02, test_loss 8.0910e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 709, train_loss 1.0012e-02, test_loss 8.0953e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 710, train_loss 9.9910e-03, test_loss 8.0996e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 711, train_loss 9.9700e-03, test_loss 8.1038e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 712, train_loss 9.9493e-03, test_loss 8.1079e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 713, train_loss 9.9288e-03, test_loss 8.1120e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 714, train_loss 9.9086e-03, test_loss 8.1160e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 715, train_loss 9.8886e-03, test_loss 8.1199e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 716, train_loss 9.8689e-03, test_loss 8.1238e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 717, train_loss 9.8494e-03, test_loss 8.1276e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 718, train_loss 9.8301e-03, test_loss 8.1313e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 719, train_loss 9.8110e-03, test_loss 8.1350e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 720, train_loss 9.7922e-03, test_loss 8.1386e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 721, train_loss 9.7735e-03, test_loss 8.1421e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 722, train_loss 9.7550e-03, test_loss 8.1456e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 723, train_loss 9.7368e-03, test_loss 8.1490e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 724, train_loss 9.7186e-03, test_loss 8.1524e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 725, train_loss 9.7007e-03, test_loss 8.1557e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 726, train_loss 9.6830e-03, test_loss 8.1589e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 727, train_loss 9.6654e-03, test_loss 8.1621e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 728, train_loss 9.6479e-03, test_loss 8.1652e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 729, train_loss 9.6307e-03, test_loss 8.1682e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 730, train_loss 9.6136e-03, test_loss 8.1712e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 731, train_loss 9.5966e-03, test_loss 8.1741e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 732, train_loss 9.5798e-03, test_loss 8.1770e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 733, train_loss 9.5631e-03, test_loss 8.1798e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 734, train_loss 9.5465e-03, test_loss 8.1825e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 735, train_loss 9.5301e-03, test_loss 8.1852e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 736, train_loss 9.5138e-03, test_loss 8.1879e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 737, train_loss 9.4977e-03, test_loss 8.1905e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 738, train_loss 9.4816e-03, test_loss 8.1930e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 739, train_loss 9.4657e-03, test_loss 8.1955e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 740, train_loss 9.4499e-03, test_loss 8.1979e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 741, train_loss 9.4342e-03, test_loss 8.2003e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 742, train_loss 9.4186e-03, test_loss 8.2026e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 743, train_loss 9.4032e-03, test_loss 8.2049e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 744, train_loss 9.3878e-03, test_loss 8.2071e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 745, train_loss 9.3725e-03, test_loss 8.2093e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 746, train_loss 9.3574e-03, test_loss 8.2115e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 747, train_loss 9.3423e-03, test_loss 8.2135e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 748, train_loss 9.3273e-03, test_loss 8.2156e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 749, train_loss 9.3125e-03, test_loss 8.2176e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 750, train_loss 9.2977e-03, test_loss 8.2195e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 751, train_loss 9.2830e-03, test_loss 8.2215e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 752, train_loss 9.2684e-03, test_loss 8.2233e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 753, train_loss 9.2539e-03, test_loss 8.2252e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 754, train_loss 9.2395e-03, test_loss 8.2269e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 755, train_loss 9.2252e-03, test_loss 8.2287e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 756, train_loss 9.2109e-03, test_loss 8.2304e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 757, train_loss 9.1968e-03, test_loss 8.2321e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 758, train_loss 9.1827e-03, test_loss 8.2337e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 759, train_loss 9.1687e-03, test_loss 8.2353e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 760, train_loss 9.1548e-03, test_loss 8.2368e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 761, train_loss 9.1409e-03, test_loss 8.2383e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 762, train_loss 9.1271e-03, test_loss 8.2398e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 763, train_loss 9.1134e-03, test_loss 8.2412e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 764, train_loss 9.0997e-03, test_loss 8.2427e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 765, train_loss 9.0862e-03, test_loss 8.2440e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 766, train_loss 9.0727e-03, test_loss 8.2454e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 767, train_loss 9.0592e-03, test_loss 8.2467e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 768, train_loss 9.0459e-03, test_loss 8.2479e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 769, train_loss 9.0326e-03, test_loss 8.2491e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 770, train_loss 9.0193e-03, test_loss 8.2503e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 771, train_loss 9.0062e-03, test_loss 8.2515e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 772, train_loss 8.9930e-03, test_loss 8.2526e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 773, train_loss 8.9800e-03, test_loss 8.2537e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 774, train_loss 8.9670e-03, test_loss 8.2548e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 775, train_loss 8.9541e-03, test_loss 8.2558e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 776, train_loss 8.9412e-03, test_loss 8.2569e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 777, train_loss 8.9283e-03, test_loss 8.2578e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 778, train_loss 8.9156e-03, test_loss 8.2588e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 779, train_loss 8.9028e-03, test_loss 8.2597e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 780, train_loss 8.8902e-03, test_loss 8.2606e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 781, train_loss 8.8775e-03, test_loss 8.2614e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 782, train_loss 8.8650e-03, test_loss 8.2623e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 783, train_loss 8.8524e-03, test_loss 8.2631e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 784, train_loss 8.8400e-03, test_loss 8.2638e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 785, train_loss 8.8275e-03, test_loss 8.2646e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 786, train_loss 8.8151e-03, test_loss 8.2653e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 787, train_loss 8.8028e-03, test_loss 8.2660e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 788, train_loss 8.7905e-03, test_loss 8.2666e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 789, train_loss 8.7783e-03, test_loss 8.2673e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 790, train_loss 8.7660e-03, test_loss 8.2679e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 791, train_loss 8.7539e-03, test_loss 8.2685e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 792, train_loss 8.7417e-03, test_loss 8.2690e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 793, train_loss 8.7296e-03, test_loss 8.2696e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 794, train_loss 8.7176e-03, test_loss 8.2701e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 795, train_loss 8.7055e-03, test_loss 8.2705e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 796, train_loss 8.6936e-03, test_loss 8.2710e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 797, train_loss 8.6816e-03, test_loss 8.2714e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 798, train_loss 8.6697e-03, test_loss 8.2718e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 799, train_loss 8.6578e-03, test_loss 8.2722e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 800, train_loss 8.6459e-03, test_loss 8.2726e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 801, train_loss 8.6341e-03, test_loss 8.2729e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 802, train_loss 8.6223e-03, test_loss 8.2732e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 803, train_loss 8.6105e-03, test_loss 8.2735e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 804, train_loss 8.5988e-03, test_loss 8.2737e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 805, train_loss 8.5871e-03, test_loss 8.2740e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 806, train_loss 8.5754e-03, test_loss 8.2742e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 807, train_loss 8.5638e-03, test_loss 8.2744e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 808, train_loss 8.5521e-03, test_loss 8.2745e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 809, train_loss 8.5405e-03, test_loss 8.2747e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 810, train_loss 8.5289e-03, test_loss 8.2748e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 811, train_loss 8.5174e-03, test_loss 8.2749e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 812, train_loss 8.5059e-03, test_loss 8.2750e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 813, train_loss 8.4943e-03, test_loss 8.2751e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 814, train_loss 8.4828e-03, test_loss 8.2751e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 815, train_loss 8.4714e-03, test_loss 8.2751e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 816, train_loss 8.4599e-03, test_loss 8.2751e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 817, train_loss 8.4485e-03, test_loss 8.2751e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 818, train_loss 8.4371e-03, test_loss 8.2751e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 819, train_loss 8.4257e-03, test_loss 8.2750e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 820, train_loss 8.4143e-03, test_loss 8.2750e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 821, train_loss 8.4029e-03, test_loss 8.2749e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 822, train_loss 8.3916e-03, test_loss 8.2747e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 823, train_loss 8.3802e-03, test_loss 8.2746e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 824, train_loss 8.3689e-03, test_loss 8.2745e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 825, train_loss 8.3576e-03, test_loss 8.2743e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 826, train_loss 8.3463e-03, test_loss 8.2741e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 827, train_loss 8.3350e-03, test_loss 8.2739e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 828, train_loss 8.3238e-03, test_loss 8.2737e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 829, train_loss 8.3125e-03, test_loss 8.2735e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 830, train_loss 8.3012e-03, test_loss 8.2732e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 831, train_loss 8.2900e-03, test_loss 8.2729e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 832, train_loss 8.2788e-03, test_loss 8.2726e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 833, train_loss 8.2676e-03, test_loss 8.2723e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 834, train_loss 8.2564e-03, test_loss 8.2720e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 835, train_loss 8.2452e-03, test_loss 8.2717e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 836, train_loss 8.2340e-03, test_loss 8.2713e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 837, train_loss 8.2228e-03, test_loss 8.2710e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 838, train_loss 8.2116e-03, test_loss 8.2706e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 839, train_loss 8.2004e-03, test_loss 8.2702e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 840, train_loss 8.1893e-03, test_loss 8.2698e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 841, train_loss 8.1781e-03, test_loss 8.2694e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 842, train_loss 8.1670e-03, test_loss 8.2690e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 843, train_loss 8.1558e-03, test_loss 8.2685e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 844, train_loss 8.1447e-03, test_loss 8.2681e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 845, train_loss 8.1336e-03, test_loss 8.2676e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 846, train_loss 8.1224e-03, test_loss 8.2671e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 847, train_loss 8.1113e-03, test_loss 8.2666e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 848, train_loss 8.1002e-03, test_loss 8.2661e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 849, train_loss 8.0890e-03, test_loss 8.2656e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 850, train_loss 8.0779e-03, test_loss 8.2650e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 851, train_loss 8.0668e-03, test_loss 8.2645e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 852, train_loss 8.0557e-03, test_loss 8.2639e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 853, train_loss 8.0445e-03, test_loss 8.2634e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 854, train_loss 8.0334e-03, test_loss 8.2628e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 855, train_loss 8.0223e-03, test_loss 8.2622e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 856, train_loss 8.0112e-03, test_loss 8.2616e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 857, train_loss 8.0001e-03, test_loss 8.2610e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 858, train_loss 7.9890e-03, test_loss 8.2603e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 859, train_loss 7.9778e-03, test_loss 8.2597e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 860, train_loss 7.9667e-03, test_loss 8.2590e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 861, train_loss 7.9556e-03, test_loss 8.2584e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 862, train_loss 7.9445e-03, test_loss 8.2577e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 863, train_loss 7.9333e-03, test_loss 8.2570e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 864, train_loss 7.9222e-03, test_loss 8.2563e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 865, train_loss 7.9111e-03, test_loss 8.2556e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 866, train_loss 7.8999e-03, test_loss 8.2549e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 867, train_loss 7.8888e-03, test_loss 8.2542e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 868, train_loss 7.8776e-03, test_loss 8.2534e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 869, train_loss 7.8665e-03, test_loss 8.2527e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 870, train_loss 7.8554e-03, test_loss 8.2519e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 871, train_loss 7.8442e-03, test_loss 8.2511e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 872, train_loss 7.8331e-03, test_loss 8.2503e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 873, train_loss 7.8219e-03, test_loss 8.2496e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 874, train_loss 7.8108e-03, test_loss 8.2487e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 875, train_loss 7.7996e-03, test_loss 8.2479e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 876, train_loss 7.7884e-03, test_loss 8.2471e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 877, train_loss 7.7772e-03, test_loss 8.2463e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 878, train_loss 7.7660e-03, test_loss 8.2454e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 879, train_loss 7.7548e-03, test_loss 8.2445e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 880, train_loss 7.7437e-03, test_loss 8.2437e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 881, train_loss 7.7325e-03, test_loss 8.2428e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 882, train_loss 7.7212e-03, test_loss 8.2419e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 883, train_loss 7.7100e-03, test_loss 8.2410e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 884, train_loss 7.6988e-03, test_loss 8.2401e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 885, train_loss 7.6876e-03, test_loss 8.2391e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 886, train_loss 7.6764e-03, test_loss 8.2382e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 887, train_loss 7.6651e-03, test_loss 8.2372e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 888, train_loss 7.6539e-03, test_loss 8.2363e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 889, train_loss 7.6427e-03, test_loss 8.2353e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 890, train_loss 7.6314e-03, test_loss 8.2343e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 891, train_loss 7.6202e-03, test_loss 8.2333e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 892, train_loss 7.6089e-03, test_loss 8.2322e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 893, train_loss 7.5976e-03, test_loss 8.2312e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 894, train_loss 7.5864e-03, test_loss 8.2302e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 895, train_loss 7.5751e-03, test_loss 8.2291e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 896, train_loss 7.5638e-03, test_loss 8.2280e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 897, train_loss 7.5525e-03, test_loss 8.2269e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 898, train_loss 7.5412e-03, test_loss 8.2258e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 899, train_loss 7.5299e-03, test_loss 8.2247e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 900, train_loss 7.5186e-03, test_loss 8.2236e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 901, train_loss 7.5073e-03, test_loss 8.2225e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 902, train_loss 7.4959e-03, test_loss 8.2213e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 903, train_loss 7.4846e-03, test_loss 8.2201e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 904, train_loss 7.4733e-03, test_loss 8.2189e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 905, train_loss 7.4619e-03, test_loss 8.2177e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 906, train_loss 7.4506e-03, test_loss 8.2165e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 907, train_loss 7.4392e-03, test_loss 8.2153e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 908, train_loss 7.4279e-03, test_loss 8.2140e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 909, train_loss 7.4165e-03, test_loss 8.2128e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 910, train_loss 7.4052e-03, test_loss 8.2115e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 911, train_loss 7.3938e-03, test_loss 8.2102e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 912, train_loss 7.3824e-03, test_loss 8.2089e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 913, train_loss 7.3710e-03, test_loss 8.2076e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 914, train_loss 7.3596e-03, test_loss 8.2062e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 915, train_loss 7.3483e-03, test_loss 8.2049e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 916, train_loss 7.3368e-03, test_loss 8.2035e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 917, train_loss 7.3255e-03, test_loss 8.2021e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 918, train_loss 7.3140e-03, test_loss 8.2007e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 919, train_loss 7.3026e-03, test_loss 8.1993e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 920, train_loss 7.2912e-03, test_loss 8.1978e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 921, train_loss 7.2798e-03, test_loss 8.1964e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 922, train_loss 7.2684e-03, test_loss 8.1949e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 923, train_loss 7.2569e-03, test_loss 8.1934e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 924, train_loss 7.2455e-03, test_loss 8.1919e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 925, train_loss 7.2341e-03, test_loss 8.1904e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 926, train_loss 7.2226e-03, test_loss 8.1888e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 927, train_loss 7.2112e-03, test_loss 8.1873e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 928, train_loss 7.1997e-03, test_loss 8.1857e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 929, train_loss 7.1883e-03, test_loss 8.1841e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 930, train_loss 7.1768e-03, test_loss 8.1825e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 931, train_loss 7.1654e-03, test_loss 8.1809e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 932, train_loss 7.1539e-03, test_loss 8.1793e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 933, train_loss 7.1425e-03, test_loss 8.1776e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 934, train_loss 7.1310e-03, test_loss 8.1759e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 935, train_loss 7.1195e-03, test_loss 8.1743e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 936, train_loss 7.1081e-03, test_loss 8.1726e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 937, train_loss 7.0966e-03, test_loss 8.1708e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 938, train_loss 7.0851e-03, test_loss 8.1691e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 939, train_loss 7.0736e-03, test_loss 8.1674e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 940, train_loss 7.0622e-03, test_loss 8.1656e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 941, train_loss 7.0507e-03, test_loss 8.1638e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 942, train_loss 7.0392e-03, test_loss 8.1620e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 943, train_loss 7.0277e-03, test_loss 8.1602e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 944, train_loss 7.0162e-03, test_loss 8.1584e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 945, train_loss 7.0048e-03, test_loss 8.1566e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 946, train_loss 6.9933e-03, test_loss 8.1547e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 947, train_loss 6.9818e-03, test_loss 8.1528e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 948, train_loss 6.9703e-03, test_loss 8.1510e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 949, train_loss 6.9588e-03, test_loss 8.1491e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 950, train_loss 6.9473e-03, test_loss 8.1472e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 951, train_loss 6.9358e-03, test_loss 8.1452e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 952, train_loss 6.9243e-03, test_loss 8.1433e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 953, train_loss 6.9129e-03, test_loss 8.1414e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 954, train_loss 6.9014e-03, test_loss 8.1394e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 955, train_loss 6.8899e-03, test_loss 8.1374e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 956, train_loss 6.8784e-03, test_loss 8.1355e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 957, train_loss 6.8669e-03, test_loss 8.1335e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 958, train_loss 6.8555e-03, test_loss 8.1315e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 959, train_loss 6.8440e-03, test_loss 8.1295e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 960, train_loss 6.8325e-03, test_loss 8.1274e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 961, train_loss 6.8210e-03, test_loss 8.1254e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 962, train_loss 6.8095e-03, test_loss 8.1234e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 963, train_loss 6.7981e-03, test_loss 8.1213e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 964, train_loss 6.7866e-03, test_loss 8.1193e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 965, train_loss 6.7751e-03, test_loss 8.1172e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 966, train_loss 6.7637e-03, test_loss 8.1151e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 967, train_loss 6.7522e-03, test_loss 8.1130e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 968, train_loss 6.7408e-03, test_loss 8.1109e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 969, train_loss 6.7293e-03, test_loss 8.1088e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 970, train_loss 6.7179e-03, test_loss 8.1067e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 971, train_loss 6.7064e-03, test_loss 8.1046e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 972, train_loss 6.6950e-03, test_loss 8.1025e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 973, train_loss 6.6836e-03, test_loss 8.1003e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 974, train_loss 6.6722e-03, test_loss 8.0982e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 975, train_loss 6.6607e-03, test_loss 8.0961e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 976, train_loss 6.6493e-03, test_loss 8.0939e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 977, train_loss 6.6380e-03, test_loss 8.0917e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 978, train_loss 6.6266e-03, test_loss 8.0896e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 979, train_loss 6.6152e-03, test_loss 8.0874e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 980, train_loss 6.6038e-03, test_loss 8.0852e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 981, train_loss 6.5925e-03, test_loss 8.0831e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 982, train_loss 6.5811e-03, test_loss 8.0809e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 983, train_loss 6.5698e-03, test_loss 8.0787e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 984, train_loss 6.5584e-03, test_loss 8.0765e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 985, train_loss 6.5471e-03, test_loss 8.0743e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 986, train_loss 6.5358e-03, test_loss 8.0721e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 987, train_loss 6.5245e-03, test_loss 8.0699e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 988, train_loss 6.5132e-03, test_loss 8.0677e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 989, train_loss 6.5020e-03, test_loss 8.0655e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 990, train_loss 6.4907e-03, test_loss 8.0633e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 991, train_loss 6.4795e-03, test_loss 8.0611e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 992, train_loss 6.4682e-03, test_loss 8.0589e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 993, train_loss 6.4570e-03, test_loss 8.0567e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 994, train_loss 6.4459e-03, test_loss 8.0545e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 995, train_loss 6.4346e-03, test_loss 8.0523e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 996, train_loss 6.4235e-03, test_loss 8.0501e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 997, train_loss 6.4123e-03, test_loss 8.0479e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 998, train_loss 6.4012e-03, test_loss 8.0456e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 999, train_loss 6.3901e-03, test_loss 8.0434e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1000, train_loss 6.3790e-03, test_loss 8.0412e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1001, train_loss 6.3680e-03, test_loss 8.0390e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1002, train_loss 6.3569e-03, test_loss 8.0368e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1003, train_loss 6.3459e-03, test_loss 8.0346e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1004, train_loss 6.3349e-03, test_loss 8.0324e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1005, train_loss 6.3239e-03, test_loss 8.0302e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1006, train_loss 6.3129e-03, test_loss 8.0280e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1007, train_loss 6.3020e-03, test_loss 8.0258e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1008, train_loss 6.2910e-03, test_loss 8.0236e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1009, train_loss 6.2801e-03, test_loss 8.0214e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1010, train_loss 6.2693e-03, test_loss 8.0192e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1011, train_loss 6.2584e-03, test_loss 8.0170e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1012, train_loss 6.2476e-03, test_loss 8.0148e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1013, train_loss 6.2368e-03, test_loss 8.0126e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1014, train_loss 6.2260e-03, test_loss 8.0104e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1015, train_loss 6.2153e-03, test_loss 8.0082e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1016, train_loss 6.2046e-03, test_loss 8.0060e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1017, train_loss 6.1939e-03, test_loss 8.0039e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1018, train_loss 6.1832e-03, test_loss 8.0017e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1019, train_loss 6.1726e-03, test_loss 7.9995e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1020, train_loss 6.1620e-03, test_loss 7.9974e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1021, train_loss 6.1514e-03, test_loss 7.9952e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1022, train_loss 6.1408e-03, test_loss 7.9931e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1023, train_loss 6.1303e-03, test_loss 7.9909e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1024, train_loss 6.1198e-03, test_loss 7.9888e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1025, train_loss 6.1094e-03, test_loss 7.9867e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1026, train_loss 6.0990e-03, test_loss 7.9845e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1027, train_loss 6.0886e-03, test_loss 7.9824e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1028, train_loss 6.0782e-03, test_loss 7.9803e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1029, train_loss 6.0679e-03, test_loss 7.9782e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1030, train_loss 6.0576e-03, test_loss 7.9761e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1031, train_loss 6.0473e-03, test_loss 7.9740e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1032, train_loss 6.0371e-03, test_loss 7.9719e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1033, train_loss 6.0269e-03, test_loss 7.9698e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1034, train_loss 6.0167e-03, test_loss 7.9678e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1035, train_loss 6.0066e-03, test_loss 7.9657e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1036, train_loss 5.9965e-03, test_loss 7.9636e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1037, train_loss 5.9865e-03, test_loss 7.9616e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1038, train_loss 5.9765e-03, test_loss 7.9595e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1039, train_loss 5.9665e-03, test_loss 7.9575e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1040, train_loss 5.9565e-03, test_loss 7.9555e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1041, train_loss 5.9466e-03, test_loss 7.9535e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1042, train_loss 5.9367e-03, test_loss 7.9514e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1043, train_loss 5.9269e-03, test_loss 7.9494e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1044, train_loss 5.9171e-03, test_loss 7.9475e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1045, train_loss 5.9074e-03, test_loss 7.9455e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1046, train_loss 5.8976e-03, test_loss 7.9435e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1047, train_loss 5.8879e-03, test_loss 7.9415e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1048, train_loss 5.8783e-03, test_loss 7.9396e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1049, train_loss 5.8687e-03, test_loss 7.9376e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1050, train_loss 5.8591e-03, test_loss 7.9357e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1051, train_loss 5.8496e-03, test_loss 7.9338e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1052, train_loss 5.8401e-03, test_loss 7.9318e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1053, train_loss 5.8307e-03, test_loss 7.9299e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1054, train_loss 5.8213e-03, test_loss 7.9280e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1055, train_loss 5.8119e-03, test_loss 7.9261e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1056, train_loss 5.8025e-03, test_loss 7.9243e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1057, train_loss 5.7932e-03, test_loss 7.9224e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1058, train_loss 5.7840e-03, test_loss 7.9205e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1059, train_loss 5.7748e-03, test_loss 7.9187e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1060, train_loss 5.7656e-03, test_loss 7.9169e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1061, train_loss 5.7565e-03, test_loss 7.9150e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1062, train_loss 5.7474e-03, test_loss 7.9132e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1063, train_loss 5.7383e-03, test_loss 7.9114e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1064, train_loss 5.7293e-03, test_loss 7.9096e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1065, train_loss 5.7203e-03, test_loss 7.9078e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1066, train_loss 5.7114e-03, test_loss 7.9061e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1067, train_loss 5.7025e-03, test_loss 7.9043e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1068, train_loss 5.6937e-03, test_loss 7.9026e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1069, train_loss 5.6849e-03, test_loss 7.9008e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1070, train_loss 5.6761e-03, test_loss 7.8991e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1071, train_loss 5.6674e-03, test_loss 7.8974e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1072, train_loss 5.6587e-03, test_loss 7.8957e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1073, train_loss 5.6500e-03, test_loss 7.8940e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1074, train_loss 5.6414e-03, test_loss 7.8923e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1075, train_loss 5.6328e-03, test_loss 7.8907e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1076, train_loss 5.6243e-03, test_loss 7.8890e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1077, train_loss 5.6158e-03, test_loss 7.8874e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1078, train_loss 5.6074e-03, test_loss 7.8857e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1079, train_loss 5.5990e-03, test_loss 7.8841e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1080, train_loss 5.5906e-03, test_loss 7.8825e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1081, train_loss 5.5823e-03, test_loss 7.8809e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1082, train_loss 5.5740e-03, test_loss 7.8794e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1083, train_loss 5.5658e-03, test_loss 7.8778e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1084, train_loss 5.5576e-03, test_loss 7.8763e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1085, train_loss 5.5494e-03, test_loss 7.8747e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1086, train_loss 5.5413e-03, test_loss 7.8732e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1087, train_loss 5.5332e-03, test_loss 7.8717e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1088, train_loss 5.5251e-03, test_loss 7.8702e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1089, train_loss 5.5171e-03, test_loss 7.8687e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1090, train_loss 5.5092e-03, test_loss 7.8672e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1091, train_loss 5.5012e-03, test_loss 7.8658e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1092, train_loss 5.4934e-03, test_loss 7.8643e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1093, train_loss 5.4855e-03, test_loss 7.8629e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1094, train_loss 5.4777e-03, test_loss 7.8615e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1095, train_loss 5.4699e-03, test_loss 7.8601e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1096, train_loss 5.4622e-03, test_loss 7.8587e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1097, train_loss 5.4545e-03, test_loss 7.8573e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1098, train_loss 5.4468e-03, test_loss 7.8560e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1099, train_loss 5.4392e-03, test_loss 7.8546e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1100, train_loss 5.4316e-03, test_loss 7.8533e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1101, train_loss 5.4241e-03, test_loss 7.8520e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1102, train_loss 5.4166e-03, test_loss 7.8507e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1103, train_loss 5.4091e-03, test_loss 7.8494e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1104, train_loss 5.4017e-03, test_loss 7.8481e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1105, train_loss 5.3943e-03, test_loss 7.8469e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1106, train_loss 5.3869e-03, test_loss 7.8456e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1107, train_loss 5.3796e-03, test_loss 7.8444e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1108, train_loss 5.3723e-03, test_loss 7.8432e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1109, train_loss 5.3651e-03, test_loss 7.8420e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1110, train_loss 5.3579e-03, test_loss 7.8408e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1111, train_loss 5.3507e-03, test_loss 7.8397e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1112, train_loss 5.3436e-03, test_loss 7.8385e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1113, train_loss 5.3365e-03, test_loss 7.8374e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1114, train_loss 5.3294e-03, test_loss 7.8363e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1115, train_loss 5.3224e-03, test_loss 7.8352e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1116, train_loss 5.3154e-03, test_loss 7.8341e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1117, train_loss 5.3084e-03, test_loss 7.8330e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1118, train_loss 5.3015e-03, test_loss 7.8319e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1119, train_loss 5.2946e-03, test_loss 7.8309e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1120, train_loss 5.2877e-03, test_loss 7.8299e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1121, train_loss 5.2809e-03, test_loss 7.8289e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1122, train_loss 5.2741e-03, test_loss 7.8279e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1123, train_loss 5.2673e-03, test_loss 7.8269e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1124, train_loss 5.2606e-03, test_loss 7.8260e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1125, train_loss 5.2539e-03, test_loss 7.8250e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1126, train_loss 5.2473e-03, test_loss 7.8241e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1127, train_loss 5.2406e-03, test_loss 7.8232e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1128, train_loss 5.2340e-03, test_loss 7.8223e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1129, train_loss 5.2275e-03, test_loss 7.8214e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1130, train_loss 5.2210e-03, test_loss 7.8206e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1131, train_loss 5.2145e-03, test_loss 7.8197e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1132, train_loss 5.2080e-03, test_loss 7.8189e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1133, train_loss 5.2016e-03, test_loss 7.8181e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1134, train_loss 5.1952e-03, test_loss 7.8173e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1135, train_loss 5.1888e-03, test_loss 7.8165e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1136, train_loss 5.1825e-03, test_loss 7.8158e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1137, train_loss 5.1762e-03, test_loss 7.8150e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1138, train_loss 5.1699e-03, test_loss 7.8143e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1139, train_loss 5.1636e-03, test_loss 7.8136e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1140, train_loss 5.1574e-03, test_loss 7.8129e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1141, train_loss 5.1512e-03, test_loss 7.8123e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1142, train_loss 5.1451e-03, test_loss 7.8116e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1143, train_loss 5.1390e-03, test_loss 7.8110e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1144, train_loss 5.1329e-03, test_loss 7.8104e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1145, train_loss 5.1268e-03, test_loss 7.8098e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1146, train_loss 5.1208e-03, test_loss 7.8092e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1147, train_loss 5.1148e-03, test_loss 7.8087e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1148, train_loss 5.1088e-03, test_loss 7.8080e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1149, train_loss 5.1029e-03, test_loss 7.8076e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1150, train_loss 5.0970e-03, test_loss 7.8070e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1151, train_loss 5.0911e-03, test_loss 7.8067e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1152, train_loss 5.0853e-03, test_loss 7.8059e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1153, train_loss 5.0795e-03, test_loss 7.8060e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1154, train_loss 5.0738e-03, test_loss 7.8047e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1155, train_loss 5.0683e-03, test_loss 7.8057e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1156, train_loss 5.0633e-03, test_loss 7.8032e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1157, train_loss 5.0592e-03, test_loss 7.8061e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1158, train_loss 5.0575e-03, test_loss 7.8007e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1159, train_loss 5.0611e-03, test_loss 7.8083e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1160, train_loss 5.0759e-03, test_loss 7.7970e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1161, train_loss 5.1060e-03, test_loss 7.8115e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1162, train_loss 5.1380e-03, test_loss 7.7959e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1163, train_loss 5.1208e-03, test_loss 7.8066e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1164, train_loss 5.0508e-03, test_loss 7.8025e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1165, train_loss 5.0128e-03, test_loss 7.7974e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1166, train_loss 5.0440e-03, test_loss 7.8075e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1167, train_loss 5.0648e-03, test_loss 7.7976e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1168, train_loss 5.0237e-03, test_loss 7.8008e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1169, train_loss 4.9915e-03, test_loss 7.8046e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1170, train_loss 5.0120e-03, test_loss 7.7961e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1171, train_loss 5.0202e-03, test_loss 7.8025e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1172, train_loss 4.9873e-03, test_loss 7.8009e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1173, train_loss 4.9730e-03, test_loss 7.7959e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1174, train_loss 4.9891e-03, test_loss 7.8020e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1175, train_loss 4.9828e-03, test_loss 7.7973e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1176, train_loss 4.9578e-03, test_loss 7.7961e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1177, train_loss 4.9571e-03, test_loss 7.8009e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1178, train_loss 4.9647e-03, test_loss 7.7956e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1179, train_loss 4.9500e-03, test_loss 7.7972e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1180, train_loss 4.9360e-03, test_loss 7.7997e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1181, train_loss 4.9401e-03, test_loss 7.7951e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1182, train_loss 4.9381e-03, test_loss 7.7984e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1183, train_loss 4.9235e-03, test_loss 7.7985e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1184, train_loss 4.9182e-03, test_loss 7.7954e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1185, train_loss 4.9203e-03, test_loss 7.7989e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1186, train_loss 4.9127e-03, test_loss 7.7973e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1187, train_loss 4.9023e-03, test_loss 7.7963e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1188, train_loss 4.9007e-03, test_loss 7.7995e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1189, train_loss 4.8989e-03, test_loss 7.7970e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1190, train_loss 4.8901e-03, test_loss 7.7976e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1191, train_loss 4.8836e-03, test_loss 7.7995e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1192, train_loss 4.8822e-03, test_loss 7.7971e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1193, train_loss 4.8777e-03, test_loss 7.7989e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1194, train_loss 4.8699e-03, test_loss 7.7993e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1195, train_loss 4.8656e-03, test_loss 7.7978e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1196, train_loss 4.8632e-03, test_loss 7.8000e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1197, train_loss 4.8577e-03, test_loss 7.7993e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1198, train_loss 4.8513e-03, test_loss 7.7992e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1199, train_loss 4.8477e-03, test_loss 7.8010e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1200, train_loss 4.8444e-03, test_loss 7.7998e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1201, train_loss 4.8388e-03, test_loss 7.8007e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1202, train_loss 4.8334e-03, test_loss 7.8017e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1203, train_loss 4.8298e-03, test_loss 7.8007e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1204, train_loss 4.8260e-03, test_loss 7.8024e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1205, train_loss 4.8207e-03, test_loss 7.8024e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1206, train_loss 4.8159e-03, test_loss 7.8023e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1207, train_loss 4.8122e-03, test_loss 7.8039e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1208, train_loss 4.8082e-03, test_loss 7.8034e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1209, train_loss 4.8032e-03, test_loss 7.8042e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1210, train_loss 4.7987e-03, test_loss 7.8052e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1211, train_loss 4.7949e-03, test_loss 7.8046e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1212, train_loss 4.7908e-03, test_loss 7.8060e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1213, train_loss 4.7862e-03, test_loss 7.8062e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1214, train_loss 4.7818e-03, test_loss 7.8063e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1215, train_loss 4.7780e-03, test_loss 7.8077e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1216, train_loss 4.7739e-03, test_loss 7.8075e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1217, train_loss 4.7695e-03, test_loss 7.8084e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1218, train_loss 4.7652e-03, test_loss 7.8093e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1219, train_loss 4.7613e-03, test_loss 7.8093e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1220, train_loss 4.7574e-03, test_loss 7.8105e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1221, train_loss 4.7532e-03, test_loss 7.8109e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1222, train_loss 4.7490e-03, test_loss 7.8114e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1223, train_loss 4.7450e-03, test_loss 7.8126e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1224, train_loss 4.7411e-03, test_loss 7.8127e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1225, train_loss 4.7371e-03, test_loss 7.8138e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1226, train_loss 4.7330e-03, test_loss 7.8145e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1227, train_loss 4.7291e-03, test_loss 7.8149e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1228, train_loss 4.7252e-03, test_loss 7.8161e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1229, train_loss 4.7214e-03, test_loss 7.8164e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1230, train_loss 4.7174e-03, test_loss 7.8173e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1231, train_loss 4.7135e-03, test_loss 7.8182e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1232, train_loss 4.7096e-03, test_loss 7.8187e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1233, train_loss 4.7058e-03, test_loss 7.8199e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1234, train_loss 4.7020e-03, test_loss 7.8204e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1235, train_loss 4.6981e-03, test_loss 7.8213e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1236, train_loss 4.6943e-03, test_loss 7.8223e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1237, train_loss 4.6906e-03, test_loss 7.8228e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1238, train_loss 4.6869e-03, test_loss 7.8239e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1239, train_loss 4.6831e-03, test_loss 7.8246e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1240, train_loss 4.6793e-03, test_loss 7.8255e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1241, train_loss 4.6756e-03, test_loss 7.8265e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1242, train_loss 4.6720e-03, test_loss 7.8272e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1243, train_loss 4.6683e-03, test_loss 7.8283e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1244, train_loss 4.6646e-03, test_loss 7.8291e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1245, train_loss 4.6610e-03, test_loss 7.8300e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1246, train_loss 4.6573e-03, test_loss 7.8310e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1247, train_loss 4.6537e-03, test_loss 7.8318e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1248, train_loss 4.6501e-03, test_loss 7.8329e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1249, train_loss 4.6465e-03, test_loss 7.8337e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1250, train_loss 4.6430e-03, test_loss 7.8348e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1251, train_loss 4.6394e-03, test_loss 7.8358e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1252, train_loss 4.6359e-03, test_loss 7.8367e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1253, train_loss 4.6323e-03, test_loss 7.8378e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1254, train_loss 4.6288e-03, test_loss 7.8387e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1255, train_loss 4.6253e-03, test_loss 7.8398e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1256, train_loss 4.6219e-03, test_loss 7.8408e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1257, train_loss 4.6184e-03, test_loss 7.8417e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1258, train_loss 4.6149e-03, test_loss 7.8429e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1259, train_loss 4.6115e-03, test_loss 7.8438e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1260, train_loss 4.6081e-03, test_loss 7.8450e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1261, train_loss 4.6046e-03, test_loss 7.8459e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1262, train_loss 4.6012e-03, test_loss 7.8470e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1263, train_loss 4.5979e-03, test_loss 7.8481e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1264, train_loss 4.5945e-03, test_loss 7.8492e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1265, train_loss 4.5911e-03, test_loss 7.8503e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1266, train_loss 4.5878e-03, test_loss 7.8513e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1267, train_loss 4.5844e-03, test_loss 7.8525e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1268, train_loss 4.5811e-03, test_loss 7.8536e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1269, train_loss 4.5778e-03, test_loss 7.8547e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1270, train_loss 4.5745e-03, test_loss 7.8559e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1271, train_loss 4.5712e-03, test_loss 7.8570e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1272, train_loss 4.5679e-03, test_loss 7.8582e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1273, train_loss 4.5647e-03, test_loss 7.8593e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1274, train_loss 4.5614e-03, test_loss 7.8605e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1275, train_loss 4.5582e-03, test_loss 7.8616e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1276, train_loss 4.5550e-03, test_loss 7.8628e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1277, train_loss 4.5517e-03, test_loss 7.8640e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1278, train_loss 4.5485e-03, test_loss 7.8652e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1279, train_loss 4.5454e-03, test_loss 7.8664e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1280, train_loss 4.5422e-03, test_loss 7.8676e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1281, train_loss 4.5390e-03, test_loss 7.8688e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1282, train_loss 4.5358e-03, test_loss 7.8700e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1283, train_loss 4.5327e-03, test_loss 7.8712e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1284, train_loss 4.5296e-03, test_loss 7.8724e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1285, train_loss 4.5264e-03, test_loss 7.8737e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1286, train_loss 4.5233e-03, test_loss 7.8749e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1287, train_loss 4.5202e-03, test_loss 7.8762e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1288, train_loss 4.5171e-03, test_loss 7.8774e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1289, train_loss 4.5140e-03, test_loss 7.8787e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1290, train_loss 4.5109e-03, test_loss 7.8800e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1291, train_loss 4.5079e-03, test_loss 7.8812e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1292, train_loss 4.5048e-03, test_loss 7.8825e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1293, train_loss 4.5018e-03, test_loss 7.8838e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1294, train_loss 4.4987e-03, test_loss 7.8851e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1295, train_loss 4.4957e-03, test_loss 7.8864e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1296, train_loss 4.4927e-03, test_loss 7.8877e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1297, train_loss 4.4897e-03, test_loss 7.8890e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1298, train_loss 4.4867e-03, test_loss 7.8904e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1299, train_loss 4.4837e-03, test_loss 7.8917e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1300, train_loss 4.4807e-03, test_loss 7.8930e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1301, train_loss 4.4777e-03, test_loss 7.8943e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1302, train_loss 4.4748e-03, test_loss 7.8957e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1303, train_loss 4.4718e-03, test_loss 7.8970e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1304, train_loss 4.4689e-03, test_loss 7.8984e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1305, train_loss 4.4659e-03, test_loss 7.8997e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1306, train_loss 4.4630e-03, test_loss 7.9011e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1307, train_loss 4.4601e-03, test_loss 7.9025e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1308, train_loss 4.4571e-03, test_loss 7.9039e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1309, train_loss 4.4542e-03, test_loss 7.9052e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1310, train_loss 4.4514e-03, test_loss 7.9066e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1311, train_loss 4.4484e-03, test_loss 7.9080e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1312, train_loss 4.4456e-03, test_loss 7.9094e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1313, train_loss 4.4427e-03, test_loss 7.9108e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1314, train_loss 4.4398e-03, test_loss 7.9123e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1315, train_loss 4.4370e-03, test_loss 7.9137e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1316, train_loss 4.4341e-03, test_loss 7.9151e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1317, train_loss 4.4313e-03, test_loss 7.9165e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1318, train_loss 4.4284e-03, test_loss 7.9180e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1319, train_loss 4.4256e-03, test_loss 7.9194e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1320, train_loss 4.4227e-03, test_loss 7.9209e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1321, train_loss 4.4199e-03, test_loss 7.9222e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1322, train_loss 4.4171e-03, test_loss 7.9239e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1323, train_loss 4.4143e-03, test_loss 7.9251e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1324, train_loss 4.4115e-03, test_loss 7.9270e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1325, train_loss 4.4088e-03, test_loss 7.9278e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1326, train_loss 4.4061e-03, test_loss 7.9302e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1327, train_loss 4.4035e-03, test_loss 7.9304e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1328, train_loss 4.4012e-03, test_loss 7.9338e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1329, train_loss 4.3993e-03, test_loss 7.9325e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1330, train_loss 4.3986e-03, test_loss 7.9381e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1331, train_loss 4.4002e-03, test_loss 7.9338e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1332, train_loss 4.4071e-03, test_loss 7.9440e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1333, train_loss 4.4242e-03, test_loss 7.9336e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1334, train_loss 4.4581e-03, test_loss 7.9518e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1335, train_loss 4.5104e-03, test_loss 7.9345e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1336, train_loss 4.5443e-03, test_loss 7.9538e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1337, train_loss 4.5117e-03, test_loss 7.9434e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1338, train_loss 4.4173e-03, test_loss 7.9452e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1339, train_loss 4.3733e-03, test_loss 7.9554e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1340, train_loss 4.4142e-03, test_loss 7.9444e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1341, train_loss 4.4507e-03, test_loss 7.9561e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1342, train_loss 4.4176e-03, test_loss 7.9553e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1343, train_loss 4.3696e-03, test_loss 7.9497e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1344, train_loss 4.3782e-03, test_loss 7.9632e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1345, train_loss 4.4040e-03, test_loss 7.9545e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1346, train_loss 4.3872e-03, test_loss 7.9572e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1347, train_loss 4.3589e-03, test_loss 7.9657e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1348, train_loss 4.3648e-03, test_loss 7.9546e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1349, train_loss 4.3766e-03, test_loss 7.9656e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1350, train_loss 4.3606e-03, test_loss 7.9651e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1351, train_loss 4.3440e-03, test_loss 7.9600e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1352, train_loss 4.3522e-03, test_loss 7.9731e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1353, train_loss 4.3582e-03, test_loss 7.9651e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1354, train_loss 4.3422e-03, test_loss 7.9692e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1355, train_loss 4.3304e-03, test_loss 7.9757e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1356, train_loss 4.3378e-03, test_loss 7.9675e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1357, train_loss 4.3412e-03, test_loss 7.9778e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1358, train_loss 4.3288e-03, test_loss 7.9757e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1359, train_loss 4.3197e-03, test_loss 7.9742e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1360, train_loss 4.3236e-03, test_loss 7.9834e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1361, train_loss 4.3251e-03, test_loss 7.9778e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1362, train_loss 4.3166e-03, test_loss 7.9828e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1363, train_loss 4.3105e-03, test_loss 7.9859e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1364, train_loss 4.3114e-03, test_loss 7.9825e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1365, train_loss 4.3105e-03, test_loss 7.9892e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1366, train_loss 4.3045e-03, test_loss 7.9880e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1367, train_loss 4.3006e-03, test_loss 7.9892e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1368, train_loss 4.3005e-03, test_loss 7.9936e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1369, train_loss 4.2982e-03, test_loss 7.9921e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1370, train_loss 4.2930e-03, test_loss 7.9954e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1371, train_loss 4.2899e-03, test_loss 7.9973e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1372, train_loss 4.2894e-03, test_loss 7.9973e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1373, train_loss 4.2873e-03, test_loss 8.0006e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1374, train_loss 4.2826e-03, test_loss 8.0016e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1375, train_loss 4.2793e-03, test_loss 8.0025e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1376, train_loss 4.2782e-03, test_loss 8.0057e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1377, train_loss 4.2763e-03, test_loss 8.0064e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1378, train_loss 4.2727e-03, test_loss 8.0079e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1379, train_loss 4.2693e-03, test_loss 8.0108e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1380, train_loss 4.2674e-03, test_loss 8.0107e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1381, train_loss 4.2654e-03, test_loss 8.0135e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1382, train_loss 4.2624e-03, test_loss 8.0151e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1383, train_loss 4.2594e-03, test_loss 8.0154e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1384, train_loss 4.2572e-03, test_loss 8.0190e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1385, train_loss 4.2550e-03, test_loss 8.0190e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1386, train_loss 4.2522e-03, test_loss 8.0213e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1387, train_loss 4.2493e-03, test_loss 8.0237e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1388, train_loss 4.2470e-03, test_loss 8.0236e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1389, train_loss 4.2448e-03, test_loss 8.0272e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1390, train_loss 4.2422e-03, test_loss 8.0276e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1391, train_loss 4.2393e-03, test_loss 8.0294e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1392, train_loss 4.2368e-03, test_loss 8.0320e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1393, train_loss 4.2346e-03, test_loss 8.0322e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1394, train_loss 4.2322e-03, test_loss 8.0353e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1395, train_loss 4.2295e-03, test_loss 8.0361e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1396, train_loss 4.2269e-03, test_loss 8.0378e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1397, train_loss 4.2244e-03, test_loss 8.0402e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1398, train_loss 4.2221e-03, test_loss 8.0408e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1399, train_loss 4.2196e-03, test_loss 8.0434e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1400, train_loss 4.2170e-03, test_loss 8.0446e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1401, train_loss 4.2145e-03, test_loss 8.0462e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1402, train_loss 4.2121e-03, test_loss 8.0484e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1403, train_loss 4.2096e-03, test_loss 8.0495e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1404, train_loss 4.2071e-03, test_loss 8.0515e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1405, train_loss 4.2045e-03, test_loss 8.0531e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1406, train_loss 4.2021e-03, test_loss 8.0546e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1407, train_loss 4.1997e-03, test_loss 8.0566e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1408, train_loss 4.1972e-03, test_loss 8.0580e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1409, train_loss 4.1947e-03, test_loss 8.0597e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1410, train_loss 4.1922e-03, test_loss 8.0616e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1411, train_loss 4.1897e-03, test_loss 8.0629e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1412, train_loss 4.1873e-03, test_loss 8.0649e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1413, train_loss 4.1848e-03, test_loss 8.0664e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1414, train_loss 4.1823e-03, test_loss 8.0681e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1415, train_loss 4.1799e-03, test_loss 8.0700e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1416, train_loss 4.1774e-03, test_loss 8.0713e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1417, train_loss 4.1749e-03, test_loss 8.0733e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1418, train_loss 4.1725e-03, test_loss 8.0748e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1419, train_loss 4.1700e-03, test_loss 8.0765e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1420, train_loss 4.1675e-03, test_loss 8.0783e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1421, train_loss 4.1650e-03, test_loss 8.0796e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1422, train_loss 4.1626e-03, test_loss 8.0817e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1423, train_loss 4.1601e-03, test_loss 8.0830e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1424, train_loss 4.1577e-03, test_loss 8.0849e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1425, train_loss 4.1552e-03, test_loss 8.0866e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1426, train_loss 4.1527e-03, test_loss 8.0881e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1427, train_loss 4.1503e-03, test_loss 8.0900e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1428, train_loss 4.1478e-03, test_loss 8.0914e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1429, train_loss 4.1453e-03, test_loss 8.0932e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1430, train_loss 4.1429e-03, test_loss 8.0948e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1431, train_loss 4.1404e-03, test_loss 8.0964e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1432, train_loss 4.1379e-03, test_loss 8.0982e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1433, train_loss 4.1355e-03, test_loss 8.0997e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1434, train_loss 4.1330e-03, test_loss 8.1015e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1435, train_loss 4.1306e-03, test_loss 8.1030e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1436, train_loss 4.1281e-03, test_loss 8.1047e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1437, train_loss 4.1256e-03, test_loss 8.1064e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1438, train_loss 4.1232e-03, test_loss 8.1079e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1439, train_loss 4.1207e-03, test_loss 8.1096e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1440, train_loss 4.1183e-03, test_loss 8.1112e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1441, train_loss 4.1158e-03, test_loss 8.1129e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1442, train_loss 4.1133e-03, test_loss 8.1145e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1443, train_loss 4.1109e-03, test_loss 8.1161e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1444, train_loss 4.1084e-03, test_loss 8.1178e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1445, train_loss 4.1059e-03, test_loss 8.1193e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1446, train_loss 4.1035e-03, test_loss 8.1210e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1447, train_loss 4.1010e-03, test_loss 8.1226e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1448, train_loss 4.0986e-03, test_loss 8.1242e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1449, train_loss 4.0961e-03, test_loss 8.1259e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1450, train_loss 4.0936e-03, test_loss 8.1274e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1451, train_loss 4.0912e-03, test_loss 8.1291e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1452, train_loss 4.0887e-03, test_loss 8.1306e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1453, train_loss 4.0862e-03, test_loss 8.1323e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1454, train_loss 4.0838e-03, test_loss 8.1338e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1455, train_loss 4.0813e-03, test_loss 8.1354e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1456, train_loss 4.0788e-03, test_loss 8.1370e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1457, train_loss 4.0764e-03, test_loss 8.1386e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1458, train_loss 4.0739e-03, test_loss 8.1402e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1459, train_loss 4.0715e-03, test_loss 8.1418e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1460, train_loss 4.0690e-03, test_loss 8.1434e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1461, train_loss 4.0665e-03, test_loss 8.1449e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1462, train_loss 4.0641e-03, test_loss 8.1465e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1463, train_loss 4.0616e-03, test_loss 8.1481e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1464, train_loss 4.0591e-03, test_loss 8.1496e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1465, train_loss 4.0567e-03, test_loss 8.1512e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1466, train_loss 4.0542e-03, test_loss 8.1527e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1467, train_loss 4.0518e-03, test_loss 8.1543e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1468, train_loss 4.0493e-03, test_loss 8.1559e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1469, train_loss 4.0468e-03, test_loss 8.1574e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1470, train_loss 4.0444e-03, test_loss 8.1590e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1471, train_loss 4.0419e-03, test_loss 8.1605e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1472, train_loss 4.0394e-03, test_loss 8.1620e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1473, train_loss 4.0369e-03, test_loss 8.1635e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1474, train_loss 4.0345e-03, test_loss 8.1651e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1475, train_loss 4.0320e-03, test_loss 8.1666e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1476, train_loss 4.0296e-03, test_loss 8.1682e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1477, train_loss 4.0271e-03, test_loss 8.1696e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1478, train_loss 4.0246e-03, test_loss 8.1712e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1479, train_loss 4.0222e-03, test_loss 8.1727e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1480, train_loss 4.0197e-03, test_loss 8.1742e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1481, train_loss 4.0173e-03, test_loss 8.1756e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1482, train_loss 4.0148e-03, test_loss 8.1772e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1483, train_loss 4.0123e-03, test_loss 8.1786e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1484, train_loss 4.0099e-03, test_loss 8.1803e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1485, train_loss 4.0074e-03, test_loss 8.1816e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1486, train_loss 4.0050e-03, test_loss 8.1833e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1487, train_loss 4.0025e-03, test_loss 8.1844e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1488, train_loss 4.0001e-03, test_loss 8.1864e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1489, train_loss 3.9977e-03, test_loss 8.1872e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1490, train_loss 3.9953e-03, test_loss 8.1895e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1491, train_loss 3.9930e-03, test_loss 8.1899e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1492, train_loss 3.9908e-03, test_loss 8.1928e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1493, train_loss 3.9889e-03, test_loss 8.1923e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1494, train_loss 3.9874e-03, test_loss 8.1964e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1495, train_loss 3.9868e-03, test_loss 8.1943e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1496, train_loss 3.9878e-03, test_loss 8.2007e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1497, train_loss 3.9920e-03, test_loss 8.1955e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1498, train_loss 4.0017e-03, test_loss 8.2062e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1499, train_loss 4.0212e-03, test_loss 8.1958e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1500, train_loss 4.0561e-03, test_loss 8.2133e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1501, train_loss 4.1090e-03, test_loss 8.1958e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1502, train_loss 4.1767e-03, test_loss 8.2194e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1503, train_loss 4.2311e-03, test_loss 8.1991e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1504, train_loss 4.2428e-03, test_loss 8.2178e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1505, train_loss 4.1846e-03, test_loss 8.2082e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1506, train_loss 4.0866e-03, test_loss 8.2097e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1507, train_loss 4.0025e-03, test_loss 8.2195e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1508, train_loss 3.9772e-03, test_loss 8.2054e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1509, train_loss 4.0065e-03, test_loss 8.2270e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1510, train_loss 4.0496e-03, test_loss 8.2086e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1511, train_loss 4.0633e-03, test_loss 8.2255e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1512, train_loss 4.0326e-03, test_loss 8.2183e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1513, train_loss 3.9828e-03, test_loss 8.2184e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1514, train_loss 3.9516e-03, test_loss 8.2288e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1515, train_loss 3.9553e-03, test_loss 8.2157e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1516, train_loss 3.9789e-03, test_loss 8.2336e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1517, train_loss 3.9939e-03, test_loss 8.2198e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1518, train_loss 3.9836e-03, test_loss 8.2315e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1519, train_loss 3.9555e-03, test_loss 8.2283e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1520, train_loss 3.9312e-03, test_loss 8.2269e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1521, train_loss 3.9265e-03, test_loss 8.2371e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1522, train_loss 3.9380e-03, test_loss 8.2260e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1523, train_loss 3.9498e-03, test_loss 8.2409e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1524, train_loss 3.9488e-03, test_loss 8.2306e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1525, train_loss 3.9341e-03, test_loss 8.2390e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1526, train_loss 3.9166e-03, test_loss 8.2382e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1527, train_loss 3.9073e-03, test_loss 8.2363e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1528, train_loss 3.9092e-03, test_loss 8.2448e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1529, train_loss 3.9162e-03, test_loss 8.2367e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1530, train_loss 3.9194e-03, test_loss 8.2481e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1531, train_loss 3.9148e-03, test_loss 8.2407e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1532, train_loss 3.9046e-03, test_loss 8.2477e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1533, train_loss 3.8952e-03, test_loss 8.2468e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1534, train_loss 3.8907e-03, test_loss 8.2465e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1535, train_loss 3.8912e-03, test_loss 8.2521e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1536, train_loss 3.8932e-03, test_loss 8.2474e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1537, train_loss 3.8929e-03, test_loss 8.2552e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1538, train_loss 3.8891e-03, test_loss 8.2507e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1539, train_loss 3.8832e-03, test_loss 8.2564e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1540, train_loss 3.8779e-03, test_loss 8.2550e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1541, train_loss 3.8748e-03, test_loss 8.2568e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1542, train_loss 3.8737e-03, test_loss 8.2593e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1543, train_loss 3.8732e-03, test_loss 8.2581e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1544, train_loss 3.8716e-03, test_loss 8.2623e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1545, train_loss 3.8686e-03, test_loss 8.2608e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1546, train_loss 3.8645e-03, test_loss 8.2642e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1547, train_loss 3.8606e-03, test_loss 8.2642e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1548, train_loss 3.8576e-03, test_loss 8.2657e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1549, train_loss 3.8556e-03, test_loss 8.2674e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1550, train_loss 3.8543e-03, test_loss 8.2676e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1551, train_loss 3.8528e-03, test_loss 8.2701e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1552, train_loss 3.8507e-03, test_loss 8.2702e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1553, train_loss 3.8479e-03, test_loss 8.2721e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1554, train_loss 3.8449e-03, test_loss 8.2734e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1555, train_loss 3.8418e-03, test_loss 8.2737e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1556, train_loss 3.8392e-03, test_loss 8.2766e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1557, train_loss 3.8369e-03, test_loss 8.2755e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1558, train_loss 3.8350e-03, test_loss 8.2795e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1559, train_loss 3.8330e-03, test_loss 8.2777e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1560, train_loss 3.8308e-03, test_loss 8.2820e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1561, train_loss 3.8284e-03, test_loss 8.2802e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1562, train_loss 3.8258e-03, test_loss 8.2841e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1563, train_loss 3.8232e-03, test_loss 8.2829e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1564, train_loss 3.8207e-03, test_loss 8.2861e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1565, train_loss 3.8184e-03, test_loss 8.2855e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1566, train_loss 3.8163e-03, test_loss 8.2884e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1567, train_loss 3.8144e-03, test_loss 8.2879e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1568, train_loss 3.8127e-03, test_loss 8.2910e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1569, train_loss 3.8111e-03, test_loss 8.2898e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1570, train_loss 3.8098e-03, test_loss 8.2941e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1571, train_loss 3.8089e-03, test_loss 8.2911e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1572, train_loss 3.8087e-03, test_loss 8.2978e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1573, train_loss 3.8098e-03, test_loss 8.2919e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1574, train_loss 3.8127e-03, test_loss 8.3023e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1575, train_loss 3.8183e-03, test_loss 8.2921e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1576, train_loss 3.8271e-03, test_loss 8.3073e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1577, train_loss 3.8400e-03, test_loss 8.2920e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1578, train_loss 3.8546e-03, test_loss 8.3122e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1579, train_loss 3.8687e-03, test_loss 8.2928e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1580, train_loss 3.8729e-03, test_loss 8.3147e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1581, train_loss 3.8644e-03, test_loss 8.2957e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1582, train_loss 3.8415e-03, test_loss 8.3139e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1583, train_loss 3.8160e-03, test_loss 8.3008e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1584, train_loss 3.7992e-03, test_loss 8.3120e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1585, train_loss 3.7958e-03, test_loss 8.3064e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1586, train_loss 3.8005e-03, test_loss 8.3108e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1587, train_loss 3.8038e-03, test_loss 8.3112e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1588, train_loss 3.7988e-03, test_loss 8.3111e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1589, train_loss 3.7854e-03, test_loss 8.3136e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1590, train_loss 3.7698e-03, test_loss 8.3132e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1591, train_loss 3.7592e-03, test_loss 8.3148e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1592, train_loss 3.7570e-03, test_loss 8.3158e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1593, train_loss 3.7610e-03, test_loss 8.3169e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1594, train_loss 3.7660e-03, test_loss 8.3176e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1595, train_loss 3.7675e-03, test_loss 8.3201e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1596, train_loss 3.7642e-03, test_loss 8.3185e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1597, train_loss 3.7578e-03, test_loss 8.3237e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1598, train_loss 3.7521e-03, test_loss 8.3188e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1599, train_loss 3.7490e-03, test_loss 8.3274e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1600, train_loss 3.7489e-03, test_loss 8.3194e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1601, train_loss 3.7500e-03, test_loss 8.3305e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1602, train_loss 3.7504e-03, test_loss 8.3211e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1603, train_loss 3.7485e-03, test_loss 8.3324e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1604, train_loss 3.7448e-03, test_loss 8.3238e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1605, train_loss 3.7403e-03, test_loss 8.3337e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1606, train_loss 3.7367e-03, test_loss 8.3265e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1607, train_loss 3.7345e-03, test_loss 8.3353e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1608, train_loss 3.7340e-03, test_loss 8.3290e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1609, train_loss 3.7342e-03, test_loss 8.3374e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1610, train_loss 3.7345e-03, test_loss 8.3310e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1611, train_loss 3.7343e-03, test_loss 8.3402e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1612, train_loss 3.7340e-03, test_loss 8.3320e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1613, train_loss 3.7338e-03, test_loss 8.3437e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1614, train_loss 3.7348e-03, test_loss 8.3324e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1615, train_loss 3.7374e-03, test_loss 8.3476e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1616, train_loss 3.7423e-03, test_loss 8.3327e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1617, train_loss 3.7495e-03, test_loss 8.3520e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1618, train_loss 3.7594e-03, test_loss 8.3328e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1619, train_loss 3.7721e-03, test_loss 8.3567e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1620, train_loss 3.7875e-03, test_loss 8.3327e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1621, train_loss 3.8059e-03, test_loss 8.3613e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1622, train_loss 3.8257e-03, test_loss 8.3329e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1623, train_loss 3.8469e-03, test_loss 8.3655e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1624, train_loss 3.8646e-03, test_loss 8.3338e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1625, train_loss 3.8777e-03, test_loss 8.3681e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1626, train_loss 3.8785e-03, test_loss 8.3360e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1627, train_loss 3.8668e-03, test_loss 8.3681e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1628, train_loss 3.8386e-03, test_loss 8.3404e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1629, train_loss 3.7998e-03, test_loss 8.3653e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1630, train_loss 3.7554e-03, test_loss 8.3469e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1631, train_loss 3.7147e-03, test_loss 8.3611e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1632, train_loss 3.6844e-03, test_loss 8.3546e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1633, train_loss 3.6677e-03, test_loss 8.3572e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1634, train_loss 3.6640e-03, test_loss 8.3621e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1635, train_loss 3.6699e-03, test_loss 8.3548e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1636, train_loss 3.6807e-03, test_loss 8.3682e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1637, train_loss 3.6925e-03, test_loss 8.3540e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1638, train_loss 3.7016e-03, test_loss 8.3722e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1639, train_loss 3.7064e-03, test_loss 8.3550e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1640, train_loss 3.7061e-03, test_loss 8.3742e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1641, train_loss 3.7009e-03, test_loss 8.3573e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1642, train_loss 3.6920e-03, test_loss 8.3745e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1643, train_loss 3.6808e-03, test_loss 8.3610e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1644, train_loss 3.6686e-03, test_loss 8.3737e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1645, train_loss 3.6569e-03, test_loss 8.3654e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1646, train_loss 3.6467e-03, test_loss 8.3727e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1647, train_loss 3.6387e-03, test_loss 8.3701e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1648, train_loss 3.6332e-03, test_loss 8.3719e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1649, train_loss 3.6301e-03, test_loss 8.3744e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1650, train_loss 3.6289e-03, test_loss 8.3716e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1651, train_loss 3.6290e-03, test_loss 8.3781e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1652, train_loss 3.6299e-03, test_loss 8.3719e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1653, train_loss 3.6311e-03, test_loss 8.3813e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1654, train_loss 3.6323e-03, test_loss 8.3726e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1655, train_loss 3.6331e-03, test_loss 8.3839e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1656, train_loss 3.6335e-03, test_loss 8.3737e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1657, train_loss 3.6334e-03, test_loss 8.3862e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1658, train_loss 3.6330e-03, test_loss 8.3751e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1659, train_loss 3.6322e-03, test_loss 8.3884e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1660, train_loss 3.6314e-03, test_loss 8.3767e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1661, train_loss 3.6304e-03, test_loss 8.3905e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1662, train_loss 3.6296e-03, test_loss 8.3783e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1663, train_loss 3.6289e-03, test_loss 8.3927e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1664, train_loss 3.6287e-03, test_loss 8.3798e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1665, train_loss 3.6288e-03, test_loss 8.3951e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1666, train_loss 3.6296e-03, test_loss 8.3811e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1667, train_loss 3.6309e-03, test_loss 8.3977e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1668, train_loss 3.6331e-03, test_loss 8.3821e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1669, train_loss 3.6362e-03, test_loss 8.4006e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1670, train_loss 3.6404e-03, test_loss 8.3828e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1671, train_loss 3.6460e-03, test_loss 8.4038e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1672, train_loss 3.6531e-03, test_loss 8.3834e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1673, train_loss 3.6619e-03, test_loss 8.4073e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1674, train_loss 3.6722e-03, test_loss 8.3837e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1675, train_loss 3.6841e-03, test_loss 8.4110e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1676, train_loss 3.6965e-03, test_loss 8.3842e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1677, train_loss 3.7093e-03, test_loss 8.4143e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1678, train_loss 3.7199e-03, test_loss 8.3851e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1679, train_loss 3.7278e-03, test_loss 8.4166e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1680, train_loss 3.7295e-03, test_loss 8.3869e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1681, train_loss 3.7253e-03, test_loss 8.4174e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1682, train_loss 3.7127e-03, test_loss 8.3900e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1683, train_loss 3.6939e-03, test_loss 8.4165e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1684, train_loss 3.6689e-03, test_loss 8.3943e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1685, train_loss 3.6414e-03, test_loss 8.4143e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1686, train_loss 3.6136e-03, test_loss 8.3996e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1687, train_loss 3.5884e-03, test_loss 8.4117e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1688, train_loss 3.5680e-03, test_loss 8.4052e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1689, train_loss 3.5533e-03, test_loss 8.4095e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1690, train_loss 3.5447e-03, test_loss 8.4106e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1691, train_loss 3.5414e-03, test_loss 8.4082e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1692, train_loss 3.5422e-03, test_loss 8.4152e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1693, train_loss 3.5460e-03, test_loss 8.4077e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1694, train_loss 3.5511e-03, test_loss 8.4190e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1695, train_loss 3.5568e-03, test_loss 8.4079e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1696, train_loss 3.5618e-03, test_loss 8.4220e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1697, train_loss 3.5658e-03, test_loss 8.4087e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1698, train_loss 3.5683e-03, test_loss 8.4245e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1699, train_loss 3.5695e-03, test_loss 8.4099e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1700, train_loss 3.5692e-03, test_loss 8.4266e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1701, train_loss 3.5679e-03, test_loss 8.4114e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1702, train_loss 3.5657e-03, test_loss 8.4284e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1703, train_loss 3.5630e-03, test_loss 8.4131e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1704, train_loss 3.5601e-03, test_loss 8.4301e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1705, train_loss 3.5572e-03, test_loss 8.4149e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1706, train_loss 3.5544e-03, test_loss 8.4317e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1707, train_loss 3.5519e-03, test_loss 8.4168e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1708, train_loss 3.5495e-03, test_loss 8.4333e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1709, train_loss 3.5474e-03, test_loss 8.4186e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1710, train_loss 3.5452e-03, test_loss 8.4349e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1711, train_loss 3.5430e-03, test_loss 8.4204e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1712, train_loss 3.5404e-03, test_loss 8.4365e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1713, train_loss 3.5379e-03, test_loss 8.4222e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1714, train_loss 3.5352e-03, test_loss 8.4381e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1715, train_loss 3.5328e-03, test_loss 8.4239e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1716, train_loss 3.5307e-03, test_loss 8.4399e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1717, train_loss 3.5293e-03, test_loss 8.4255e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1718, train_loss 3.5289e-03, test_loss 8.4419e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1719, train_loss 3.5296e-03, test_loss 8.4269e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1720, train_loss 3.5314e-03, test_loss 8.4442e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1721, train_loss 3.5347e-03, test_loss 8.4281e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1722, train_loss 3.5394e-03, test_loss 8.4470e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1723, train_loss 3.5454e-03, test_loss 8.4290e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1724, train_loss 3.5530e-03, test_loss 8.4501e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1725, train_loss 3.5621e-03, test_loss 8.4295e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1726, train_loss 3.5728e-03, test_loss 8.4536e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1727, train_loss 3.5848e-03, test_loss 8.4298e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1728, train_loss 3.5984e-03, test_loss 8.4574e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1729, train_loss 3.6122e-03, test_loss 8.4301e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1730, train_loss 3.6269e-03, test_loss 8.4610e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1731, train_loss 3.6395e-03, test_loss 8.4307e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1732, train_loss 3.6508e-03, test_loss 8.4640e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1733, train_loss 3.6565e-03, test_loss 8.4320e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1734, train_loss 3.6570e-03, test_loss 8.4656e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1735, train_loss 3.6480e-03, test_loss 8.4346e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1736, train_loss 3.6303e-03, test_loss 8.4650e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1737, train_loss 3.6021e-03, test_loss 8.4388e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1738, train_loss 3.5670e-03, test_loss 8.4623e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1739, train_loss 3.5285e-03, test_loss 8.4445e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1740, train_loss 3.4923e-03, test_loss 8.4587e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1741, train_loss 3.4636e-03, test_loss 8.4508e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1742, train_loss 3.4449e-03, test_loss 8.4555e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1743, train_loss 3.4367e-03, test_loss 8.4570e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1744, train_loss 3.4369e-03, test_loss 8.4534e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1745, train_loss 3.4424e-03, test_loss 8.4624e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1746, train_loss 3.4503e-03, test_loss 8.4524e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1747, train_loss 3.4580e-03, test_loss 8.4663e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1748, train_loss 3.4641e-03, test_loss 8.4528e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1749, train_loss 3.4677e-03, test_loss 8.4687e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1750, train_loss 3.4690e-03, test_loss 8.4541e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1751, train_loss 3.4685e-03, test_loss 8.4703e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1752, train_loss 3.4667e-03, test_loss 8.4560e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1753, train_loss 3.4643e-03, test_loss 8.4715e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1754, train_loss 3.4615e-03, test_loss 8.4583e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1755, train_loss 3.4583e-03, test_loss 8.4723e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1756, train_loss 3.4547e-03, test_loss 8.4609e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1757, train_loss 3.4504e-03, test_loss 8.4731e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1758, train_loss 3.4457e-03, test_loss 8.4634e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1759, train_loss 3.4402e-03, test_loss 8.4742e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1760, train_loss 3.4346e-03, test_loss 8.4657e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1761, train_loss 3.4286e-03, test_loss 8.4753e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1762, train_loss 3.4228e-03, test_loss 8.4679e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1763, train_loss 3.4173e-03, test_loss 8.4767e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1764, train_loss 3.4123e-03, test_loss 8.4700e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1765, train_loss 3.4078e-03, test_loss 8.4782e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1766, train_loss 3.4041e-03, test_loss 8.4719e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1767, train_loss 3.4009e-03, test_loss 8.4800e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1768, train_loss 3.3984e-03, test_loss 8.4736e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1769, train_loss 3.3965e-03, test_loss 8.4821e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1770, train_loss 3.3951e-03, test_loss 8.4752e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1771, train_loss 3.3944e-03, test_loss 8.4845e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1772, train_loss 3.3944e-03, test_loss 8.4765e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1773, train_loss 3.3952e-03, test_loss 8.4873e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1774, train_loss 3.3972e-03, test_loss 8.4774e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1775, train_loss 3.4007e-03, test_loss 8.4907e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1776, train_loss 3.4062e-03, test_loss 8.4778e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1777, train_loss 3.4143e-03, test_loss 8.4947e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1778, train_loss 3.4264e-03, test_loss 8.4776e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1779, train_loss 3.4433e-03, test_loss 8.4997e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1780, train_loss 3.4670e-03, test_loss 8.4767e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1781, train_loss 3.4991e-03, test_loss 8.5057e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1782, train_loss 3.5411e-03, test_loss 8.4753e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1783, train_loss 3.5952e-03, test_loss 8.5128e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1784, train_loss 3.6595e-03, test_loss 8.4739e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1785, train_loss 3.7355e-03, test_loss 8.5199e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1786, train_loss 3.8121e-03, test_loss 8.4731e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1787, train_loss 3.8883e-03, test_loss 8.5251e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1788, train_loss 3.9370e-03, test_loss 8.4743e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1789, train_loss 3.9534e-03, test_loss 8.5248e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1790, train_loss 3.9050e-03, test_loss 8.4793e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1791, train_loss 3.8021e-03, test_loss 8.5167e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1792, train_loss 3.6544e-03, test_loss 8.4898e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1793, train_loss 3.5080e-03, test_loss 8.5046e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1794, train_loss 3.4033e-03, test_loss 8.5039e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1795, train_loss 3.3641e-03, test_loss 8.4956e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1796, train_loss 3.3855e-03, test_loss 8.5159e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1797, train_loss 3.4421e-03, test_loss 8.4924e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1798, train_loss 3.5005e-03, test_loss 8.5216e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1799, train_loss 3.5316e-03, test_loss 8.4940e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1800, train_loss 3.5230e-03, test_loss 8.5199e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1801, train_loss 3.4775e-03, test_loss 8.5001e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1802, train_loss 3.4152e-03, test_loss 8.5133e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1803, train_loss 3.3604e-03, test_loss 8.5093e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1804, train_loss 3.3309e-03, test_loss 8.5069e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1805, train_loss 3.3311e-03, test_loss 8.5180e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1806, train_loss 3.3522e-03, test_loss 8.5041e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1807, train_loss 3.3786e-03, test_loss 8.5228e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1808, train_loss 3.3959e-03, test_loss 8.5054e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1809, train_loss 3.3962e-03, test_loss 8.5233e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1810, train_loss 3.3798e-03, test_loss 8.5096e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1811, train_loss 3.3538e-03, test_loss 8.5207e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1812, train_loss 3.3282e-03, test_loss 8.5157e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1813, train_loss 3.3107e-03, test_loss 8.5174e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1814, train_loss 3.3050e-03, test_loss 8.5221e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1815, train_loss 3.3093e-03, test_loss 8.5154e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1816, train_loss 3.3187e-03, test_loss 8.5267e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1817, train_loss 3.3276e-03, test_loss 8.5157e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1818, train_loss 3.3316e-03, test_loss 8.5287e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1819, train_loss 3.3293e-03, test_loss 8.5182e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1820, train_loss 3.3214e-03, test_loss 8.5288e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1821, train_loss 3.3106e-03, test_loss 8.5220e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1822, train_loss 3.2996e-03, test_loss 8.5281e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1823, train_loss 3.2912e-03, test_loss 8.5265e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1824, train_loss 3.2864e-03, test_loss 8.5274e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1825, train_loss 3.2850e-03, test_loss 8.5309e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1826, train_loss 3.2861e-03, test_loss 8.5275e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1827, train_loss 3.2880e-03, test_loss 8.5344e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1828, train_loss 3.2897e-03, test_loss 8.5286e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1829, train_loss 3.2899e-03, test_loss 8.5368e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1830, train_loss 3.2885e-03, test_loss 8.5307e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1831, train_loss 3.2856e-03, test_loss 8.5384e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1832, train_loss 3.2817e-03, test_loss 8.5333e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1833, train_loss 3.2773e-03, test_loss 8.5395e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1834, train_loss 3.2731e-03, test_loss 8.5362e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1835, train_loss 3.2694e-03, test_loss 8.5404e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1836, train_loss 3.2665e-03, test_loss 8.5392e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1837, train_loss 3.2644e-03, test_loss 8.5415e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1838, train_loss 3.2630e-03, test_loss 8.5421e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1839, train_loss 3.2621e-03, test_loss 8.5430e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1840, train_loss 3.2615e-03, test_loss 8.5446e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1841, train_loss 3.2613e-03, test_loss 8.5449e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1842, train_loss 3.2612e-03, test_loss 8.5468e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1843, train_loss 3.2613e-03, test_loss 8.5471e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1844, train_loss 3.2617e-03, test_loss 8.5486e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1845, train_loss 3.2628e-03, test_loss 8.5497e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1846, train_loss 3.2647e-03, test_loss 8.5500e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1847, train_loss 3.2679e-03, test_loss 8.5527e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1848, train_loss 3.2731e-03, test_loss 8.5511e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1849, train_loss 3.2809e-03, test_loss 8.5561e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1850, train_loss 3.2921e-03, test_loss 8.5519e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1851, train_loss 3.3062e-03, test_loss 8.5597e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1852, train_loss 3.3236e-03, test_loss 8.5528e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1853, train_loss 3.3397e-03, test_loss 8.5630e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1854, train_loss 3.3523e-03, test_loss 8.5540e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1855, train_loss 3.3529e-03, test_loss 8.5651e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1856, train_loss 3.3409e-03, test_loss 8.5553e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1857, train_loss 3.3158e-03, test_loss 8.5666e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1858, train_loss 3.2874e-03, test_loss 8.5562e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1859, train_loss 3.2657e-03, test_loss 8.5689e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1860, train_loss 3.2593e-03, test_loss 8.5570e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1861, train_loss 3.2694e-03, test_loss 8.5721e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1862, train_loss 3.2921e-03, test_loss 8.5579e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1863, train_loss 3.3200e-03, test_loss 8.5757e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1864, train_loss 3.3469e-03, test_loss 8.5585e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1865, train_loss 3.3695e-03, test_loss 8.5802e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1866, train_loss 3.3881e-03, test_loss 8.5577e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1867, train_loss 3.4072e-03, test_loss 8.5860e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1868, train_loss 3.4319e-03, test_loss 8.5563e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1869, train_loss 3.4678e-03, test_loss 8.5923e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1870, train_loss 3.5132e-03, test_loss 8.5558e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1871, train_loss 3.5677e-03, test_loss 8.5979e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1872, train_loss 3.6161e-03, test_loss 8.5564e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1873, train_loss 3.6528e-03, test_loss 8.6011e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1874, train_loss 3.6548e-03, test_loss 8.5586e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1875, train_loss 3.6230e-03, test_loss 8.5998e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1876, train_loss 3.5491e-03, test_loss 8.5636e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1877, train_loss 3.4543e-03, test_loss 8.5939e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1878, train_loss 3.3547e-03, test_loss 8.5720e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1879, train_loss 3.2733e-03, test_loss 8.5866e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1880, train_loss 3.2218e-03, test_loss 8.5821e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1881, train_loss 3.2020e-03, test_loss 8.5810e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1882, train_loss 3.2077e-03, test_loss 8.5913e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1883, train_loss 3.2288e-03, test_loss 8.5779e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1884, train_loss 3.2552e-03, test_loss 8.5978e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1885, train_loss 3.2788e-03, test_loss 8.5773e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1886, train_loss 3.2946e-03, test_loss 8.6007e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1887, train_loss 3.2989e-03, test_loss 8.5792e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1888, train_loss 3.2913e-03, test_loss 8.6003e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1889, train_loss 3.2728e-03, test_loss 8.5832e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1890, train_loss 3.2471e-03, test_loss 8.5982e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1891, train_loss 3.2193e-03, test_loss 8.5886e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1892, train_loss 3.1945e-03, test_loss 8.5958e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1893, train_loss 3.1770e-03, test_loss 8.5943e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1894, train_loss 3.1683e-03, test_loss 8.5940e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1895, train_loss 3.1680e-03, test_loss 8.5996e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1896, train_loss 3.1737e-03, test_loss 8.5932e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1897, train_loss 3.1822e-03, test_loss 8.6037e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1898, train_loss 3.1906e-03, test_loss 8.5935e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1899, train_loss 3.1963e-03, test_loss 8.6065e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1900, train_loss 3.1986e-03, test_loss 8.5948e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1901, train_loss 3.1971e-03, test_loss 8.6081e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1902, train_loss 3.1925e-03, test_loss 8.5969e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1903, train_loss 3.1858e-03, test_loss 8.6090e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1904, train_loss 3.1783e-03, test_loss 8.5997e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1905, train_loss 3.1706e-03, test_loss 8.6096e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1906, train_loss 3.1637e-03, test_loss 8.6028e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1907, train_loss 3.1576e-03, test_loss 8.6100e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1908, train_loss 3.1527e-03, test_loss 8.6061e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1909, train_loss 3.1485e-03, test_loss 8.6106e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1910, train_loss 3.1451e-03, test_loss 8.6093e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1911, train_loss 3.1423e-03, test_loss 8.6114e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1912, train_loss 3.1400e-03, test_loss 8.6123e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1913, train_loss 3.1380e-03, test_loss 8.6125e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1914, train_loss 3.1363e-03, test_loss 8.6152e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1915, train_loss 3.1350e-03, test_loss 8.6136e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1916, train_loss 3.1339e-03, test_loss 8.6179e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1917, train_loss 3.1331e-03, test_loss 8.6149e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1918, train_loss 3.1325e-03, test_loss 8.6204e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1919, train_loss 3.1321e-03, test_loss 8.6161e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1920, train_loss 3.1320e-03, test_loss 8.6229e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1921, train_loss 3.1323e-03, test_loss 8.6173e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1922, train_loss 3.1329e-03, test_loss 8.6256e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1923, train_loss 3.1341e-03, test_loss 8.6183e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1924, train_loss 3.1360e-03, test_loss 8.6286e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1925, train_loss 3.1391e-03, test_loss 8.6192e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1926, train_loss 3.1435e-03, test_loss 8.6321e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1927, train_loss 3.1502e-03, test_loss 8.6196e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1928, train_loss 3.1596e-03, test_loss 8.6362e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1929, train_loss 3.1732e-03, test_loss 8.6194e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1930, train_loss 3.1926e-03, test_loss 8.6414e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1931, train_loss 3.2197e-03, test_loss 8.6184e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1932, train_loss 3.2579e-03, test_loss 8.6479e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1933, train_loss 3.3098e-03, test_loss 8.6166e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1934, train_loss 3.3811e-03, test_loss 8.6562e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1935, train_loss 3.4719e-03, test_loss 8.6143e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1936, train_loss 3.5881e-03, test_loss 8.6659e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1937, train_loss 3.7153e-03, test_loss 8.6124e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1938, train_loss 3.8503e-03, test_loss 8.6741e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1939, train_loss 3.9444e-03, test_loss 8.6125e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1940, train_loss 3.9812e-03, test_loss 8.6748e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1941, train_loss 3.9016e-03, test_loss 8.6168e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1942, train_loss 3.7285e-03, test_loss 8.6642e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1943, train_loss 3.4872e-03, test_loss 8.6279e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1944, train_loss 3.2657e-03, test_loss 8.6482e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1945, train_loss 3.1292e-03, test_loss 8.6451e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1946, train_loss 3.1053e-03, test_loss 8.6361e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1947, train_loss 3.1711e-03, test_loss 8.6610e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1948, train_loss 3.2726e-03, test_loss 8.6311e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1949, train_loss 3.3535e-03, test_loss 8.6675e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1950, train_loss 3.3725e-03, test_loss 8.6326e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1951, train_loss 3.3275e-03, test_loss 8.6630e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1952, train_loss 3.2389e-03, test_loss 8.6398e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1953, train_loss 3.1500e-03, test_loss 8.6532e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1954, train_loss 3.0949e-03, test_loss 8.6506e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1955, train_loss 3.0867e-03, test_loss 8.6452e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1956, train_loss 3.1148e-03, test_loss 8.6603e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1957, train_loss 3.1545e-03, test_loss 8.6420e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1958, train_loss 3.1811e-03, test_loss 8.6645e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1959, train_loss 3.1807e-03, test_loss 8.6438e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1960, train_loss 3.1557e-03, test_loss 8.6625e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1961, train_loss 3.1184e-03, test_loss 8.6494e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1962, train_loss 3.0855e-03, test_loss 8.6576e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1963, train_loss 3.0682e-03, test_loss 8.6567e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1964, train_loss 3.0684e-03, test_loss 8.6537e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1965, train_loss 3.0802e-03, test_loss 8.6628e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1966, train_loss 3.0943e-03, test_loss 8.6523e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1967, train_loss 3.1020e-03, test_loss 8.6656e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1968, train_loss 3.0994e-03, test_loss 8.6536e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1969, train_loss 3.0879e-03, test_loss 8.6652e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1970, train_loss 3.0723e-03, test_loss 8.6569e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1971, train_loss 3.0582e-03, test_loss 8.6632e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1972, train_loss 3.0497e-03, test_loss 8.6612e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1973, train_loss 3.0476e-03, test_loss 8.6615e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1974, train_loss 3.0505e-03, test_loss 8.6654e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1975, train_loss 3.0553e-03, test_loss 8.6612e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1976, train_loss 3.0589e-03, test_loss 8.6684e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1977, train_loss 3.0593e-03, test_loss 8.6624e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1978, train_loss 3.0560e-03, test_loss 8.6699e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1979, train_loss 3.0500e-03, test_loss 8.6648e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1980, train_loss 3.0428e-03, test_loss 8.6703e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1981, train_loss 3.0362e-03, test_loss 8.6677e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1982, train_loss 3.0314e-03, test_loss 8.6703e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1983, train_loss 3.0287e-03, test_loss 8.6707e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1984, train_loss 3.0280e-03, test_loss 8.6705e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1985, train_loss 3.0285e-03, test_loss 8.6732e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1986, train_loss 3.0294e-03, test_loss 8.6711e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1987, train_loss 3.0299e-03, test_loss 8.6752e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1988, train_loss 3.0296e-03, test_loss 8.6724e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1989, train_loss 3.0283e-03, test_loss 8.6766e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1990, train_loss 3.0261e-03, test_loss 8.6743e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1991, train_loss 3.0233e-03, test_loss 8.6777e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1992, train_loss 3.0201e-03, test_loss 8.6764e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1993, train_loss 3.0169e-03, test_loss 8.6785e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1994, train_loss 3.0141e-03, test_loss 8.6786e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1995, train_loss 3.0115e-03, test_loss 8.6792e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1996, train_loss 3.0094e-03, test_loss 8.6808e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1997, train_loss 3.0077e-03, test_loss 8.6800e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1998, train_loss 3.0063e-03, test_loss 8.6828e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 1999, train_loss 3.0052e-03, test_loss 8.6808e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "step 2000, train_loss 3.0041e-03, test_loss 8.6846e-01\n",
      "X has grad? True\n",
      "X has grad? False\n",
      "Final train loss 3.0031e-03 +/- 1.2396e-03\n",
      "Final test loss 8.6846e-01 +/- 4.4489e-01\n"
     ]
    }
   ],
   "source": [
    "args = get_args()\n",
    "model, stats = train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE=10\n",
    "R = 2.5\n",
    "t_span=torch.tensor([0, 28])\n",
    "LINE_SEGMENTS = 10\n",
    "ARROW_SCALE = 40\n",
    "ARROW_WIDTH = 6e-3\n",
    "LINE_WIDTH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X has grad? False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors does not require grad",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m field \u001b[38;5;241m=\u001b[39m get_field(xmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mR, xmax\u001b[38;5;241m=\u001b[39mR, ymin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mR, ymax\u001b[38;5;241m=\u001b[39mR, gridsize\u001b[38;5;241m=\u001b[39mGRID_SIZE)\n\u001b[0;32m----> 2\u001b[0m vector_field \u001b[38;5;241m=\u001b[39m \u001b[43mget_vector_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mymin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mymax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgridsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGRID_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# integrate along those fields starting from point (1,0)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m ivp \u001b[38;5;241m=\u001b[39m integrate_model(\n\u001b[1;32m      6\u001b[0m         model,\n\u001b[1;32m      7\u001b[0m         t_span,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-12\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m~/development/pinns/src/hnn/../hnn/simulation.py:97\u001b[0m, in \u001b[0;36mget_vector_field\u001b[0;34m(model, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m field \u001b[38;5;241m=\u001b[39m get_field(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     96\u001b[0m mesh_x \u001b[38;5;241m=\u001b[39m field[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 97\u001b[0m mesh_dx \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mesh_dx\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/development/pinns/src/hnn/../hnn/models.py:64\u001b[0m, in \u001b[0;36mHNN.time_derivative\u001b[0;34m(self, x, t, separate_fields)\u001b[0m\n\u001b[1;32m     60\u001b[0m solenoidal_field \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(x)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolenoidal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# gradients for conservative field\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     dF1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     65\u001b[0m     conservative_field \u001b[38;5;241m=\u001b[39m dF1 \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconservative\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# gradients for solenoidal field\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors does not require grad"
     ]
    }
   ],
   "source": [
    "\n",
    "field = get_field(xmin=-R, xmax=R, ymin=-R, ymax=R, gridsize=GRID_SIZE)\n",
    "vector_field = get_vector_field(model, xmin=-R, xmax=R, ymin=-R, ymax=R, gridsize=GRID_SIZE)\n",
    "\n",
    "# integrate along those fields starting from point (1,0)\n",
    "ivp = integrate_model(\n",
    "        model,\n",
    "        t_span,\n",
    "        y0=torch.tensor([2.1, 0]),\n",
    "        t_eval=torch.linspace(t_span[0], t_span[1], 1000),\n",
    "        rtol=1e-12\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11.3, 3.2), facecolor='white', dpi=300)\n",
    "\n",
    "# plot data\n",
    "fig.add_subplot(1, 4, 2, frameon=True)\n",
    "x, y, dx, dy, t = get_trajectory(t_span=[0,4], radius=2.1, y0=torch.tensor([2.1, 0]))\n",
    "N = len(x)\n",
    "point_colors = [(i/N, 0, 1-i/N) for i in range(N)]\n",
    "plt.scatter(x,y, s=14, label='data', c=point_colors)\n",
    "plt.quiver(\n",
    "        field['x'][:,0],\n",
    "        field['x'][:,1],\n",
    "        field['dx'][:,0],\n",
    "        field['dx'][:,1],\n",
    "        cmap='gray_r',\n",
    "        scale=ARROW_SCALE,\n",
    "        width=ARROW_WIDTH,\n",
    "        color=(.2,.2,.2)\n",
    ")  \n",
    "plt.xlabel(\"$q$\", fontsize=14)\n",
    "plt.ylabel(\"$p$\", rotation=0, fontsize=14)\n",
    "plt.title(\"Data\", pad=10)\n",
    "\n",
    "# plot HNN\n",
    "fig.add_subplot(1, 4, 4, frameon=True)\n",
    "plt.quiver(\n",
    "        field['x'][:,0],\n",
    "        field['x'][:,1],\n",
    "        vector_field[:,0],\n",
    "        vector_field[:,1],\n",
    "        cmap='gray_r',\n",
    "        scale=ARROW_SCALE,\n",
    "        width=ARROW_WIDTH,\n",
    "        color=(.5,.5,.5)\n",
    ")\n",
    "\n",
    "for i, l in enumerate(torch.tensor_split(torch.tensor(ivp['y'].T), LINE_SEGMENTS)):\n",
    "        color = (float(i)/LINE_SEGMENTS, 0, 1-float(i)/LINE_SEGMENTS)\n",
    "        plt.plot(l[:,0], l[:,1], color=color, linewidth=LINE_WIDTH)\n",
    "\n",
    "plt.xlabel(\"$q$\", fontsize=14)\n",
    "plt.ylabel(\"$p$\", rotation=0, fontsize=14)\n",
    "plt.title(\"Hamiltonian NN\", pad=10)\n",
    "plt.tight_layout() ; plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
