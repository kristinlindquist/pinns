{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristinlindquist/.pyenv/versions/3.12.3/lib/python3.12/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_args\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dynnn.train.train_simulator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdynnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmve_ensemble\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualize_trajectory, plot_energy\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdynnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmve_ensemble\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmve_ensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m energy_conservation_loss, calc_kinetic_energy, get_initial_conditions\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdynnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_simulator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_simulator \u001b[38;5;28;01mas\u001b[39;00m train\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdynnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dynnn.train.train_simulator'"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys  \n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "sys.path.insert(0, '../../..')\n",
    "\n",
    "from dynnn.simulation.mve_ensemble import MveEnsembleMechanics\n",
    "from dynnn.simulation.mve_ensemble.viz import visualize_trajectory, plot_energy\n",
    "from dynnn.simulation.mve_ensemble.mve_ensemble import energy_conservation_loss, calc_kinetic_energy, get_initial_conditions\n",
    "from dynnn.train.simulator.train_simulator import train_simulator as train\n",
    "from dynnn.utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(allow_abbrev=False)\n",
    "    parser.add_argument('--device', default=\"cpu\", type=str, help=\"device to run on\")\n",
    "    parser.add_argument('--rl_learn_rate', default=1e-4, type=float, help='learning rate')\n",
    "    parser.add_argument('--rl_weight_decay', default=1e-5, type=float, help='weight decay')\n",
    "    parser.add_argument('--num_experiments', default=100, type=int, help='number of RL param switch experiments')\n",
    "    parser.add_argument('--max_simulator_steps', default=1000, type=int, help='max steps within an experiment')\n",
    "    parser.add_argument('--verbose', default=False, type=bool, help='is notebook verbose? shows extra stuff that takes time to compute.')\n",
    "    parser.set_defaults(feature=True)\n",
    "    return parser.parse_known_args()[0]\n",
    "\n",
    "args = get_args()\n",
    "\n",
    "torch.set_default_device(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mechanics = MveEnsembleMechanics()\n",
    "\n",
    "def plot_energy_from_coords(r, v, time, masses):\n",
    "    pe = mechanics.no_bc_potential_fn(r).detach().cpu()\n",
    "    ke = calc_kinetic_energy(v, masses).detach().cpu()\n",
    "    te = pe + ke\n",
    "\n",
    "    plot_energy(pe, ke, te, time.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0, masses = get_initial_conditions(5)\n",
    "\n",
    "if args.verbose:\n",
    "    r, v, dr, dv, time = mechanics.get_trajectory({ \"y0\": y0, \"masses\": masses }).dict().values()\n",
    "    plot_energy_from_coords(r, v, time, masses)\n",
    "    ani = visualize_trajectory(r.detach().cpu(), len(time), (mechanics.domain_min, mechanics.domain_max))\n",
    "    display(HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.verbose:\n",
    "    ani.save(sys.path[0] + '/../images/mve_ensemble.gif', writer='pillow')\n",
    "    display(Image(filename=sys.path[0] + '/../images/mve_ensemble.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, _ = mechanics.get_dataset({}, { \"y0\": y0, \"masses\": masses })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.verbose:\n",
    "    data_r, data_v = [v.squeeze(-2) for v in torch.split(data[\"x\"][0], 1, dim=-2)]\n",
    "    plot_energy_from_coords(data_r, data_v, data[\"time\"], masses)\n",
    "    ani = visualize_trajectory(data_r, len(data[\"time\"]), mechanics.domain)\n",
    "    display(HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-5.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-5.pkl not found.\n",
      "Creating new data...\n",
      "step 0, train_loss 4.3160e-01, additional_loss 3.5048e-02, test_loss 9.3974e-01, test_additional_loss 6.4161e-01\n",
      "step 1, train_loss 1.5437e+00, additional_loss 1.1670e+00, test_loss 4.8948e-01, test_additional_loss 2.2893e-01\n",
      "step 2, train_loss 6.8031e-01, additional_loss 3.2191e-01, test_loss 4.2185e-01, test_additional_loss 1.5199e-01\n",
      "step 3, train_loss 6.5449e-01, additional_loss 2.9111e-01, test_loss 4.3366e-01, test_additional_loss 1.7331e-01\n",
      "step 4, train_loss 3.8956e-01, additional_loss 3.3426e-02, test_loss 4.3167e-01, test_additional_loss 1.7467e-01\n",
      "step 5, train_loss 4.4098e-01, additional_loss 8.9884e-02, test_loss 4.4701e-01, test_additional_loss 1.9743e-01\n",
      "step 6, train_loss 3.6953e-01, additional_loss 2.5082e-02, test_loss 5.1056e-01, test_additional_loss 2.7485e-01\n",
      "step 7, train_loss 3.9211e-01, additional_loss 6.5517e-02, test_loss 5.2852e-01, test_additional_loss 3.0308e-01\n",
      "step 8, train_loss 3.6735e-01, additional_loss 5.5885e-02, test_loss 5.6910e-01, test_additional_loss 3.5472e-01\n",
      "step 9, train_loss 3.7680e-01, additional_loss 8.2111e-02, test_loss 5.7667e-01, test_additional_loss 3.7029e-01\n",
      "step 10, train_loss 3.3023e-01, additional_loss 4.7636e-02, test_loss 6.1010e-01, test_additional_loss 4.1173e-01\n",
      "step 11, train_loss 3.5675e-01, additional_loss 8.3828e-02, test_loss 6.4994e-01, test_additional_loss 4.5872e-01\n",
      "step 12, train_loss 3.6840e-01, additional_loss 1.0843e-01, test_loss 6.6247e-01, test_additional_loss 4.7648e-01\n",
      "step 13, train_loss 3.0945e-01, additional_loss 5.8937e-02, test_loss 6.7330e-01, test_additional_loss 4.9472e-01\n",
      "step 14, train_loss 2.8706e-01, additional_loss 4.5633e-02, test_loss 7.2587e-01, test_additional_loss 5.5735e-01\n",
      "step 15, train_loss 3.3828e-01, additional_loss 1.0629e-01, test_loss 7.9102e-01, test_additional_loss 6.3214e-01\n",
      "step 16, train_loss 3.1811e-01, additional_loss 9.8562e-02, test_loss 8.2612e-01, test_additional_loss 6.7511e-01\n",
      "step 17, train_loss 3.1313e-01, additional_loss 1.0743e-01, test_loss 8.5460e-01, test_additional_loss 7.0951e-01\n",
      "step 18, train_loss 3.3077e-01, additional_loss 1.3390e-01, test_loss 9.2008e-01, test_additional_loss 7.8056e-01\n",
      "step 19, train_loss 2.9474e-01, additional_loss 1.0233e-01, test_loss 1.0229e+00, test_additional_loss 8.9154e-01\n",
      "step 20, train_loss 2.4640e-01, additional_loss 6.3992e-02, test_loss 1.1505e+00, test_additional_loss 1.0267e+00\n",
      "step 21, train_loss 2.9818e-01, additional_loss 1.2770e-01, test_loss 1.1862e+00, test_additional_loss 1.0659e+00\n",
      "step 22, train_loss 2.9887e-01, additional_loss 1.3661e-01, test_loss 1.2075e+00, test_additional_loss 1.0895e+00\n",
      "step 23, train_loss 3.4091e-01, additional_loss 1.8477e-01, test_loss 1.2578e+00, test_additional_loss 1.1418e+00\n",
      "step 24, train_loss 2.7559e-01, additional_loss 1.2722e-01, test_loss 1.3210e+00, test_additional_loss 1.2066e+00\n",
      "step 25, train_loss 2.8013e-01, additional_loss 1.3957e-01, test_loss 1.3821e+00, test_additional_loss 1.2694e+00\n",
      "step 26, train_loss 3.5279e-01, additional_loss 2.1286e-01, test_loss 1.3633e+00, test_additional_loss 1.2522e+00\n",
      "step 27, train_loss 3.1894e-01, additional_loss 1.7762e-01, test_loss 1.3533e+00, test_additional_loss 1.2451e+00\n",
      "step 28, train_loss 2.7318e-01, additional_loss 1.3199e-01, test_loss 1.3306e+00, test_additional_loss 1.2240e+00\n",
      "step 29, train_loss 2.9665e-01, additional_loss 1.5492e-01, test_loss 1.3261e+00, test_additional_loss 1.2197e+00\n",
      "step 30, train_loss 2.2042e-01, additional_loss 7.4100e-02, test_loss 1.3270e+00, test_additional_loss 1.2200e+00\n",
      "step 31, train_loss 3.7063e-01, additional_loss 2.1739e-01, test_loss 1.2980e+00, test_additional_loss 1.1907e+00\n",
      "step 32, train_loss 3.0658e-01, additional_loss 1.4930e-01, test_loss 1.2971e+00, test_additional_loss 1.1898e+00\n",
      "step 33, train_loss 2.7485e-01, additional_loss 1.1649e-01, test_loss 1.2830e+00, test_additional_loss 1.1744e+00\n",
      "step 34, train_loss 2.9045e-01, additional_loss 1.2789e-01, test_loss 1.2458e+00, test_additional_loss 1.1348e+00\n",
      "step 35, train_loss 2.3665e-01, additional_loss 6.7568e-02, test_loss 1.2068e+00, test_additional_loss 1.0938e+00\n",
      "step 36, train_loss 2.9959e-01, additional_loss 1.2960e-01, test_loss 1.1740e+00, test_additional_loss 1.0596e+00\n",
      "step 37, train_loss 2.3920e-01, additional_loss 6.8474e-02, test_loss 1.2074e+00, test_additional_loss 1.0936e+00\n",
      "step 38, train_loss 2.8363e-01, additional_loss 1.1344e-01, test_loss 1.2302e+00, test_additional_loss 1.1183e+00\n",
      "step 39, train_loss 2.8242e-01, additional_loss 1.1559e-01, test_loss 1.2018e+00, test_additional_loss 1.0910e+00\n",
      "step 40, train_loss 1.9242e-01, additional_loss 2.6655e-02, test_loss 1.2583e+00, test_additional_loss 1.1522e+00\n",
      "step 41, train_loss 3.1174e-01, additional_loss 1.5569e-01, test_loss 1.2857e+00, test_additional_loss 1.1813e+00\n",
      "step 42, train_loss 2.5199e-01, additional_loss 1.0443e-01, test_loss 1.3585e+00, test_additional_loss 1.2551e+00\n",
      "step 43, train_loss 2.2252e-01, additional_loss 7.8964e-02, test_loss 1.4276e+00, test_additional_loss 1.3264e+00\n",
      "step 44, train_loss 2.1987e-01, additional_loss 8.2827e-02, test_loss 1.4483e+00, test_additional_loss 1.3503e+00\n",
      "step 45, train_loss 2.6018e-01, additional_loss 1.3170e-01, test_loss 1.4784e+00, test_additional_loss 1.3813e+00\n",
      "step 46, train_loss 2.1913e-01, additional_loss 9.5367e-02, test_loss 1.4952e+00, test_additional_loss 1.3958e+00\n",
      "step 47, train_loss 2.3786e-01, additional_loss 1.1735e-01, test_loss 1.5225e+00, test_additional_loss 1.4227e+00\n",
      "step 48, train_loss 2.2119e-01, additional_loss 1.0438e-01, test_loss 1.5514e+00, test_additional_loss 1.4528e+00\n",
      "step 49, train_loss 1.9709e-01, additional_loss 8.6403e-02, test_loss 1.5579e+00, test_additional_loss 1.4585e+00\n",
      "step 50, train_loss 1.6957e-01, additional_loss 5.9795e-02, test_loss 1.5759e+00, test_additional_loss 1.4764e+00\n",
      "Val metric improved. 1.5758649110794067 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137557.251158.pt\n",
      "Final train loss 1.0832e-01 +/- 2.3517e-01\n",
      "Final test loss 9.9482e-02 +/- 1.5357e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-4_t_span_min-0_t_span_max-4.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-2_time_scale-4_t_span_min-0_t_span_max-4.pkl not found.\n",
      "Creating new data...\n",
      "step 0, train_loss 8.0644e+03, additional_loss 1.3591e+03, test_loss 7.3669e-01, test_additional_loss 3.8829e-01\n",
      "step 1, train_loss 6.7511e+03, additional_loss 4.5079e+01, test_loss 5.5503e-01, test_additional_loss 2.0099e-01\n",
      "step 2, train_loss 6.8189e+03, additional_loss 1.1398e+02, test_loss 4.1765e-01, test_additional_loss 7.0786e-02\n",
      "step 3, train_loss 6.7354e+03, additional_loss 3.0569e+01, test_loss 3.9537e-01, test_additional_loss 5.3740e-02\n",
      "step 4, train_loss 6.7232e+03, additional_loss 1.8310e+01, test_loss 3.6303e-01, test_additional_loss 2.1005e-02\n",
      "step 5, train_loss 6.7113e+03, additional_loss 6.4121e+00, test_loss 3.4999e-01, test_additional_loss 6.9618e-03\n",
      "step 6, train_loss 6.7110e+03, additional_loss 6.1169e+00, test_loss 3.4546e-01, test_additional_loss 2.2650e-03\n",
      "step 7, train_loss 6.7068e+03, additional_loss 1.9295e+00, test_loss 3.4954e-01, test_additional_loss 6.2704e-03\n",
      "step 8, train_loss 6.7073e+03, additional_loss 2.4506e+00, test_loss 3.4710e-01, test_additional_loss 3.8624e-03\n",
      "step 9, train_loss 6.7061e+03, additional_loss 1.2753e+00, test_loss 3.4428e-01, test_additional_loss 1.1444e-03\n",
      "step 10, train_loss 6.7051e+03, additional_loss 2.2697e-01, test_loss 3.4371e-01, test_additional_loss 6.9141e-04\n",
      "step 11, train_loss 6.7049e+03, additional_loss 8.9645e-02, test_loss 3.4379e-01, test_additional_loss 8.3447e-04\n",
      "step 12, train_loss 6.7051e+03, additional_loss 2.0943e-01, test_loss 3.4356e-01, test_additional_loss 6.4373e-04\n",
      "step 13, train_loss 6.7049e+03, additional_loss 4.1962e-02, test_loss 3.4449e-01, test_additional_loss 1.5974e-03\n",
      "step 14, train_loss 6.7051e+03, additional_loss 2.0943e-01, test_loss 3.4439e-01, test_additional_loss 1.5020e-03\n",
      "step 15, train_loss 6.7050e+03, additional_loss 1.4877e-01, test_loss 3.4391e-01, test_additional_loss 1.0252e-03\n",
      "step 16, train_loss 6.7049e+03, additional_loss 1.1444e-02, test_loss 3.4365e-01, test_additional_loss 7.6294e-04\n",
      "step 17, train_loss 6.7049e+03, additional_loss 8.0109e-03, test_loss 3.4358e-01, test_additional_loss 6.9141e-04\n",
      "step 18, train_loss 6.7049e+03, additional_loss 3.9291e-02, test_loss 3.4344e-01, test_additional_loss 5.4836e-04\n",
      "step 19, train_loss 6.7049e+03, additional_loss 3.8528e-02, test_loss 3.4330e-01, test_additional_loss 4.0531e-04\n",
      "step 20, train_loss 6.7049e+03, additional_loss 1.1826e-02, test_loss 3.4332e-01, test_additional_loss 4.2915e-04\n",
      "step 21, train_loss 6.7049e+03, additional_loss 1.2589e-02, test_loss 3.4329e-01, test_additional_loss 4.0531e-04\n",
      "step 22, train_loss 6.7049e+03, additional_loss 2.9755e-02, test_loss 3.4330e-01, test_additional_loss 4.0531e-04\n",
      "step 23, train_loss 6.7049e+03, additional_loss 1.9836e-02, test_loss 3.4332e-01, test_additional_loss 4.2915e-04\n",
      "step 24, train_loss 6.7049e+03, additional_loss 1.3351e-02, test_loss 3.4332e-01, test_additional_loss 4.2915e-04\n",
      "step 25, train_loss 6.7049e+03, additional_loss 1.2589e-02, test_loss 3.4332e-01, test_additional_loss 4.2915e-04\n",
      "step 26, train_loss 6.7049e+03, additional_loss 1.2589e-02, test_loss 3.4332e-01, test_additional_loss 4.2915e-04\n",
      "step 27, train_loss 6.7049e+03, additional_loss 1.4114e-02, test_loss 3.4332e-01, test_additional_loss 4.2915e-04\n",
      "step 28, train_loss 6.7049e+03, additional_loss 1.2589e-02, test_loss 3.4330e-01, test_additional_loss 4.0531e-04\n",
      "step 29, train_loss 6.7049e+03, additional_loss 1.4114e-02, test_loss 3.4327e-01, test_additional_loss 3.8147e-04\n",
      "step 30, train_loss 6.7049e+03, additional_loss 3.0518e-02, test_loss 3.4325e-01, test_additional_loss 3.5763e-04\n",
      "step 31, train_loss 6.7049e+03, additional_loss 1.1826e-02, test_loss 3.4334e-01, test_additional_loss 4.5300e-04\n",
      "step 32, train_loss 6.7049e+03, additional_loss 3.0518e-02, test_loss 3.4327e-01, test_additional_loss 3.8147e-04\n",
      "step 33, train_loss 6.7049e+03, additional_loss 1.0300e-02, test_loss 3.4327e-01, test_additional_loss 3.8147e-04\n",
      "step 34, train_loss 6.7049e+03, additional_loss 1.4114e-02, test_loss 3.4329e-01, test_additional_loss 4.0531e-04\n",
      "step 35, train_loss 6.7049e+03, additional_loss 2.8992e-02, test_loss 3.4336e-01, test_additional_loss 4.7684e-04\n",
      "step 36, train_loss 6.7049e+03, additional_loss 3.1281e-02, test_loss 3.4327e-01, test_additional_loss 3.8147e-04\n",
      "step 37, train_loss 6.7049e+03, additional_loss 1.4114e-02, test_loss 3.4327e-01, test_additional_loss 3.8147e-04\n",
      "step 38, train_loss 6.7049e+03, additional_loss 1.4877e-02, test_loss 3.4330e-01, test_additional_loss 4.0531e-04\n",
      "step 39, train_loss 6.7049e+03, additional_loss 1.7166e-02, test_loss 3.4325e-01, test_additional_loss 3.5763e-04\n",
      "step 40, train_loss 6.7049e+03, additional_loss 1.2970e-02, test_loss 3.4325e-01, test_additional_loss 3.5763e-04\n",
      "step 41, train_loss 6.7049e+03, additional_loss 1.5640e-02, test_loss 3.4325e-01, test_additional_loss 3.5763e-04\n",
      "step 42, train_loss 6.7049e+03, additional_loss 1.2589e-02, test_loss 3.4325e-01, test_additional_loss 3.5763e-04\n",
      "step 43, train_loss 6.7049e+03, additional_loss 1.1063e-02, test_loss 3.4325e-01, test_additional_loss 3.5763e-04\n",
      "step 44, train_loss 6.7049e+03, additional_loss 1.8692e-02, test_loss 3.4325e-01, test_additional_loss 3.5763e-04\n",
      "step 45, train_loss 6.7049e+03, additional_loss 1.6403e-02, test_loss 3.4327e-01, test_additional_loss 3.8147e-04\n",
      "step 46, train_loss 6.7049e+03, additional_loss 1.3351e-02, test_loss 3.4332e-01, test_additional_loss 4.2915e-04\n",
      "step 47, train_loss 6.7049e+03, additional_loss 1.1826e-02, test_loss 3.4330e-01, test_additional_loss 4.0531e-04\n",
      "step 48, train_loss 6.7049e+03, additional_loss 6.8665e-03, test_loss 3.4325e-01, test_additional_loss 3.5763e-04\n",
      "step 49, train_loss 6.7049e+03, additional_loss 1.4877e-02, test_loss 3.4330e-01, test_additional_loss 4.0531e-04\n",
      "step 50, train_loss 6.7049e+03, additional_loss 5.6458e-02, test_loss 3.4325e-01, test_additional_loss 3.5763e-04\n",
      "Val metric improved. 0.34324800968170166 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137558.152148.pt\n",
      "Final train loss 6.7049e+03 +/- 6.4485e+04\n",
      "Final test loss 3.4289e-01 +/- 4.5451e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "step 0, train_loss 9.6814e-02, additional_loss 1.3113e-04, test_loss 1.1942e-01, test_additional_loss 2.5034e-04\n",
      "step 1, train_loss 9.6797e-02, additional_loss 1.1921e-04, test_loss 1.1943e-01, test_additional_loss 2.7418e-04\n",
      "step 2, train_loss 9.6771e-02, additional_loss 1.1921e-04, test_loss 1.1943e-01, test_additional_loss 3.0994e-04\n",
      "step 3, train_loss 9.6778e-02, additional_loss 1.5497e-04, test_loss 1.1941e-01, test_additional_loss 3.2187e-04\n",
      "step 4, train_loss 9.6726e-02, additional_loss 9.5367e-05, test_loss 1.1950e-01, test_additional_loss 4.6492e-04\n",
      "step 5, train_loss 9.6714e-02, additional_loss 1.3113e-04, test_loss 1.1958e-01, test_additional_loss 6.4373e-04\n",
      "step 6, train_loss 9.6503e-02, additional_loss 1.1921e-04, test_loss 1.1912e-01, test_additional_loss 3.4571e-04\n",
      "step 7, train_loss 9.5893e-02, additional_loss 1.6689e-04, test_loss 1.1919e-01, test_additional_loss 4.2915e-04\n",
      "step 8, train_loss 9.5136e-02, additional_loss 6.5565e-04, test_loss 1.2000e-01, test_additional_loss 9.5367e-04\n",
      "step 9, train_loss 9.4759e-02, additional_loss 1.3232e-03, test_loss 1.2051e-01, test_additional_loss 9.8944e-04\n",
      "step 10, train_loss 9.3968e-02, additional_loss 2.1815e-03, test_loss 1.2082e-01, test_additional_loss 1.3471e-03\n",
      "step 11, train_loss 8.8960e-02, additional_loss 1.5736e-03, test_loss 1.2131e-01, test_additional_loss 2.1935e-03\n",
      "step 12, train_loss 8.6933e-02, additional_loss 5.4717e-03, test_loss 1.2485e-01, test_additional_loss 5.7220e-03\n",
      "step 13, train_loss 7.2535e-02, additional_loss 2.2769e-03, test_loss 1.2540e-01, test_additional_loss 7.1764e-03\n",
      "step 14, train_loss 6.8132e-02, additional_loss 1.3483e-02, test_loss 1.3236e-01, test_additional_loss 1.2755e-02\n",
      "step 15, train_loss 4.4098e-02, additional_loss 6.1870e-03, test_loss 1.5417e-01, test_additional_loss 2.7514e-02\n",
      "step 16, train_loss 6.7386e-02, additional_loss 4.3166e-02, test_loss 1.6540e-01, test_additional_loss 3.3545e-02\n",
      "step 17, train_loss 4.6765e-02, additional_loss 2.8479e-02, test_loss 1.7365e-01, test_additional_loss 3.4618e-02\n",
      "step 18, train_loss 3.9015e-02, additional_loss 2.4331e-02, test_loss 1.7922e-01, test_additional_loss 2.8265e-02\n",
      "step 19, train_loss 3.7389e-02, additional_loss 2.3782e-02, test_loss 1.6436e-01, test_additional_loss 1.2863e-02\n",
      "step 20, train_loss 5.9779e-02, additional_loss 4.4954e-02, test_loss 1.5802e-01, test_additional_loss 5.3525e-03\n",
      "step 21, train_loss 4.1356e-02, additional_loss 2.6846e-02, test_loss 1.6991e-01, test_additional_loss 5.3406e-03\n",
      "step 22, train_loss 6.5526e-02, additional_loss 5.4085e-02, test_loss 1.5370e-01, test_additional_loss 5.2691e-03\n",
      "step 23, train_loss 3.8144e-02, additional_loss 2.7347e-02, test_loss 1.5148e-01, test_additional_loss 6.4611e-03\n",
      "step 24, train_loss 4.2777e-02, additional_loss 3.0923e-02, test_loss 1.5244e-01, test_additional_loss 9.7036e-03\n",
      "step 25, train_loss 7.1423e-02, additional_loss 5.7876e-02, test_loss 1.5013e-01, test_additional_loss 1.0204e-02\n",
      "step 26, train_loss 5.7655e-02, additional_loss 4.1628e-02, test_loss 1.4599e-01, test_additional_loss 8.8573e-03\n",
      "step 27, train_loss 3.8243e-02, additional_loss 1.9562e-02, test_loss 1.5506e-01, test_additional_loss 8.4400e-03\n",
      "step 28, train_loss 4.7223e-02, additional_loss 3.5155e-02, test_loss 1.7258e-01, test_additional_loss 7.8321e-03\n",
      "step 29, train_loss 4.4150e-02, additional_loss 3.5012e-02, test_loss 2.3455e-01, test_additional_loss 3.5048e-02\n",
      "step 30, train_loss 2.3769e-02, additional_loss 1.1265e-02, test_loss 2.4070e-01, test_additional_loss 5.0187e-02\n",
      "step 31, train_loss 5.4231e-02, additional_loss 4.2665e-02, test_loss 2.4884e-01, test_additional_loss 7.1430e-02\n",
      "step 32, train_loss 3.6167e-02, additional_loss 2.4223e-02, test_loss 2.4183e-01, test_additional_loss 7.4935e-02\n",
      "step 33, train_loss 2.9321e-02, additional_loss 1.8287e-02, test_loss 2.3665e-01, test_additional_loss 8.1491e-02\n",
      "step 34, train_loss 4.2897e-02, additional_loss 3.2616e-02, test_loss 2.2317e-01, test_additional_loss 7.6997e-02\n",
      "step 35, train_loss 5.0599e-02, additional_loss 4.0519e-02, test_loss 2.1244e-01, test_additional_loss 7.1180e-02\n",
      "step 36, train_loss 4.2328e-02, additional_loss 2.9624e-02, test_loss 2.0109e-01, test_additional_loss 6.5827e-02\n",
      "step 37, train_loss 2.3235e-02, additional_loss 8.1062e-03, test_loss 2.0836e-01, test_additional_loss 7.2801e-02\n",
      "step 38, train_loss 5.3121e-02, additional_loss 4.1497e-02, test_loss 2.1284e-01, test_additional_loss 7.4315e-02\n",
      "step 39, train_loss 5.5235e-02, additional_loss 4.5395e-02, test_loss 2.0327e-01, test_additional_loss 6.3443e-02\n",
      "step 40, train_loss 2.4950e-02, additional_loss 1.6010e-02, test_loss 1.9218e-01, test_additional_loss 5.4026e-02\n",
      "step 41, train_loss 5.1602e-02, additional_loss 4.4501e-02, test_loss 1.7194e-01, test_additional_loss 3.7575e-02\n",
      "step 42, train_loss 5.8408e-02, additional_loss 5.0557e-02, test_loss 1.6526e-01, test_additional_loss 3.3176e-02\n",
      "step 43, train_loss 2.8272e-02, additional_loss 1.6809e-02, test_loss 1.6459e-01, test_additional_loss 3.1292e-02\n",
      "step 44, train_loss 4.7858e-02, additional_loss 3.0470e-02, test_loss 1.6705e-01, test_additional_loss 3.3915e-02\n",
      "step 45, train_loss 6.2958e-02, additional_loss 4.4394e-02, test_loss 1.6554e-01, test_additional_loss 3.4237e-02\n",
      "step 46, train_loss 4.4583e-02, additional_loss 2.7978e-02, test_loss 1.5812e-01, test_additional_loss 2.9099e-02\n",
      "step 47, train_loss 6.2207e-02, additional_loss 5.1987e-02, test_loss 1.5803e-01, test_additional_loss 3.1447e-02\n",
      "step 48, train_loss 4.6389e-02, additional_loss 3.7754e-02, test_loss 1.6000e-01, test_additional_loss 3.0839e-02\n",
      "step 49, train_loss 3.9702e-02, additional_loss 3.0351e-02, test_loss 1.5958e-01, test_additional_loss 2.7466e-02\n",
      "step 50, train_loss 4.0917e-02, additional_loss 2.9814e-02, test_loss 1.6309e-01, test_additional_loss 2.8896e-02\n",
      "Val metric improved. 0.16309122741222382 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137558.632131.pt\n",
      "Final train loss 1.2023e-02 +/- 2.3368e-02\n",
      "Final test loss 1.3419e-01 +/- 2.5186e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-3_time_scale-2_t_span_min-0_t_span_max-4.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-3_time_scale-2_t_span_min-0_t_span_max-4.pkl not found.\n",
      "Creating new data...\n",
      "step 0, train_loss 1.3272e+01, additional_loss 2.7432e-01, test_loss 7.4226e-01, test_additional_loss 5.0404e-01\n",
      "step 1, train_loss 3.0817e+01, additional_loss 1.7728e+01, test_loss 3.9549e-01, test_additional_loss 1.7861e-01\n",
      "step 2, train_loss 3.4330e+01, additional_loss 2.1263e+01, test_loss 2.5911e-01, test_additional_loss 4.8494e-02\n",
      "step 3, train_loss 1.5737e+01, additional_loss 2.7184e+00, test_loss 2.8015e-01, test_additional_loss 6.1917e-02\n",
      "step 4, train_loss 1.8201e+01, additional_loss 5.1934e+00, test_loss 2.5998e-01, test_additional_loss 4.3237e-02\n",
      "step 5, train_loss 1.5723e+01, additional_loss 2.7162e+00, test_loss 2.2910e-01, test_additional_loss 1.4353e-02\n",
      "step 6, train_loss 1.3510e+01, additional_loss 5.0302e-01, test_loss 2.1701e-01, test_additional_loss 3.0160e-03\n",
      "step 7, train_loss 1.3077e+01, additional_loss 7.1049e-02, test_loss 2.1511e-01, test_additional_loss 1.2517e-03\n",
      "step 8, train_loss 1.3007e+01, additional_loss 1.3828e-03, test_loss 2.1490e-01, test_additional_loss 1.0490e-03\n",
      "step 9, train_loss 1.3028e+01, additional_loss 2.2316e-02, test_loss 2.1452e-01, test_additional_loss 6.9141e-04\n",
      "step 10, train_loss 1.3010e+01, additional_loss 4.5776e-03, test_loss 2.1453e-01, test_additional_loss 7.1526e-04\n",
      "step 11, train_loss 1.3009e+01, additional_loss 3.1948e-03, test_loss 2.1443e-01, test_additional_loss 6.1989e-04\n",
      "step 12, train_loss 1.3008e+01, additional_loss 2.5749e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 13, train_loss 1.3007e+01, additional_loss 1.6212e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 14, train_loss 1.3007e+01, additional_loss 1.4305e-03, test_loss 2.1453e-01, test_additional_loss 7.1526e-04\n",
      "step 15, train_loss 1.3007e+01, additional_loss 1.4782e-03, test_loss 2.1442e-01, test_additional_loss 6.0797e-04\n",
      "step 16, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1452e-01, test_additional_loss 7.0333e-04\n",
      "step 17, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1466e-01, test_additional_loss 8.4639e-04\n",
      "step 18, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1462e-01, test_additional_loss 8.1062e-04\n",
      "step 19, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1462e-01, test_additional_loss 8.1062e-04\n",
      "step 20, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1457e-01, test_additional_loss 7.6294e-04\n",
      "step 21, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1453e-01, test_additional_loss 7.1526e-04\n",
      "step 22, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 23, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1454e-01, test_additional_loss 7.2718e-04\n",
      "step 24, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1454e-01, test_additional_loss 7.2718e-04\n",
      "step 25, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1454e-01, test_additional_loss 7.2718e-04\n",
      "step 26, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1454e-01, test_additional_loss 7.2718e-04\n",
      "step 27, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1454e-01, test_additional_loss 7.2718e-04\n",
      "step 28, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 29, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 30, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 31, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 32, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 33, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 34, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 35, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 36, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 37, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 38, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 39, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 40, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 41, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 42, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 43, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 44, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 45, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 46, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 47, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 48, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 49, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 50, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1455e-01, test_additional_loss 7.3910e-04\n",
      "Val metric improved. 0.2145514339208603 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137559.518337.pt\n",
      "Final train loss 1.3006e+01 +/- 6.2446e+01\n",
      "Final test loss 2.1381e-01 +/- 4.8780e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "step 0, train_loss 9.6027e-02, additional_loss 8.1062e-04, test_loss 1.2054e-01, test_additional_loss 1.3947e-03\n",
      "step 1, train_loss 9.5909e-02, additional_loss 5.6863e-03, test_loss 1.1964e-01, test_additional_loss 1.5497e-03\n",
      "step 2, train_loss 1.0371e-01, additional_loss 1.9550e-02, test_loss 1.1966e-01, test_additional_loss 9.7752e-04\n",
      "step 3, train_loss 9.1855e-02, additional_loss 5.0783e-03, test_loss 1.2053e-01, test_additional_loss 1.5736e-03\n",
      "step 4, train_loss 8.7549e-02, additional_loss 2.1219e-03, test_loss 1.2293e-01, test_additional_loss 3.5405e-03\n",
      "step 5, train_loss 8.1069e-02, additional_loss 1.1444e-03, test_loss 1.2704e-01, test_additional_loss 6.5088e-03\n",
      "step 6, train_loss 8.3499e-02, additional_loss 1.4138e-02, test_loss 1.3421e-01, test_additional_loss 1.1122e-02\n",
      "step 7, train_loss 7.4690e-02, additional_loss 2.2566e-02, test_loss 1.4996e-01, test_additional_loss 2.1696e-02\n",
      "step 8, train_loss 5.1741e-02, additional_loss 2.1780e-02, test_loss 1.7861e-01, test_additional_loss 4.6360e-02\n",
      "step 9, train_loss 8.3046e-02, additional_loss 6.2823e-02, test_loss 1.8381e-01, test_additional_loss 5.2106e-02\n",
      "step 10, train_loss 8.0441e-02, additional_loss 6.3324e-02, test_loss 1.6864e-01, test_additional_loss 4.0329e-02\n",
      "step 11, train_loss 4.9078e-02, additional_loss 3.3152e-02, test_loss 1.4978e-01, test_additional_loss 2.4939e-02\n",
      "step 12, train_loss 6.0567e-02, additional_loss 3.7682e-02, test_loss 1.4057e-01, test_additional_loss 1.7977e-02\n",
      "step 13, train_loss 5.8744e-02, additional_loss 2.7621e-02, test_loss 1.3611e-01, test_additional_loss 1.4973e-02\n",
      "step 14, train_loss 7.1422e-02, additional_loss 3.4451e-02, test_loss 1.3788e-01, test_additional_loss 1.5187e-02\n",
      "step 15, train_loss 6.4932e-02, additional_loss 2.8384e-02, test_loss 1.4984e-01, test_additional_loss 2.0719e-02\n",
      "step 16, train_loss 6.2120e-02, additional_loss 3.3629e-02, test_loss 1.6567e-01, test_additional_loss 2.7370e-02\n",
      "step 17, train_loss 2.7818e-02, additional_loss 9.8228e-03, test_loss 1.8639e-01, test_additional_loss 3.6931e-02\n",
      "step 18, train_loss 7.4441e-02, additional_loss 6.1715e-02, test_loss 1.8204e-01, test_additional_loss 3.7527e-02\n",
      "step 19, train_loss 4.8045e-02, additional_loss 3.3951e-02, test_loss 1.6992e-01, test_additional_loss 3.4559e-02\n",
      "step 20, train_loss 4.6475e-02, additional_loss 3.2794e-02, test_loss 1.5861e-01, test_additional_loss 2.9564e-02\n",
      "step 21, train_loss 5.5565e-02, additional_loss 4.0197e-02, test_loss 1.4931e-01, test_additional_loss 2.4080e-02\n",
      "step 22, train_loss 3.6812e-02, additional_loss 1.6606e-02, test_loss 1.5084e-01, test_additional_loss 2.3997e-02\n",
      "step 23, train_loss 4.0958e-02, additional_loss 1.7023e-02, test_loss 1.5387e-01, test_additional_loss 2.5594e-02\n",
      "step 24, train_loss 3.9216e-02, additional_loss 1.5557e-02, test_loss 1.6006e-01, test_additional_loss 2.9433e-02\n",
      "step 25, train_loss 3.4148e-02, additional_loss 1.4114e-02, test_loss 1.7009e-01, test_additional_loss 3.5572e-02\n",
      "step 26, train_loss 4.5507e-02, additional_loss 3.2306e-02, test_loss 1.8399e-01, test_additional_loss 4.2105e-02\n",
      "step 27, train_loss 4.4274e-02, additional_loss 3.4511e-02, test_loss 2.0152e-01, test_additional_loss 4.7886e-02\n",
      "step 28, train_loss 3.6723e-02, additional_loss 2.8253e-02, test_loss 2.1413e-01, test_additional_loss 5.0390e-02\n",
      "step 29, train_loss 3.8304e-02, additional_loss 2.9480e-02, test_loss 2.1414e-01, test_additional_loss 5.1415e-02\n",
      "step 30, train_loss 5.9172e-02, additional_loss 4.9281e-02, test_loss 2.0038e-01, test_additional_loss 4.8435e-02\n",
      "step 31, train_loss 3.3786e-02, additional_loss 2.1291e-02, test_loss 1.9017e-01, test_additional_loss 4.5764e-02\n",
      "step 32, train_loss 4.4662e-02, additional_loss 3.1590e-02, test_loss 1.7973e-01, test_additional_loss 4.2379e-02\n",
      "step 33, train_loss 4.8047e-02, additional_loss 3.4416e-02, test_loss 1.6958e-01, test_additional_loss 3.9542e-02\n",
      "step 34, train_loss 4.8213e-02, additional_loss 3.3700e-02, test_loss 1.6241e-01, test_additional_loss 3.5262e-02\n",
      "step 35, train_loss 3.6082e-02, additional_loss 1.9157e-02, test_loss 1.6495e-01, test_additional_loss 3.6836e-02\n",
      "step 36, train_loss 2.9830e-02, additional_loss 1.3769e-02, test_loss 1.7787e-01, test_additional_loss 4.0507e-02\n",
      "step 37, train_loss 2.1008e-02, additional_loss 8.7142e-03, test_loss 1.9053e-01, test_additional_loss 4.2808e-02\n",
      "step 38, train_loss 2.1235e-02, additional_loss 1.2076e-02, test_loss 2.0970e-01, test_additional_loss 4.5180e-02\n",
      "step 39, train_loss 2.6681e-02, additional_loss 1.9753e-02, test_loss 2.2931e-01, test_additional_loss 4.7576e-02\n",
      "step 40, train_loss 2.6737e-02, additional_loss 1.9968e-02, test_loss 2.2599e-01, test_additional_loss 4.5109e-02\n",
      "step 41, train_loss 2.6352e-02, additional_loss 2.0027e-02, test_loss 2.1534e-01, test_additional_loss 4.2045e-02\n",
      "step 42, train_loss 3.2506e-02, additional_loss 2.4390e-02, test_loss 2.0582e-01, test_additional_loss 3.9089e-02\n",
      "step 43, train_loss 3.8477e-02, additional_loss 2.7335e-02, test_loss 2.0637e-01, test_additional_loss 3.8016e-02\n",
      "step 44, train_loss 4.2372e-02, additional_loss 2.7835e-02, test_loss 2.0754e-01, test_additional_loss 3.7158e-02\n",
      "step 45, train_loss 2.4923e-02, additional_loss 1.0371e-02, test_loss 2.2612e-01, test_additional_loss 4.1461e-02\n",
      "step 46, train_loss 6.6958e-02, additional_loss 5.7006e-02, test_loss 2.3430e-01, test_additional_loss 4.5133e-02\n",
      "step 47, train_loss 4.8428e-02, additional_loss 3.9995e-02, test_loss 2.2878e-01, test_additional_loss 3.6955e-02\n",
      "step 48, train_loss 3.8245e-02, additional_loss 2.9254e-02, test_loss 2.0919e-01, test_additional_loss 2.7096e-02\n",
      "step 49, train_loss 5.0529e-02, additional_loss 3.9816e-02, test_loss 1.9057e-01, test_additional_loss 2.6238e-02\n",
      "step 50, train_loss 5.9480e-02, additional_loss 4.6098e-02, test_loss 1.7330e-01, test_additional_loss 2.4283e-02\n",
      "Val metric improved. 0.17329668998718262 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137560.026135.pt\n",
      "Final train loss 1.5248e-02 +/- 2.7204e-02\n",
      "Final test loss 1.4901e-01 +/- 3.0334e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-5_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-5_time_scale-1_t_span_min-0_t_span_max-4.pkl not found.\n",
      "Creating new data...\n",
      "step 0, train_loss 6.5962e-01, additional_loss 3.8683e-02, test_loss 2.5851e+00, test_additional_loss 2.2641e+00\n",
      "step 1, train_loss 3.1213e+00, additional_loss 2.5223e+00, test_loss 1.0181e+00, test_additional_loss 7.7443e-01\n",
      "step 2, train_loss 9.3024e+00, additional_loss 8.6867e+00, test_loss 3.6952e-01, test_additional_loss 1.6022e-01\n",
      "step 3, train_loss 2.5327e+00, additional_loss 1.9308e+00, test_loss 2.8270e-01, test_additional_loss 6.7472e-02\n",
      "step 4, train_loss 8.9661e-01, additional_loss 2.7838e-01, test_loss 2.3608e-01, test_additional_loss 2.2888e-02\n",
      "step 5, train_loss 6.8043e-01, additional_loss 6.1345e-02, test_loss 2.2698e-01, test_additional_loss 1.5068e-02\n",
      "step 6, train_loss 6.6655e-01, additional_loss 4.7159e-02, test_loss 2.1676e-01, test_additional_loss 5.2452e-03\n",
      "step 7, train_loss 6.4290e-01, additional_loss 2.3329e-02, test_loss 2.1428e-01, test_additional_loss 2.9564e-03\n",
      "step 8, train_loss 6.2550e-01, additional_loss 6.0439e-03, test_loss 2.1560e-01, test_additional_loss 4.3869e-03\n",
      "step 9, train_loss 6.2417e-01, additional_loss 4.6611e-03, test_loss 2.1584e-01, test_additional_loss 4.6730e-03\n",
      "step 10, train_loss 6.2272e-01, additional_loss 3.1590e-03, test_loss 2.1583e-01, test_additional_loss 4.6730e-03\n",
      "step 11, train_loss 6.2201e-01, additional_loss 2.4319e-03, test_loss 2.1539e-01, test_additional_loss 4.2439e-03\n",
      "step 12, train_loss 6.2185e-01, additional_loss 2.2650e-03, test_loss 2.1483e-01, test_additional_loss 3.6716e-03\n",
      "step 13, train_loss 6.2185e-01, additional_loss 2.2531e-03, test_loss 2.1455e-01, test_additional_loss 3.3855e-03\n",
      "step 14, train_loss 6.2174e-01, additional_loss 2.1458e-03, test_loss 2.1412e-01, test_additional_loss 2.9564e-03\n",
      "step 15, train_loss 6.2161e-01, additional_loss 2.0146e-03, test_loss 2.1341e-01, test_additional_loss 2.2411e-03\n",
      "step 16, train_loss 6.2172e-01, additional_loss 2.1219e-03, test_loss 2.1332e-01, test_additional_loss 2.1458e-03\n",
      "step 17, train_loss 6.2173e-01, additional_loss 2.1338e-03, test_loss 2.1299e-01, test_additional_loss 1.8120e-03\n",
      "step 18, train_loss 6.2173e-01, additional_loss 2.1338e-03, test_loss 2.1294e-01, test_additional_loss 1.7643e-03\n",
      "step 19, train_loss 6.2167e-01, additional_loss 2.0742e-03, test_loss 2.1285e-01, test_additional_loss 1.6689e-03\n",
      "step 20, train_loss 6.2165e-01, additional_loss 2.0504e-03, test_loss 2.1285e-01, test_additional_loss 1.6689e-03\n",
      "step 21, train_loss 6.2148e-01, additional_loss 1.8835e-03, test_loss 2.1271e-01, test_additional_loss 1.5259e-03\n",
      "step 22, train_loss 6.2139e-01, additional_loss 1.7881e-03, test_loss 2.1285e-01, test_additional_loss 1.6689e-03\n",
      "step 23, train_loss 6.2086e-01, additional_loss 1.2517e-03, test_loss 2.1276e-01, test_additional_loss 1.5736e-03\n",
      "step 24, train_loss 6.2099e-01, additional_loss 1.3709e-03, test_loss 2.1285e-01, test_additional_loss 1.6689e-03\n",
      "step 25, train_loss 6.2120e-01, additional_loss 1.5855e-03, test_loss 2.1290e-01, test_additional_loss 1.7166e-03\n",
      "step 26, train_loss 6.2100e-01, additional_loss 1.3828e-03, test_loss 2.1261e-01, test_additional_loss 1.4305e-03\n",
      "step 27, train_loss 6.2114e-01, additional_loss 1.5259e-03, test_loss 2.1295e-01, test_additional_loss 1.7643e-03\n",
      "step 28, train_loss 6.2117e-01, additional_loss 1.5616e-03, test_loss 2.1280e-01, test_additional_loss 1.6212e-03\n",
      "step 29, train_loss 6.2109e-01, additional_loss 1.4901e-03, test_loss 2.1256e-01, test_additional_loss 1.3828e-03\n",
      "step 30, train_loss 6.2093e-01, additional_loss 1.3232e-03, test_loss 2.1285e-01, test_additional_loss 1.6689e-03\n",
      "step 31, train_loss 6.2088e-01, additional_loss 1.2755e-03, test_loss 2.1304e-01, test_additional_loss 1.8597e-03\n",
      "step 32, train_loss 6.2075e-01, additional_loss 1.1444e-03, test_loss 2.1280e-01, test_additional_loss 1.6212e-03\n",
      "step 33, train_loss 6.2136e-01, additional_loss 1.7524e-03, test_loss 2.1270e-01, test_additional_loss 1.5259e-03\n",
      "step 34, train_loss 6.2104e-01, additional_loss 1.4305e-03, test_loss 2.1270e-01, test_additional_loss 1.5259e-03\n",
      "step 35, train_loss 6.2053e-01, additional_loss 9.2983e-04, test_loss 2.1280e-01, test_additional_loss 1.6212e-03\n",
      "step 36, train_loss 6.2040e-01, additional_loss 7.9870e-04, test_loss 2.1266e-01, test_additional_loss 1.4782e-03\n",
      "step 37, train_loss 6.2051e-01, additional_loss 9.1791e-04, test_loss 2.1280e-01, test_additional_loss 1.6212e-03\n",
      "step 38, train_loss 6.2031e-01, additional_loss 7.1526e-04, test_loss 2.1270e-01, test_additional_loss 1.5259e-03\n",
      "step 39, train_loss 6.1995e-01, additional_loss 3.5763e-04, test_loss 2.1260e-01, test_additional_loss 1.4305e-03\n",
      "step 40, train_loss 6.2013e-01, additional_loss 5.3644e-04, test_loss 2.1270e-01, test_additional_loss 1.5259e-03\n",
      "step 41, train_loss 6.1982e-01, additional_loss 2.3842e-04, test_loss 2.1270e-01, test_additional_loss 1.5259e-03\n",
      "step 42, train_loss 6.1989e-01, additional_loss 3.0994e-04, test_loss 2.1279e-01, test_additional_loss 1.6212e-03\n",
      "step 43, train_loss 6.1995e-01, additional_loss 3.6955e-04, test_loss 2.1294e-01, test_additional_loss 1.7643e-03\n",
      "step 44, train_loss 6.1999e-01, additional_loss 4.1723e-04, test_loss 2.1284e-01, test_additional_loss 1.6689e-03\n",
      "step 45, train_loss 6.1989e-01, additional_loss 3.0994e-04, test_loss 2.1270e-01, test_additional_loss 1.5259e-03\n",
      "step 46, train_loss 6.2015e-01, additional_loss 5.7220e-04, test_loss 2.1251e-01, test_additional_loss 1.3351e-03\n",
      "step 47, train_loss 6.2027e-01, additional_loss 6.9141e-04, test_loss 2.1256e-01, test_additional_loss 1.3828e-03\n",
      "step 48, train_loss 6.2030e-01, additional_loss 7.1526e-04, test_loss 2.1265e-01, test_additional_loss 1.4782e-03\n",
      "step 49, train_loss 6.2018e-01, additional_loss 5.9605e-04, test_loss 2.1261e-01, test_additional_loss 1.4305e-03\n",
      "step 50, train_loss 6.2023e-01, additional_loss 6.4373e-04, test_loss 2.1275e-01, test_additional_loss 1.5736e-03\n",
      "Val metric improved. 0.21274805068969727 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137560.930502.pt\n",
      "Final train loss 6.1958e-01 +/- 2.0308e+00\n",
      "Final test loss 2.1117e-01 +/- 5.6077e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-3_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-3_time_scale-1_t_span_min-0_t_span_max-4.pkl not found.\n",
      "Creating new data...\n",
      "step 0, train_loss 3.9202e+01, additional_loss 6.8264e-01, test_loss 1.9548e-01, test_additional_loss 1.0267e-01\n",
      "step 1, train_loss 4.0330e+01, additional_loss 1.8111e+00, test_loss 1.0484e-01, test_additional_loss 1.3494e-02\n",
      "step 2, train_loss 3.8576e+01, additional_loss 5.9271e-02, test_loss 9.9263e-02, test_additional_loss 8.2374e-03\n",
      "step 3, train_loss 3.8622e+01, additional_loss 1.0552e-01, test_loss 9.3287e-02, test_additional_loss 2.2769e-03\n",
      "step 4, train_loss 3.8525e+01, additional_loss 8.7738e-03, test_loss 9.1235e-02, test_additional_loss 2.1458e-04\n",
      "step 5, train_loss 3.8554e+01, additional_loss 3.7742e-02, test_loss 9.1111e-02, test_additional_loss 1.0729e-04\n",
      "step 6, train_loss 3.8540e+01, additional_loss 2.3293e-02, test_loss 9.1122e-02, test_additional_loss 1.3113e-04\n",
      "step 7, train_loss 3.8524e+01, additional_loss 7.2479e-03, test_loss 9.1081e-02, test_additional_loss 9.5367e-05\n",
      "step 8, train_loss 3.8522e+01, additional_loss 5.4121e-03, test_loss 9.1056e-02, test_additional_loss 7.1526e-05\n",
      "step 9, train_loss 3.8526e+01, additional_loss 8.9645e-03, test_loss 9.1131e-02, test_additional_loss 1.4305e-04\n",
      "step 10, train_loss 3.8522e+01, additional_loss 5.4359e-03, test_loss 9.1204e-02, test_additional_loss 2.1458e-04\n",
      "step 11, train_loss 3.8524e+01, additional_loss 7.2002e-03, test_loss 9.1168e-02, test_additional_loss 1.7881e-04\n",
      "step 12, train_loss 3.8525e+01, additional_loss 8.2254e-03, test_loss 9.1144e-02, test_additional_loss 1.5497e-04\n",
      "step 13, train_loss 3.8522e+01, additional_loss 5.6505e-03, test_loss 9.1155e-02, test_additional_loss 1.6689e-04\n",
      "step 14, train_loss 3.8522e+01, additional_loss 5.4836e-03, test_loss 9.1130e-02, test_additional_loss 1.4305e-04\n",
      "step 15, train_loss 3.8522e+01, additional_loss 5.4836e-03, test_loss 9.1069e-02, test_additional_loss 8.3447e-05\n",
      "step 16, train_loss 3.8524e+01, additional_loss 7.2479e-03, test_loss 9.1094e-02, test_additional_loss 1.0729e-04\n",
      "step 17, train_loss 3.8522e+01, additional_loss 5.4836e-03, test_loss 9.1142e-02, test_additional_loss 1.5497e-04\n",
      "step 18, train_loss 3.8522e+01, additional_loss 5.4836e-03, test_loss 9.1142e-02, test_additional_loss 1.5497e-04\n",
      "step 19, train_loss 3.8522e+01, additional_loss 5.4836e-03, test_loss 9.1167e-02, test_additional_loss 1.7881e-04\n",
      "step 20, train_loss 3.8522e+01, additional_loss 5.5075e-03, test_loss 9.1166e-02, test_additional_loss 1.7881e-04\n",
      "step 21, train_loss 3.8522e+01, additional_loss 5.5075e-03, test_loss 9.1107e-02, test_additional_loss 1.1921e-04\n",
      "step 22, train_loss 3.8522e+01, additional_loss 5.4836e-03, test_loss 9.1106e-02, test_additional_loss 1.1921e-04\n",
      "step 23, train_loss 3.8522e+01, additional_loss 5.4836e-03, test_loss 9.1106e-02, test_additional_loss 1.1921e-04\n",
      "step 24, train_loss 3.8522e+01, additional_loss 5.4359e-03, test_loss 9.1069e-02, test_additional_loss 8.3447e-05\n",
      "step 25, train_loss 3.8524e+01, additional_loss 7.2479e-03, test_loss 9.1070e-02, test_additional_loss 8.3447e-05\n",
      "step 26, train_loss 3.8522e+01, additional_loss 5.4598e-03, test_loss 9.1107e-02, test_additional_loss 1.1921e-04\n",
      "step 27, train_loss 3.8522e+01, additional_loss 5.4836e-03, test_loss 9.1107e-02, test_additional_loss 1.1921e-04\n",
      "step 28, train_loss 3.8522e+01, additional_loss 5.4836e-03, test_loss 9.1131e-02, test_additional_loss 1.4305e-04\n",
      "step 29, train_loss 3.8522e+01, additional_loss 5.4598e-03, test_loss 9.1143e-02, test_additional_loss 1.5497e-04\n",
      "step 30, train_loss 3.8523e+01, additional_loss 6.4373e-03, test_loss 9.1143e-02, test_additional_loss 1.5497e-04\n",
      "step 31, train_loss 3.8523e+01, additional_loss 6.4373e-03, test_loss 9.1131e-02, test_additional_loss 1.4305e-04\n",
      "step 32, train_loss 3.8522e+01, additional_loss 5.4598e-03, test_loss 9.1131e-02, test_additional_loss 1.4305e-04\n",
      "step 33, train_loss 3.8522e+01, additional_loss 5.4598e-03, test_loss 9.1107e-02, test_additional_loss 1.1921e-04\n",
      "step 34, train_loss 3.8522e+01, additional_loss 5.4598e-03, test_loss 9.1107e-02, test_additional_loss 1.1921e-04\n",
      "step 35, train_loss 3.8522e+01, additional_loss 5.4121e-03, test_loss 9.1107e-02, test_additional_loss 1.1921e-04\n",
      "step 36, train_loss 3.8522e+01, additional_loss 5.4121e-03, test_loss 9.1107e-02, test_additional_loss 1.1921e-04\n",
      "step 37, train_loss 3.8522e+01, additional_loss 5.3883e-03, test_loss 9.1107e-02, test_additional_loss 1.1921e-04\n",
      "step 38, train_loss 3.8522e+01, additional_loss 5.4359e-03, test_loss 9.1107e-02, test_additional_loss 1.1921e-04\n",
      "step 39, train_loss 3.8522e+01, additional_loss 5.3406e-03, test_loss 9.1119e-02, test_additional_loss 1.3113e-04\n",
      "step 40, train_loss 3.8523e+01, additional_loss 6.2704e-03, test_loss 9.1120e-02, test_additional_loss 1.3113e-04\n",
      "step 41, train_loss 3.8522e+01, additional_loss 5.3406e-03, test_loss 9.1132e-02, test_additional_loss 1.4305e-04\n",
      "step 42, train_loss 3.8522e+01, additional_loss 5.3406e-03, test_loss 9.1168e-02, test_additional_loss 1.7881e-04\n",
      "step 43, train_loss 3.8523e+01, additional_loss 6.4135e-03, test_loss 9.1168e-02, test_additional_loss 1.7881e-04\n",
      "step 44, train_loss 3.8523e+01, additional_loss 6.5088e-03, test_loss 9.1168e-02, test_additional_loss 1.7881e-04\n",
      "step 45, train_loss 3.8523e+01, additional_loss 6.4135e-03, test_loss 9.1144e-02, test_additional_loss 1.5497e-04\n",
      "step 46, train_loss 3.8523e+01, additional_loss 6.3896e-03, test_loss 9.1120e-02, test_additional_loss 1.3113e-04\n",
      "step 47, train_loss 3.8522e+01, additional_loss 5.3406e-03, test_loss 9.1096e-02, test_additional_loss 1.0729e-04\n",
      "step 48, train_loss 3.8522e+01, additional_loss 5.3883e-03, test_loss 9.1071e-02, test_additional_loss 8.3447e-05\n",
      "step 49, train_loss 3.8522e+01, additional_loss 5.2929e-03, test_loss 9.1058e-02, test_additional_loss 7.1526e-05\n",
      "step 50, train_loss 3.8528e+01, additional_loss 1.1420e-02, test_loss 9.1143e-02, test_additional_loss 1.5497e-04\n",
      "Val metric improved. 0.0911434069275856 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137561.780021.pt\n",
      "Final train loss 3.8516e+01 +/- 1.9541e+02\n",
      "Final test loss 9.0988e-02 +/- 1.7022e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "step 0, train_loss 9.6876e-02, additional_loss 1.7881e-04, test_loss 1.1950e-01, test_additional_loss 2.9802e-04\n",
      "step 1, train_loss 9.6778e-02, additional_loss 5.1260e-04, test_loss 1.1947e-01, test_additional_loss 2.5034e-04\n",
      "step 2, train_loss 9.6300e-02, additional_loss 4.1723e-04, test_loss 1.1965e-01, test_additional_loss 3.3379e-04\n",
      "step 3, train_loss 9.5512e-02, additional_loss 8.7023e-04, test_loss 1.2013e-01, test_additional_loss 5.7220e-04\n",
      "step 4, train_loss 9.2148e-02, additional_loss 6.4373e-04, test_loss 1.2135e-01, test_additional_loss 1.3351e-03\n",
      "step 5, train_loss 8.7617e-02, additional_loss 3.6478e-03, test_loss 1.2606e-01, test_additional_loss 3.4451e-03\n",
      "step 6, train_loss 6.8662e-02, additional_loss 3.1352e-03, test_loss 1.4316e-01, test_additional_loss 9.0480e-03\n",
      "step 7, train_loss 4.8076e-02, additional_loss 1.5771e-02, test_loss 1.7848e-01, test_additional_loss 2.3663e-02\n",
      "step 8, train_loss 1.2247e-01, additional_loss 1.0860e-01, test_loss 1.6730e-01, test_additional_loss 2.1541e-02\n",
      "step 9, train_loss 9.3401e-02, additional_loss 8.2541e-02, test_loss 1.6011e-01, test_additional_loss 2.2340e-02\n",
      "step 10, train_loss 5.8649e-02, additional_loss 4.3321e-02, test_loss 1.5293e-01, test_additional_loss 2.3723e-02\n",
      "step 11, train_loss 5.7973e-02, additional_loss 2.9516e-02, test_loss 1.4260e-01, test_additional_loss 1.9872e-02\n",
      "step 12, train_loss 4.3620e-02, additional_loss 7.8082e-03, test_loss 1.4042e-01, test_additional_loss 1.7083e-02\n",
      "step 13, train_loss 6.3193e-02, additional_loss 2.8610e-02, test_loss 1.3819e-01, test_additional_loss 1.5831e-02\n",
      "step 14, train_loss 6.3866e-02, additional_loss 3.0327e-02, test_loss 1.3712e-01, test_additional_loss 1.6820e-02\n",
      "step 15, train_loss 5.3009e-02, additional_loss 2.1088e-02, test_loss 1.4050e-01, test_additional_loss 1.9443e-02\n",
      "step 16, train_loss 6.1477e-02, additional_loss 3.4750e-02, test_loss 1.4767e-01, test_additional_loss 2.3472e-02\n",
      "step 17, train_loss 5.3025e-02, additional_loss 3.3176e-02, test_loss 1.5258e-01, test_additional_loss 2.7406e-02\n",
      "step 18, train_loss 8.5997e-02, additional_loss 6.9082e-02, test_loss 1.5450e-01, test_additional_loss 2.8169e-02\n",
      "step 19, train_loss 6.7834e-02, additional_loss 5.2023e-02, test_loss 1.5676e-01, test_additional_loss 2.8241e-02\n",
      "step 20, train_loss 4.7550e-02, additional_loss 3.1996e-02, test_loss 1.5339e-01, test_additional_loss 2.6655e-02\n",
      "step 21, train_loss 4.9935e-02, additional_loss 3.3903e-02, test_loss 1.4624e-01, test_additional_loss 2.3150e-02\n",
      "step 22, train_loss 3.1483e-02, additional_loss 1.4925e-02, test_loss 1.4528e-01, test_additional_loss 2.3234e-02\n",
      "step 23, train_loss 2.5800e-02, additional_loss 1.1194e-02, test_loss 1.4881e-01, test_additional_loss 2.5570e-02\n",
      "step 24, train_loss 3.7983e-02, additional_loss 2.6119e-02, test_loss 1.5049e-01, test_additional_loss 2.7537e-02\n",
      "step 25, train_loss 3.1738e-02, additional_loss 2.2209e-02, test_loss 1.4896e-01, test_additional_loss 2.7692e-02\n",
      "step 26, train_loss 3.7533e-02, additional_loss 3.0077e-02, test_loss 1.4707e-01, test_additional_loss 2.6810e-02\n",
      "step 27, train_loss 3.5291e-02, additional_loss 2.8300e-02, test_loss 1.4784e-01, test_additional_loss 2.7776e-02\n",
      "step 28, train_loss 2.9942e-02, additional_loss 2.2733e-02, test_loss 1.4847e-01, test_additional_loss 2.8229e-02\n",
      "step 29, train_loss 4.9830e-02, additional_loss 4.2057e-02, test_loss 1.4575e-01, test_additional_loss 2.6989e-02\n",
      "step 30, train_loss 5.4206e-02, additional_loss 4.5156e-02, test_loss 1.3551e-01, test_additional_loss 2.0373e-02\n",
      "step 31, train_loss 2.3191e-02, additional_loss 1.0812e-02, test_loss 1.2458e-01, test_additional_loss 1.3363e-02\n",
      "step 32, train_loss 5.8113e-02, additional_loss 4.3249e-02, test_loss 1.2217e-01, test_additional_loss 1.2720e-02\n",
      "step 33, train_loss 5.4666e-02, additional_loss 3.9172e-02, test_loss 1.2429e-01, test_additional_loss 1.5068e-02\n",
      "step 34, train_loss 5.5815e-02, additional_loss 4.0805e-02, test_loss 1.3251e-01, test_additional_loss 2.1696e-02\n",
      "step 35, train_loss 4.1967e-02, additional_loss 2.5177e-02, test_loss 1.4264e-01, test_additional_loss 2.9433e-02\n",
      "step 36, train_loss 3.4379e-02, additional_loss 1.6689e-02, test_loss 1.5748e-01, test_additional_loss 3.6931e-02\n",
      "step 37, train_loss 4.0222e-02, additional_loss 2.8014e-02, test_loss 1.7109e-01, test_additional_loss 4.4692e-02\n",
      "step 38, train_loss 3.7571e-02, additional_loss 2.8849e-02, test_loss 1.8257e-01, test_additional_loss 5.2333e-02\n",
      "step 39, train_loss 1.9954e-02, additional_loss 1.2457e-02, test_loss 1.9136e-01, test_additional_loss 5.7411e-02\n",
      "step 40, train_loss 6.4514e-02, additional_loss 5.7149e-02, test_loss 1.8987e-01, test_additional_loss 5.5051e-02\n",
      "step 41, train_loss 3.8257e-02, additional_loss 3.1137e-02, test_loss 1.8802e-01, test_additional_loss 5.0664e-02\n",
      "step 42, train_loss 6.0207e-02, additional_loss 5.2893e-02, test_loss 1.6991e-01, test_additional_loss 4.1711e-02\n",
      "step 43, train_loss 5.1164e-02, additional_loss 4.1521e-02, test_loss 1.5191e-01, test_additional_loss 3.2973e-02\n",
      "step 44, train_loss 2.9829e-02, additional_loss 1.5354e-02, test_loss 1.4720e-01, test_additional_loss 3.0899e-02\n",
      "step 45, train_loss 2.7904e-02, additional_loss 1.1814e-02, test_loss 1.4680e-01, test_additional_loss 3.3128e-02\n",
      "step 46, train_loss 2.7615e-02, additional_loss 1.4114e-02, test_loss 1.4857e-01, test_additional_loss 3.4654e-02\n",
      "step 47, train_loss 1.9198e-02, additional_loss 8.8573e-03, test_loss 1.5146e-01, test_additional_loss 3.4785e-02\n",
      "step 48, train_loss 3.6891e-02, additional_loss 2.8896e-02, test_loss 1.5053e-01, test_additional_loss 3.3927e-02\n",
      "step 49, train_loss 3.9571e-02, additional_loss 3.2794e-02, test_loss 1.4578e-01, test_additional_loss 3.1900e-02\n",
      "step 50, train_loss 3.3442e-02, additional_loss 2.7597e-02, test_loss 1.4463e-01, test_additional_loss 3.0649e-02\n",
      "Val metric improved. 0.14462557435035706 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137562.32511.pt\n",
      "Final train loss 5.2831e-03 +/- 1.1320e-02\n",
      "Final test loss 1.1398e-01 +/- 2.2284e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-9_t_span_min-0_t_span_max-4.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-2_time_scale-9_t_span_min-0_t_span_max-4.pkl not found.\n",
      "Creating new data...\n",
      "step 0, train_loss 6.8898e-01, additional_loss 2.7962e-01, test_loss 1.5924e+00, test_additional_loss 8.1701e-01\n",
      "step 1, train_loss 1.2240e+00, additional_loss 7.2994e-01, test_loss 1.3005e+00, test_additional_loss 4.3526e-01\n",
      "step 2, train_loss 8.8465e-01, additional_loss 3.2854e-01, test_loss 1.0922e+00, test_additional_loss 1.5850e-01\n",
      "step 3, train_loss 7.3186e-01, additional_loss 1.2026e-01, test_loss 1.0414e+00, test_additional_loss 8.4782e-02\n",
      "step 4, train_loss 6.8965e-01, additional_loss 5.6458e-02, test_loss 1.0162e+00, test_additional_loss 4.9973e-02\n",
      "step 5, train_loss 6.8949e-01, additional_loss 4.9305e-02, test_loss 1.0057e+00, test_additional_loss 3.4904e-02\n",
      "step 6, train_loss 6.5785e-01, additional_loss 1.5354e-02, test_loss 1.0485e+00, test_additional_loss 7.8487e-02\n",
      "step 7, train_loss 6.9013e-01, additional_loss 4.8542e-02, test_loss 1.0332e+00, test_additional_loss 6.2370e-02\n",
      "step 8, train_loss 6.7173e-01, additional_loss 3.1281e-02, test_loss 1.0023e+00, test_additional_loss 3.1471e-02\n",
      "step 9, train_loss 6.7121e-01, additional_loss 3.2902e-02, test_loss 1.0004e+00, test_additional_loss 3.2997e-02\n",
      "step 10, train_loss 6.6521e-01, additional_loss 3.0804e-02, test_loss 1.0032e+00, test_additional_loss 4.3297e-02\n",
      "step 11, train_loss 6.5160e-01, additional_loss 2.4319e-02, test_loss 1.0079e+00, test_additional_loss 5.8174e-02\n",
      "step 12, train_loss 6.4916e-01, additional_loss 3.0613e-02, test_loss 9.9870e-01, test_additional_loss 6.1321e-02\n",
      "step 13, train_loss 6.2658e-01, additional_loss 1.8120e-02, test_loss 1.0102e+00, test_additional_loss 9.5749e-02\n",
      "step 14, train_loss 6.0946e-01, additional_loss 2.2221e-02, test_loss 9.7830e-01, test_additional_loss 9.4700e-02\n",
      "step 15, train_loss 5.9706e-01, additional_loss 3.9673e-02, test_loss 1.0205e+00, test_additional_loss 1.7672e-01\n",
      "step 16, train_loss 6.0372e-01, additional_loss 8.6498e-02, test_loss 9.9318e-01, test_additional_loss 1.9579e-01\n",
      "step 17, train_loss 5.4671e-01, additional_loss 7.3719e-02, test_loss 9.9523e-01, test_additional_loss 2.4443e-01\n",
      "step 18, train_loss 5.8595e-01, additional_loss 1.5326e-01, test_loss 1.0231e+00, test_additional_loss 3.0422e-01\n",
      "step 19, train_loss 5.6584e-01, additional_loss 1.6212e-01, test_loss 8.9425e-01, test_additional_loss 1.9760e-01\n",
      "step 20, train_loss 4.3248e-01, additional_loss 5.0735e-02, test_loss 9.2574e-01, test_additional_loss 2.6655e-01\n",
      "step 21, train_loss 4.5813e-01, additional_loss 1.0796e-01, test_loss 1.0684e+00, test_additional_loss 4.4918e-01\n",
      "step 22, train_loss 5.2663e-01, additional_loss 2.0790e-01, test_loss 1.0245e+00, test_additional_loss 4.4518e-01\n",
      "step 23, train_loss 4.5871e-01, additional_loss 1.7385e-01, test_loss 1.0889e+00, test_additional_loss 5.5094e-01\n",
      "step 24, train_loss 5.1705e-01, additional_loss 2.6741e-01, test_loss 1.0658e+00, test_additional_loss 5.4684e-01\n",
      "step 25, train_loss 4.9781e-01, additional_loss 2.6178e-01, test_loss 9.4318e-01, test_additional_loss 4.3154e-01\n",
      "step 26, train_loss 4.0758e-01, additional_loss 1.7309e-01, test_loss 1.0666e+00, test_additional_loss 5.6868e-01\n",
      "step 27, train_loss 4.1334e-01, additional_loss 1.8692e-01, test_loss 9.0013e-01, test_additional_loss 4.1504e-01\n",
      "step 28, train_loss 3.2750e-01, additional_loss 1.1225e-01, test_loss 1.0606e+00, test_additional_loss 5.9071e-01\n",
      "step 29, train_loss 4.8685e-01, additional_loss 2.8400e-01, test_loss 1.0344e+00, test_additional_loss 5.6696e-01\n",
      "step 30, train_loss 4.7450e-01, additional_loss 2.7142e-01, test_loss 8.9869e-01, test_additional_loss 4.2248e-01\n",
      "step 31, train_loss 3.9653e-01, additional_loss 1.8291e-01, test_loss 9.2030e-01, test_additional_loss 4.3859e-01\n",
      "step 32, train_loss 3.8643e-01, additional_loss 1.6613e-01, test_loss 8.9183e-01, test_additional_loss 4.0894e-01\n",
      "step 33, train_loss 3.6858e-01, additional_loss 1.4496e-01, test_loss 8.9357e-01, test_additional_loss 4.1676e-01\n",
      "step 34, train_loss 3.4886e-01, additional_loss 1.2617e-01, test_loss 8.2662e-01, test_additional_loss 3.6507e-01\n",
      "step 35, train_loss 2.7812e-01, additional_loss 6.9809e-02, test_loss 8.3511e-01, test_additional_loss 4.0512e-01\n",
      "step 36, train_loss 3.1519e-01, additional_loss 1.2865e-01, test_loss 8.4827e-01, test_additional_loss 4.4184e-01\n",
      "step 37, train_loss 3.6333e-01, additional_loss 1.9159e-01, test_loss 9.1772e-01, test_additional_loss 5.2195e-01\n",
      "step 38, train_loss 4.0509e-01, additional_loss 2.3642e-01, test_loss 8.9184e-01, test_additional_loss 4.9610e-01\n",
      "step 39, train_loss 3.4986e-01, additional_loss 1.8253e-01, test_loss 8.2034e-01, test_additional_loss 4.1695e-01\n",
      "step 40, train_loss 2.7129e-01, additional_loss 1.0176e-01, test_loss 8.5329e-01, test_additional_loss 4.3888e-01\n",
      "step 41, train_loss 3.1233e-01, additional_loss 1.3657e-01, test_loss 8.8836e-01, test_additional_loss 4.5595e-01\n",
      "step 42, train_loss 3.5940e-01, additional_loss 1.7490e-01, test_loss 8.9496e-01, test_additional_loss 4.4680e-01\n",
      "step 43, train_loss 3.4935e-01, additional_loss 1.5373e-01, test_loss 8.8456e-01, test_additional_loss 4.3659e-01\n",
      "step 44, train_loss 3.0869e-01, additional_loss 1.1454e-01, test_loss 8.3783e-01, test_additional_loss 3.9949e-01\n",
      "step 45, train_loss 3.0982e-01, additional_loss 1.2293e-01, test_loss 8.2914e-01, test_additional_loss 4.0474e-01\n",
      "step 46, train_loss 2.2721e-01, additional_loss 5.3787e-02, test_loss 8.1944e-01, test_additional_loss 4.2295e-01\n",
      "step 47, train_loss 2.7263e-01, additional_loss 1.1702e-01, test_loss 8.8029e-01, test_additional_loss 5.0497e-01\n",
      "step 48, train_loss 3.4473e-01, additional_loss 1.9779e-01, test_loss 9.3501e-01, test_additional_loss 5.6782e-01\n",
      "step 49, train_loss 3.0155e-01, additional_loss 1.5907e-01, test_loss 8.9510e-01, test_additional_loss 5.3034e-01\n",
      "step 50, train_loss 3.0344e-01, additional_loss 1.6775e-01, test_loss 1.0579e+00, test_additional_loss 6.8903e-01\n",
      "Val metric improved. 1.057908058166504 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137563.14859.pt\n",
      "Final train loss 1.3829e-01 +/- 3.2900e-01\n",
      "Final test loss 3.6888e-01 +/- 6.1937e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "step 0, train_loss 3.3816e-01, additional_loss 1.1922e-01, test_loss 1.3949e-01, test_additional_loss 5.5993e-02\n",
      "step 1, train_loss 9.9165e-02, additional_loss 7.4065e-02, test_loss 1.1814e-01, test_additional_loss 9.7394e-03\n",
      "step 2, train_loss 8.3005e-02, additional_loss 1.8573e-02, test_loss 1.2049e-01, test_additional_loss 7.4029e-03\n",
      "step 3, train_loss 7.8612e-02, additional_loss 8.5235e-03, test_loss 1.2240e-01, test_additional_loss 7.6890e-03\n",
      "step 4, train_loss 8.0290e-02, additional_loss 1.2016e-02, test_loss 1.2550e-01, test_additional_loss 9.6679e-03\n",
      "step 5, train_loss 6.9734e-02, additional_loss 8.1778e-03, test_loss 1.3479e-01, test_additional_loss 1.6034e-02\n",
      "step 6, train_loss 6.4561e-02, additional_loss 1.5497e-02, test_loss 1.5085e-01, test_additional_loss 2.6405e-02\n",
      "step 7, train_loss 5.1238e-02, additional_loss 1.5128e-02, test_loss 1.6460e-01, test_additional_loss 3.7956e-02\n",
      "step 8, train_loss 6.1265e-02, additional_loss 3.6430e-02, test_loss 1.8535e-01, test_additional_loss 5.1129e-02\n",
      "step 9, train_loss 4.1081e-02, additional_loss 2.2495e-02, test_loss 2.2345e-01, test_additional_loss 6.7532e-02\n",
      "step 10, train_loss 5.9449e-02, additional_loss 4.3595e-02, test_loss 2.1933e-01, test_additional_loss 5.4359e-02\n",
      "step 11, train_loss 7.6296e-02, additional_loss 5.8687e-02, test_loss 1.7846e-01, test_additional_loss 3.6216e-02\n",
      "step 12, train_loss 3.1318e-02, additional_loss 5.9843e-03, test_loss 1.7305e-01, test_additional_loss 3.4916e-02\n",
      "step 13, train_loss 3.5186e-02, additional_loss 1.2064e-02, test_loss 1.7883e-01, test_additional_loss 4.1842e-02\n",
      "step 14, train_loss 4.1756e-02, additional_loss 2.3329e-02, test_loss 1.8332e-01, test_additional_loss 4.6575e-02\n",
      "step 15, train_loss 3.2016e-02, additional_loss 1.7405e-02, test_loss 1.8303e-01, test_additional_loss 4.6122e-02\n",
      "step 16, train_loss 3.1516e-02, additional_loss 2.0075e-02, test_loss 1.8914e-01, test_additional_loss 5.2261e-02\n",
      "step 17, train_loss 4.4783e-02, additional_loss 3.5286e-02, test_loss 1.9410e-01, test_additional_loss 5.7185e-02\n",
      "step 18, train_loss 3.8407e-02, additional_loss 2.9361e-02, test_loss 1.9740e-01, test_additional_loss 6.0666e-02\n",
      "step 19, train_loss 1.6500e-02, additional_loss 6.2227e-03, test_loss 2.1067e-01, test_additional_loss 7.0500e-02\n",
      "step 20, train_loss 4.5957e-02, additional_loss 3.5107e-02, test_loss 2.0291e-01, test_additional_loss 6.4921e-02\n",
      "step 21, train_loss 4.5782e-02, additional_loss 3.4189e-02, test_loss 1.8173e-01, test_additional_loss 4.8125e-02\n",
      "step 22, train_loss 2.2561e-02, additional_loss 9.3460e-03, test_loss 1.5788e-01, test_additional_loss 2.6274e-02\n",
      "step 23, train_loss 6.2179e-02, additional_loss 5.0926e-02, test_loss 1.5101e-01, test_additional_loss 2.0576e-02\n",
      "step 24, train_loss 5.9911e-02, additional_loss 4.9675e-02, test_loss 1.4907e-01, test_additional_loss 1.9717e-02\n",
      "step 25, train_loss 5.3875e-02, additional_loss 4.3833e-02, test_loss 1.4889e-01, test_additional_loss 1.8728e-02\n",
      "step 26, train_loss 5.2606e-02, additional_loss 4.0472e-02, test_loss 1.4932e-01, test_additional_loss 1.7631e-02\n",
      "step 27, train_loss 3.9155e-02, additional_loss 2.4235e-02, test_loss 1.5594e-01, test_additional_loss 1.9968e-02\n",
      "step 28, train_loss 3.5123e-02, additional_loss 2.0230e-02, test_loss 1.6520e-01, test_additional_loss 2.2960e-02\n",
      "step 29, train_loss 3.5059e-02, additional_loss 2.1803e-02, test_loss 1.7635e-01, test_additional_loss 2.6643e-02\n",
      "step 30, train_loss 3.3711e-02, additional_loss 2.3234e-02, test_loss 1.9188e-01, test_additional_loss 3.3236e-02\n",
      "step 31, train_loss 3.7707e-02, additional_loss 2.9695e-02, test_loss 2.0358e-01, test_additional_loss 3.6204e-02\n",
      "step 32, train_loss 2.3739e-02, additional_loss 1.6928e-02, test_loss 2.1251e-01, test_additional_loss 3.6347e-02\n",
      "step 33, train_loss 3.0099e-02, additional_loss 2.3770e-02, test_loss 2.1810e-01, test_additional_loss 3.3832e-02\n",
      "step 34, train_loss 4.7411e-02, additional_loss 4.0698e-02, test_loss 2.1718e-01, test_additional_loss 3.4928e-02\n",
      "step 35, train_loss 3.9970e-02, additional_loss 3.2711e-02, test_loss 2.1726e-01, test_additional_loss 3.9995e-02\n",
      "step 36, train_loss 3.0413e-02, additional_loss 2.2221e-02, test_loss 2.1134e-01, test_additional_loss 4.0209e-02\n",
      "step 37, train_loss 2.9533e-02, additional_loss 2.0921e-02, test_loss 2.0236e-01, test_additional_loss 3.7301e-02\n",
      "step 38, train_loss 2.2855e-02, additional_loss 1.4389e-02, test_loss 1.9822e-01, test_additional_loss 3.7754e-02\n",
      "step 39, train_loss 1.9396e-02, additional_loss 1.0920e-02, test_loss 1.9694e-01, test_additional_loss 3.9709e-02\n",
      "step 40, train_loss 3.9504e-02, additional_loss 3.0887e-02, test_loss 1.9453e-01, test_additional_loss 4.0317e-02\n",
      "step 41, train_loss 4.1775e-02, additional_loss 3.2842e-02, test_loss 1.9281e-01, test_additional_loss 4.1044e-02\n",
      "step 42, train_loss 2.2065e-02, additional_loss 1.2362e-02, test_loss 1.9560e-01, test_additional_loss 4.3368e-02\n",
      "step 43, train_loss 3.7107e-02, additional_loss 2.8396e-02, test_loss 1.9581e-01, test_additional_loss 4.4692e-02\n",
      "step 44, train_loss 4.5127e-02, additional_loss 3.7241e-02, test_loss 1.9214e-01, test_additional_loss 4.5526e-02\n",
      "step 45, train_loss 3.4634e-02, additional_loss 2.7883e-02, test_loss 1.7867e-01, test_additional_loss 4.0877e-02\n",
      "step 46, train_loss 2.1026e-02, additional_loss 1.5295e-02, test_loss 1.8411e-01, test_additional_loss 4.2880e-02\n",
      "step 47, train_loss 3.0837e-02, additional_loss 2.5749e-02, test_loss 1.9146e-01, test_additional_loss 4.6468e-02\n",
      "step 48, train_loss 2.1553e-02, additional_loss 1.6534e-02, test_loss 1.9835e-01, test_additional_loss 4.8625e-02\n",
      "step 49, train_loss 2.8835e-02, additional_loss 2.3365e-02, test_loss 1.9809e-01, test_additional_loss 4.7874e-02\n",
      "step 50, train_loss 2.6276e-02, additional_loss 2.0325e-02, test_loss 1.9443e-01, test_additional_loss 4.6623e-02\n",
      "Val metric improved. 0.1944333165884018 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137563.700973.pt\n",
      "Final train loss 6.3955e-03 +/- 1.2436e-02\n",
      "Final test loss 1.4781e-01 +/- 2.9261e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "step 0, train_loss 1.8126e-02, additional_loss 1.1730e-02, test_loss 2.0803e-01, test_additional_loss 6.1333e-02\n",
      "step 1, train_loss 2.6140e-01, additional_loss 2.3271e-01, test_loss 1.4772e-01, test_additional_loss 2.7156e-02\n",
      "step 2, train_loss 3.2856e-02, additional_loss 2.1565e-02, test_loss 1.3156e-01, test_additional_loss 1.5390e-02\n",
      "step 3, train_loss 8.4820e-02, additional_loss 4.0877e-02, test_loss 1.2820e-01, test_additional_loss 1.2767e-02\n",
      "step 4, train_loss 9.1639e-02, additional_loss 3.6108e-02, test_loss 1.2694e-01, test_additional_loss 1.1325e-02\n",
      "step 5, train_loss 7.3484e-02, additional_loss 1.4031e-02, test_loss 1.3064e-01, test_additional_loss 1.4436e-02\n",
      "step 6, train_loss 7.6150e-02, additional_loss 2.2578e-02, test_loss 1.3018e-01, test_additional_loss 1.5891e-02\n",
      "step 7, train_loss 7.0460e-02, additional_loss 2.3901e-02, test_loss 1.3087e-01, test_additional_loss 1.7762e-02\n",
      "step 8, train_loss 5.4788e-02, additional_loss 1.2302e-02, test_loss 1.3364e-01, test_additional_loss 2.0480e-02\n",
      "step 9, train_loss 4.8745e-02, additional_loss 1.1396e-02, test_loss 1.4234e-01, test_additional_loss 2.7394e-02\n",
      "step 10, train_loss 4.7387e-02, additional_loss 2.0134e-02, test_loss 1.4931e-01, test_additional_loss 3.2616e-02\n",
      "step 11, train_loss 4.6827e-02, additional_loss 2.6429e-02, test_loss 1.5387e-01, test_additional_loss 3.3033e-02\n",
      "step 12, train_loss 2.7029e-02, additional_loss 1.1289e-02, test_loss 1.6114e-01, test_additional_loss 3.2020e-02\n",
      "step 13, train_loss 2.8639e-02, additional_loss 1.5008e-02, test_loss 1.6323e-01, test_additional_loss 3.4630e-02\n",
      "step 14, train_loss 4.4687e-02, additional_loss 3.0947e-02, test_loss 1.6027e-01, test_additional_loss 3.1984e-02\n",
      "step 15, train_loss 3.9923e-02, additional_loss 2.7013e-02, test_loss 1.5665e-01, test_additional_loss 3.0243e-02\n",
      "step 16, train_loss 2.9867e-02, additional_loss 1.8871e-02, test_loss 1.5359e-01, test_additional_loss 3.1912e-02\n",
      "step 17, train_loss 5.4499e-02, additional_loss 4.4763e-02, test_loss 1.5177e-01, test_additional_loss 3.3140e-02\n",
      "step 18, train_loss 6.8734e-02, additional_loss 5.8460e-02, test_loss 1.4487e-01, test_additional_loss 3.0911e-02\n",
      "step 19, train_loss 4.7128e-02, additional_loss 3.5524e-02, test_loss 1.3893e-01, test_additional_loss 2.7561e-02\n",
      "step 20, train_loss 3.9267e-02, additional_loss 2.6488e-02, test_loss 1.4009e-01, test_additional_loss 2.8193e-02\n",
      "step 21, train_loss 6.3562e-02, additional_loss 4.8685e-02, test_loss 1.3993e-01, test_additional_loss 3.0243e-02\n",
      "step 22, train_loss 5.4528e-02, additional_loss 3.7527e-02, test_loss 1.3930e-01, test_additional_loss 3.2926e-02\n",
      "step 23, train_loss 2.6345e-02, additional_loss 7.9393e-03, test_loss 1.4523e-01, test_additional_loss 3.7169e-02\n",
      "step 24, train_loss 3.9710e-02, additional_loss 2.8169e-02, test_loss 1.5308e-01, test_additional_loss 4.0841e-02\n",
      "step 25, train_loss 4.0700e-02, additional_loss 3.4642e-02, test_loss 1.5783e-01, test_additional_loss 4.0519e-02\n",
      "step 26, train_loss 2.9733e-02, additional_loss 2.3758e-02, test_loss 1.5657e-01, test_additional_loss 4.2510e-02\n",
      "step 27, train_loss 4.6256e-02, additional_loss 4.0603e-02, test_loss 1.4562e-01, test_additional_loss 3.9482e-02\n",
      "step 28, train_loss 3.2716e-02, additional_loss 2.7990e-02, test_loss 1.4032e-01, test_additional_loss 3.9899e-02\n",
      "step 29, train_loss 3.5355e-02, additional_loss 3.0422e-02, test_loss 1.4229e-01, test_additional_loss 4.0329e-02\n",
      "step 30, train_loss 5.0625e-02, additional_loss 4.1807e-02, test_loss 1.3391e-01, test_additional_loss 3.2938e-02\n",
      "step 31, train_loss 2.4306e-02, additional_loss 8.3804e-03, test_loss 1.3141e-01, test_additional_loss 3.0828e-02\n",
      "step 32, train_loss 5.4529e-02, additional_loss 3.5954e-02, test_loss 1.3427e-01, test_additional_loss 3.2926e-02\n",
      "step 33, train_loss 5.6342e-02, additional_loss 3.9828e-02, test_loss 1.3614e-01, test_additional_loss 3.2747e-02\n",
      "step 34, train_loss 3.0299e-02, additional_loss 1.5914e-02, test_loss 1.3451e-01, test_additional_loss 2.9945e-02\n",
      "step 35, train_loss 3.2865e-02, additional_loss 2.0051e-02, test_loss 1.3006e-01, test_additional_loss 2.5761e-02\n",
      "step 36, train_loss 4.6152e-02, additional_loss 3.4535e-02, test_loss 1.2637e-01, test_additional_loss 2.1887e-02\n",
      "step 37, train_loss 3.5070e-02, additional_loss 2.3484e-02, test_loss 1.2448e-01, test_additional_loss 1.9479e-02\n",
      "step 38, train_loss 3.3034e-02, additional_loss 2.0945e-02, test_loss 1.2515e-01, test_additional_loss 1.8990e-02\n",
      "step 39, train_loss 4.3774e-02, additional_loss 3.0529e-02, test_loss 1.2406e-01, test_additional_loss 1.7893e-02\n",
      "step 40, train_loss 4.1024e-02, additional_loss 2.7442e-02, test_loss 1.2100e-01, test_additional_loss 1.6284e-02\n",
      "step 41, train_loss 2.8880e-02, additional_loss 1.5366e-02, test_loss 1.2134e-01, test_additional_loss 1.7869e-02\n",
      "step 42, train_loss 3.5166e-02, additional_loss 2.2173e-02, test_loss 1.2645e-01, test_additional_loss 2.1565e-02\n",
      "step 43, train_loss 3.3774e-02, additional_loss 2.1970e-02, test_loss 1.3344e-01, test_additional_loss 2.5046e-02\n",
      "step 44, train_loss 3.6143e-02, additional_loss 2.5964e-02, test_loss 1.3518e-01, test_additional_loss 2.6453e-02\n",
      "step 45, train_loss 2.5747e-02, additional_loss 1.6677e-02, test_loss 1.3914e-01, test_additional_loss 3.1424e-02\n",
      "step 46, train_loss 5.2130e-02, additional_loss 4.3726e-02, test_loss 1.4354e-01, test_additional_loss 3.5667e-02\n",
      "step 47, train_loss 3.6066e-02, additional_loss 2.7311e-02, test_loss 1.4656e-01, test_additional_loss 3.7611e-02\n",
      "step 48, train_loss 2.4713e-02, additional_loss 1.6642e-02, test_loss 1.4618e-01, test_additional_loss 3.3140e-02\n",
      "step 49, train_loss 3.6722e-02, additional_loss 2.8872e-02, test_loss 1.3898e-01, test_additional_loss 2.6989e-02\n",
      "step 50, train_loss 2.0364e-02, additional_loss 1.1396e-02, test_loss 1.3593e-01, test_additional_loss 2.5380e-02\n",
      "Val metric improved. 0.13592848181724548 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137564.190352.pt\n",
      "Final train loss 8.8414e-03 +/- 1.6834e-02\n",
      "Final test loss 1.1055e-01 +/- 2.0861e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-3_time_scale-2_t_span_min-0_t_span_max-4.pkl\n",
      "step 0, train_loss 1.3031e+01, additional_loss 2.7990e-02, test_loss 2.7894e-01, test_additional_loss 6.4158e-02\n",
      "step 1, train_loss 1.4630e+01, additional_loss 1.6193e+00, test_loss 5.1108e-01, test_additional_loss 2.9578e-01\n",
      "step 2, train_loss 2.6384e+01, additional_loss 1.3349e+01, test_loss 2.4974e-01, test_additional_loss 3.7944e-02\n",
      "step 3, train_loss 1.4435e+01, additional_loss 1.4252e+00, test_loss 2.3316e-01, test_additional_loss 1.8060e-02\n",
      "step 4, train_loss 1.3316e+01, additional_loss 3.1037e-01, test_loss 2.2165e-01, test_additional_loss 7.3314e-03\n",
      "step 5, train_loss 1.3104e+01, additional_loss 9.7609e-02, test_loss 2.1786e-01, test_additional_loss 3.8028e-03\n",
      "step 6, train_loss 1.3072e+01, additional_loss 6.5327e-02, test_loss 2.1629e-01, test_additional_loss 2.3365e-03\n",
      "step 7, train_loss 1.3017e+01, additional_loss 1.0872e-02, test_loss 2.1510e-01, test_additional_loss 1.2159e-03\n",
      "step 8, train_loss 1.3011e+01, additional_loss 4.8161e-03, test_loss 2.1475e-01, test_additional_loss 9.0599e-04\n",
      "step 9, train_loss 1.3023e+01, additional_loss 1.6737e-02, test_loss 2.1461e-01, test_additional_loss 7.8678e-04\n",
      "step 10, train_loss 1.3017e+01, additional_loss 1.1301e-02, test_loss 2.1456e-01, test_additional_loss 7.3910e-04\n",
      "step 11, train_loss 1.3008e+01, additional_loss 2.2411e-03, test_loss 2.1458e-01, test_additional_loss 7.6294e-04\n",
      "step 12, train_loss 1.3010e+01, additional_loss 4.1962e-03, test_loss 2.1454e-01, test_additional_loss 7.2718e-04\n",
      "step 13, train_loss 1.3008e+01, additional_loss 1.9073e-03, test_loss 2.1456e-01, test_additional_loss 7.5102e-04\n",
      "step 14, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1458e-01, test_additional_loss 7.6294e-04\n",
      "step 15, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 16, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1453e-01, test_additional_loss 7.1526e-04\n",
      "step 17, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1453e-01, test_additional_loss 7.1526e-04\n",
      "step 18, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1453e-01, test_additional_loss 7.1526e-04\n",
      "step 19, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 20, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 21, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1453e-01, test_additional_loss 7.1526e-04\n",
      "step 22, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1453e-01, test_additional_loss 7.1526e-04\n",
      "step 23, train_loss 1.3008e+01, additional_loss 2.3365e-03, test_loss 2.1453e-01, test_additional_loss 7.1526e-04\n",
      "step 24, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 25, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 26, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 27, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 28, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 29, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 30, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 31, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 32, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 33, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1448e-01, test_additional_loss 6.6757e-04\n",
      "step 34, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1444e-01, test_additional_loss 6.3181e-04\n",
      "step 35, train_loss 1.3009e+01, additional_loss 3.2902e-03, test_loss 2.1445e-01, test_additional_loss 6.4373e-04\n",
      "step 36, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1448e-01, test_additional_loss 6.6757e-04\n",
      "step 37, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1441e-01, test_additional_loss 5.9605e-04\n",
      "step 38, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1443e-01, test_additional_loss 6.1989e-04\n",
      "step 39, train_loss 1.3009e+01, additional_loss 3.7193e-03, test_loss 2.1441e-01, test_additional_loss 5.9605e-04\n",
      "step 40, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 41, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 42, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 43, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 44, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 45, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 46, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 47, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 48, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 49, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "step 50, train_loss 1.3007e+01, additional_loss 1.5259e-03, test_loss 2.1450e-01, test_additional_loss 6.9141e-04\n",
      "Val metric improved. 0.21450288593769073 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137564.70049.pt\n",
      "Final train loss 1.3006e+01 +/- 6.2446e+01\n",
      "Final test loss 2.1381e-01 +/- 4.8780e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-4_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-4_time_scale-1_t_span_min-0_t_span_max-4.pkl not found.\n",
      "Creating new data...\n",
      "step 0, train_loss 6.4119e-02, additional_loss 6.6280e-03, test_loss 1.8723e-01, test_additional_loss 5.8174e-03\n",
      "step 1, train_loss 5.8520e-02, additional_loss 5.7220e-04, test_loss 1.8257e-01, test_additional_loss 1.3351e-03\n",
      "step 2, train_loss 5.8000e-02, additional_loss 9.5367e-05, test_loss 1.8169e-01, test_additional_loss 4.7684e-04\n",
      "step 3, train_loss 5.7949e-02, additional_loss 4.7684e-05, test_loss 1.8159e-01, test_additional_loss 3.8147e-04\n",
      "step 4, train_loss 5.7973e-02, additional_loss 7.1526e-05, test_loss 1.8168e-01, test_additional_loss 4.7684e-04\n",
      "step 5, train_loss 5.7949e-02, additional_loss 4.7684e-05, test_loss 1.8159e-01, test_additional_loss 3.8147e-04\n",
      "step 6, train_loss 5.8021e-02, additional_loss 1.1921e-04, test_loss 1.8159e-01, test_additional_loss 3.8147e-04\n",
      "step 7, train_loss 5.8045e-02, additional_loss 1.4305e-04, test_loss 1.8159e-01, test_additional_loss 3.8147e-04\n",
      "step 8, train_loss 5.7997e-02, additional_loss 9.5367e-05, test_loss 1.8159e-01, test_additional_loss 3.8147e-04\n",
      "step 9, train_loss 5.7997e-02, additional_loss 9.5367e-05, test_loss 1.8159e-01, test_additional_loss 3.8147e-04\n",
      "step 10, train_loss 5.7997e-02, additional_loss 9.5367e-05, test_loss 1.8159e-01, test_additional_loss 3.8147e-04\n",
      "step 11, train_loss 5.7997e-02, additional_loss 9.5367e-05, test_loss 1.8159e-01, test_additional_loss 3.8147e-04\n",
      "step 12, train_loss 5.7997e-02, additional_loss 9.5367e-05, test_loss 1.8159e-01, test_additional_loss 3.8147e-04\n",
      "step 13, train_loss 5.8022e-02, additional_loss 1.1921e-04, test_loss 1.8169e-01, test_additional_loss 4.7684e-04\n",
      "step 14, train_loss 5.7955e-02, additional_loss 4.7684e-05, test_loss 1.8180e-01, test_additional_loss 5.7220e-04\n",
      "step 15, train_loss 5.8096e-02, additional_loss 1.6689e-04, test_loss 1.8169e-01, test_additional_loss 4.7684e-04\n",
      "step 16, train_loss 5.7958e-02, additional_loss 4.7684e-05, test_loss 1.8178e-01, test_additional_loss 5.7220e-04\n",
      "step 17, train_loss 5.7952e-02, additional_loss 4.7684e-05, test_loss 1.8168e-01, test_additional_loss 4.7684e-04\n",
      "step 18, train_loss 5.8021e-02, additional_loss 1.1921e-04, test_loss 1.8168e-01, test_additional_loss 4.7684e-04\n",
      "step 19, train_loss 5.7973e-02, additional_loss 7.1526e-05, test_loss 1.8168e-01, test_additional_loss 4.7684e-04\n",
      "step 20, train_loss 5.7949e-02, additional_loss 4.7684e-05, test_loss 1.8168e-01, test_additional_loss 4.7684e-04\n",
      "step 21, train_loss 5.7949e-02, additional_loss 4.7684e-05, test_loss 1.8158e-01, test_additional_loss 3.8147e-04\n",
      "step 22, train_loss 5.7996e-02, additional_loss 9.5367e-05, test_loss 1.8168e-01, test_additional_loss 4.7684e-04\n",
      "step 23, train_loss 5.7973e-02, additional_loss 7.1526e-05, test_loss 1.8168e-01, test_additional_loss 4.7684e-04\n",
      "step 24, train_loss 5.7973e-02, additional_loss 7.1526e-05, test_loss 1.8168e-01, test_additional_loss 4.7684e-04\n",
      "step 25, train_loss 5.7951e-02, additional_loss 4.7684e-05, test_loss 1.8201e-01, test_additional_loss 7.6294e-04\n",
      "step 26, train_loss 5.7936e-02, additional_loss 2.3842e-05, test_loss 1.8160e-01, test_additional_loss 3.8147e-04\n",
      "step 27, train_loss 5.7954e-02, additional_loss 4.7684e-05, test_loss 1.8179e-01, test_additional_loss 5.7220e-04\n",
      "step 28, train_loss 5.7953e-02, additional_loss 4.7684e-05, test_loss 1.8190e-01, test_additional_loss 6.6757e-04\n",
      "step 29, train_loss 5.7930e-02, additional_loss 2.3842e-05, test_loss 1.8211e-01, test_additional_loss 8.5831e-04\n",
      "step 30, train_loss 5.8005e-02, additional_loss 9.5367e-05, test_loss 1.8200e-01, test_additional_loss 7.6294e-04\n",
      "step 31, train_loss 5.7953e-02, additional_loss 4.7684e-05, test_loss 1.8200e-01, test_additional_loss 7.6294e-04\n",
      "step 32, train_loss 5.7928e-02, additional_loss 2.3842e-05, test_loss 1.8200e-01, test_additional_loss 7.6294e-04\n",
      "step 33, train_loss 5.7952e-02, additional_loss 4.7684e-05, test_loss 1.8211e-01, test_additional_loss 8.5831e-04\n",
      "step 34, train_loss 5.7953e-02, additional_loss 4.7684e-05, test_loss 1.8234e-01, test_additional_loss 1.0490e-03\n",
      "step 35, train_loss 5.8003e-02, additional_loss 9.5367e-05, test_loss 1.8262e-01, test_additional_loss 1.3351e-03\n",
      "step 36, train_loss 5.7954e-02, additional_loss 4.7684e-05, test_loss 1.8201e-01, test_additional_loss 7.6294e-04\n",
      "step 37, train_loss 5.7951e-02, additional_loss 4.7684e-05, test_loss 1.8190e-01, test_additional_loss 6.6757e-04\n",
      "step 38, train_loss 5.7926e-02, additional_loss 2.3842e-05, test_loss 1.8190e-01, test_additional_loss 6.6757e-04\n",
      "step 39, train_loss 5.7950e-02, additional_loss 4.7684e-05, test_loss 1.8170e-01, test_additional_loss 4.7684e-04\n",
      "step 40, train_loss 5.7974e-02, additional_loss 7.1526e-05, test_loss 1.8189e-01, test_additional_loss 6.6757e-04\n",
      "step 41, train_loss 5.7974e-02, additional_loss 7.1526e-05, test_loss 1.8180e-01, test_additional_loss 5.7220e-04\n",
      "step 42, train_loss 5.7975e-02, additional_loss 7.1526e-05, test_loss 1.8219e-01, test_additional_loss 9.5367e-04\n",
      "step 43, train_loss 5.7954e-02, additional_loss 4.7684e-05, test_loss 1.8200e-01, test_additional_loss 7.6294e-04\n",
      "step 44, train_loss 5.7977e-02, additional_loss 7.1526e-05, test_loss 1.8190e-01, test_additional_loss 6.6757e-04\n",
      "step 45, train_loss 5.7974e-02, additional_loss 7.1526e-05, test_loss 1.8190e-01, test_additional_loss 6.6757e-04\n",
      "step 46, train_loss 5.7926e-02, additional_loss 2.3842e-05, test_loss 1.8181e-01, test_additional_loss 5.7220e-04\n",
      "step 47, train_loss 5.7974e-02, additional_loss 7.1526e-05, test_loss 1.8191e-01, test_additional_loss 6.6757e-04\n",
      "step 48, train_loss 5.7928e-02, additional_loss 2.3842e-05, test_loss 1.8192e-01, test_additional_loss 6.6757e-04\n",
      "step 49, train_loss 5.7953e-02, additional_loss 4.7684e-05, test_loss 1.8202e-01, test_additional_loss 7.6294e-04\n",
      "step 50, train_loss 5.7955e-02, additional_loss 4.7684e-05, test_loss 1.8293e-01, test_additional_loss 1.6212e-03\n",
      "Val metric improved. 0.18293291330337524 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137565.4240818.pt\n",
      "Final train loss 5.7914e-02 +/- 1.0882e-01\n",
      "Final test loss 1.8131e-01 +/- 3.3123e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "step 0, train_loss 1.0056e-01, additional_loss 1.0586e-02, test_loss 1.1909e-01, test_additional_loss 7.5936e-03\n",
      "step 1, train_loss 1.0365e-01, additional_loss 3.2878e-02, test_loss 1.1835e-01, test_additional_loss 7.0333e-04\n",
      "step 2, train_loss 9.6850e-02, additional_loss 1.0717e-02, test_loss 1.1634e-01, test_additional_loss 5.7936e-03\n",
      "step 3, train_loss 7.1279e-02, additional_loss 1.3936e-02, test_loss 1.2127e-01, test_additional_loss 8.1897e-03\n",
      "step 4, train_loss 4.8836e-02, additional_loss 1.7869e-02, test_loss 1.3461e-01, test_additional_loss 1.0967e-02\n",
      "step 5, train_loss 3.4826e-02, additional_loss 2.2364e-02, test_loss 1.5186e-01, test_additional_loss 1.3590e-02\n",
      "step 6, train_loss 5.9878e-02, additional_loss 4.6062e-02, test_loss 1.5608e-01, test_additional_loss 1.6510e-02\n",
      "step 7, train_loss 8.6386e-02, additional_loss 7.4053e-02, test_loss 1.4813e-01, test_additional_loss 1.3471e-02\n",
      "step 8, train_loss 5.3389e-02, additional_loss 4.2844e-02, test_loss 1.4107e-01, test_additional_loss 9.3341e-03\n",
      "step 9, train_loss 3.8827e-02, additional_loss 1.9038e-02, test_loss 1.4023e-01, test_additional_loss 7.3195e-03\n",
      "step 10, train_loss 6.3176e-02, additional_loss 3.7777e-02, test_loss 1.3305e-01, test_additional_loss 7.1287e-03\n",
      "step 11, train_loss 3.8026e-02, additional_loss 9.8348e-03, test_loss 1.3535e-01, test_additional_loss 1.1635e-02\n",
      "step 12, train_loss 5.3056e-02, additional_loss 3.3355e-02, test_loss 1.3784e-01, test_additional_loss 1.4174e-02\n",
      "step 13, train_loss 5.1109e-02, additional_loss 3.9089e-02, test_loss 1.3905e-01, test_additional_loss 1.4341e-02\n",
      "step 14, train_loss 3.1652e-02, additional_loss 2.2149e-02, test_loss 1.4135e-01, test_additional_loss 1.4997e-02\n",
      "step 15, train_loss 2.5969e-02, additional_loss 1.5783e-02, test_loss 1.4206e-01, test_additional_loss 1.5759e-02\n",
      "step 16, train_loss 5.9174e-02, additional_loss 4.9067e-02, test_loss 1.3938e-01, test_additional_loss 1.5819e-02\n",
      "step 17, train_loss 4.1467e-02, additional_loss 3.0637e-02, test_loss 1.3566e-01, test_additional_loss 1.5676e-02\n",
      "step 18, train_loss 5.8639e-02, additional_loss 3.9840e-02, test_loss 1.3097e-01, test_additional_loss 1.2481e-02\n",
      "step 19, train_loss 4.7888e-02, additional_loss 1.9908e-02, test_loss 1.3158e-01, test_additional_loss 1.1730e-02\n",
      "step 20, train_loss 3.9635e-02, additional_loss 1.4722e-02, test_loss 1.3662e-01, test_additional_loss 1.2004e-02\n",
      "step 21, train_loss 2.7308e-02, additional_loss 1.3077e-02, test_loss 1.4722e-01, test_additional_loss 1.2362e-02\n",
      "step 22, train_loss 2.6342e-02, additional_loss 1.9026e-02, test_loss 1.6003e-01, test_additional_loss 1.5140e-02\n",
      "step 23, train_loss 4.7711e-02, additional_loss 3.8731e-02, test_loss 1.6716e-01, test_additional_loss 1.5533e-02\n",
      "step 24, train_loss 3.3876e-02, additional_loss 2.4021e-02, test_loss 1.7187e-01, test_additional_loss 1.5676e-02\n",
      "step 25, train_loss 4.1007e-02, additional_loss 3.3927e-02, test_loss 1.5343e-01, test_additional_loss 1.3137e-02\n",
      "step 26, train_loss 3.3215e-02, additional_loss 2.5713e-02, test_loss 1.3516e-01, test_additional_loss 1.0455e-02\n",
      "step 27, train_loss 2.8852e-02, additional_loss 1.4341e-02, test_loss 1.2722e-01, test_additional_loss 8.7023e-03\n",
      "step 28, train_loss 5.4267e-02, additional_loss 3.6085e-02, test_loss 1.2473e-01, test_additional_loss 7.8678e-03\n",
      "step 29, train_loss 5.1675e-02, additional_loss 3.3653e-02, test_loss 1.2446e-01, test_additional_loss 7.1764e-03\n",
      "step 30, train_loss 3.1977e-02, additional_loss 1.5748e-02, test_loss 1.2886e-01, test_additional_loss 8.1897e-03\n",
      "step 31, train_loss 3.6302e-02, additional_loss 2.5034e-02, test_loss 1.3365e-01, test_additional_loss 9.8705e-03\n",
      "step 32, train_loss 3.1095e-02, additional_loss 2.2101e-02, test_loss 1.3638e-01, test_additional_loss 1.1444e-02\n",
      "step 33, train_loss 2.4272e-02, additional_loss 1.6952e-02, test_loss 1.3809e-01, test_additional_loss 1.1945e-02\n",
      "step 34, train_loss 3.5114e-02, additional_loss 2.8598e-02, test_loss 1.4007e-01, test_additional_loss 1.1623e-02\n",
      "step 35, train_loss 3.5622e-02, additional_loss 2.9397e-02, test_loss 1.4277e-01, test_additional_loss 1.0550e-02\n",
      "step 36, train_loss 1.8359e-02, additional_loss 1.1599e-02, test_loss 1.5036e-01, test_additional_loss 8.3923e-03\n",
      "step 37, train_loss 3.3981e-02, additional_loss 2.5749e-02, test_loss 1.4827e-01, test_additional_loss 5.9009e-03\n",
      "step 38, train_loss 3.0701e-02, additional_loss 2.0468e-02, test_loss 1.4445e-01, test_additional_loss 7.8797e-03\n",
      "step 39, train_loss 2.1386e-02, additional_loss 9.3102e-03, test_loss 1.4656e-01, test_additional_loss 1.0800e-02\n",
      "step 40, train_loss 2.0224e-02, additional_loss 9.1910e-03, test_loss 1.4910e-01, test_additional_loss 1.1432e-02\n",
      "step 41, train_loss 1.5886e-02, additional_loss 6.3300e-03, test_loss 1.5224e-01, test_additional_loss 1.4043e-02\n",
      "step 42, train_loss 1.1456e-02, additional_loss 3.9339e-03, test_loss 1.5114e-01, test_additional_loss 1.7023e-02\n",
      "step 43, train_loss 2.5337e-02, additional_loss 1.9825e-02, test_loss 1.4596e-01, test_additional_loss 1.5688e-02\n",
      "step 44, train_loss 2.1617e-02, additional_loss 1.6189e-02, test_loss 1.4439e-01, test_additional_loss 1.5628e-02\n",
      "step 45, train_loss 2.2832e-02, additional_loss 1.7691e-02, test_loss 1.4520e-01, test_additional_loss 1.9050e-02\n",
      "step 46, train_loss 4.1915e-02, additional_loss 3.7181e-02, test_loss 1.3785e-01, test_additional_loss 1.8346e-02\n",
      "step 47, train_loss 4.0330e-02, additional_loss 3.3998e-02, test_loss 1.2791e-01, test_additional_loss 1.5235e-02\n",
      "step 48, train_loss 2.6181e-02, additional_loss 1.5414e-02, test_loss 1.2994e-01, test_additional_loss 1.7452e-02\n",
      "step 49, train_loss 2.4414e-02, additional_loss 1.3459e-02, test_loss 1.3927e-01, test_additional_loss 2.2793e-02\n",
      "step 50, train_loss 2.2691e-02, additional_loss 1.5628e-02, test_loss 1.5077e-01, test_additional_loss 2.7943e-02\n",
      "Val metric improved. 0.15077221393585205 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137565.95956.pt\n",
      "Final train loss 4.9431e-03 +/- 9.6400e-03\n",
      "Final test loss 1.2283e-01 +/- 2.4200e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-1_t_span_max-4.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-1_t_span_max-4.pkl not found.\n",
      "Creating new data...\n",
      "step 0, train_loss 5.3430e-01, additional_loss 1.1811e-01, test_loss 2.5816e-01, test_additional_loss 8.1098e-02\n",
      "step 1, train_loss 3.2517e-01, additional_loss 6.3872e-02, test_loss 1.6390e-01, test_additional_loss 1.6296e-02\n",
      "step 2, train_loss 2.2650e-01, additional_loss 5.3167e-03, test_loss 1.4208e-01, test_additional_loss 1.7524e-03\n",
      "step 3, train_loss 2.2329e-01, additional_loss 1.0467e-02, test_loss 1.4249e-01, test_additional_loss 3.8505e-03\n",
      "step 4, train_loss 2.1768e-01, additional_loss 4.1008e-03, test_loss 1.4170e-01, test_additional_loss 3.9339e-03\n",
      "step 5, train_loss 2.1747e-01, additional_loss 2.0504e-03, test_loss 1.4228e-01, test_additional_loss 5.1856e-03\n",
      "step 6, train_loss 2.1101e-01, additional_loss 1.0252e-03, test_loss 1.4626e-01, test_additional_loss 1.2028e-02\n",
      "step 7, train_loss 2.0554e-01, additional_loss 6.1750e-03, test_loss 1.5361e-01, test_additional_loss 2.4033e-02\n",
      "step 8, train_loss 1.8605e-01, additional_loss 4.4346e-03, test_loss 1.7482e-01, test_additional_loss 5.6005e-02\n",
      "step 9, train_loss 1.5773e-01, additional_loss 8.7261e-03, test_loss 2.3146e-01, test_additional_loss 1.2705e-01\n",
      "step 10, train_loss 1.3367e-01, additional_loss 2.8181e-02, test_loss 3.3657e-01, test_additional_loss 2.3419e-01\n",
      "step 11, train_loss 6.8919e-02, additional_loss 7.6056e-03, test_loss 5.4567e-01, test_additional_loss 4.0019e-01\n",
      "step 12, train_loss 9.8418e-02, additional_loss 5.8389e-02, test_loss 7.0211e-01, test_additional_loss 5.0931e-01\n",
      "step 13, train_loss 1.3174e-01, additional_loss 9.3579e-02, test_loss 7.0416e-01, test_additional_loss 5.3130e-01\n",
      "step 14, train_loss 7.0820e-02, additional_loss 3.5620e-02, test_loss 6.3980e-01, test_additional_loss 5.0291e-01\n",
      "step 15, train_loss 1.2632e-01, additional_loss 8.2517e-02, test_loss 5.4663e-01, test_additional_loss 4.3619e-01\n",
      "step 16, train_loss 1.0354e-01, additional_loss 4.8232e-02, test_loss 5.5364e-01, test_additional_loss 4.4283e-01\n",
      "step 17, train_loss 8.8605e-02, additional_loss 3.3522e-02, test_loss 6.5985e-01, test_additional_loss 5.2239e-01\n",
      "step 18, train_loss 8.4555e-02, additional_loss 4.2439e-02, test_loss 8.1631e-01, test_additional_loss 6.2418e-01\n",
      "step 19, train_loss 6.5538e-02, additional_loss 3.4285e-02, test_loss 9.4672e-01, test_additional_loss 6.9985e-01\n",
      "step 20, train_loss 8.2682e-02, additional_loss 5.3954e-02, test_loss 9.0017e-01, test_additional_loss 6.7017e-01\n",
      "step 21, train_loss 4.9050e-02, additional_loss 2.1935e-02, test_loss 8.1136e-01, test_additional_loss 6.1415e-01\n",
      "step 22, train_loss 6.7604e-02, additional_loss 4.2415e-02, test_loss 7.3163e-01, test_additional_loss 5.6335e-01\n",
      "step 23, train_loss 9.6808e-02, additional_loss 7.0190e-02, test_loss 6.4583e-01, test_additional_loss 5.0582e-01\n",
      "step 24, train_loss 6.1855e-02, additional_loss 3.1590e-02, test_loss 6.3366e-01, test_additional_loss 4.9850e-01\n",
      "step 25, train_loss 6.7632e-02, additional_loss 4.0460e-02, test_loss 6.5495e-01, test_additional_loss 5.1234e-01\n",
      "step 26, train_loss 8.3978e-02, additional_loss 6.4230e-02, test_loss 6.7183e-01, test_additional_loss 5.2010e-01\n",
      "step 27, train_loss 6.2804e-02, additional_loss 4.7374e-02, test_loss 6.7642e-01, test_additional_loss 5.1845e-01\n",
      "step 28, train_loss 3.6113e-02, additional_loss 2.2244e-02, test_loss 7.2987e-01, test_additional_loss 5.5256e-01\n",
      "step 29, train_loss 7.6047e-02, additional_loss 6.3562e-02, test_loss 6.8614e-01, test_additional_loss 5.2561e-01\n",
      "step 30, train_loss 6.6349e-02, additional_loss 5.3883e-02, test_loss 5.9159e-01, test_additional_loss 4.5782e-01\n",
      "step 31, train_loss 2.9232e-02, additional_loss 1.2803e-02, test_loss 5.8832e-01, test_additional_loss 4.5354e-01\n",
      "step 32, train_loss 7.4557e-02, additional_loss 6.0558e-02, test_loss 5.7105e-01, test_additional_loss 4.3768e-01\n",
      "step 33, train_loss 6.6479e-02, additional_loss 5.2905e-02, test_loss 5.0466e-01, test_additional_loss 3.8220e-01\n",
      "step 34, train_loss 7.4126e-02, additional_loss 5.0855e-02, test_loss 4.2426e-01, test_additional_loss 3.1507e-01\n",
      "step 35, train_loss 1.4616e-01, additional_loss 1.0521e-01, test_loss 3.6833e-01, test_additional_loss 2.6703e-01\n",
      "step 36, train_loss 8.3255e-02, additional_loss 2.7180e-02, test_loss 4.1165e-01, test_additional_loss 3.0491e-01\n",
      "step 37, train_loss 1.0209e-01, additional_loss 5.6815e-02, test_loss 5.3968e-01, test_additional_loss 4.0643e-01\n",
      "step 38, train_loss 6.9090e-02, additional_loss 4.4441e-02, test_loss 7.2040e-01, test_additional_loss 5.2377e-01\n",
      "step 39, train_loss 4.0933e-02, additional_loss 2.1386e-02, test_loss 8.6477e-01, test_additional_loss 5.9701e-01\n",
      "step 40, train_loss 1.0764e-01, additional_loss 8.1825e-02, test_loss 6.4710e-01, test_additional_loss 4.8670e-01\n",
      "step 41, train_loss 8.7743e-02, additional_loss 7.2527e-02, test_loss 4.7425e-01, test_additional_loss 3.7175e-01\n",
      "step 42, train_loss 1.0051e-01, additional_loss 6.3467e-02, test_loss 3.9287e-01, test_additional_loss 3.0397e-01\n",
      "step 43, train_loss 8.0013e-02, additional_loss 2.3746e-02, test_loss 4.5111e-01, test_additional_loss 3.5617e-01\n",
      "step 44, train_loss 4.3561e-02, additional_loss 2.1458e-03, test_loss 6.7650e-01, test_additional_loss 5.2845e-01\n",
      "step 45, train_loss 5.7032e-02, additional_loss 4.1842e-02, test_loss 9.9595e-01, test_additional_loss 7.2497e-01\n",
      "step 46, train_loss 7.4374e-02, additional_loss 4.9210e-02, test_loss 1.0568e+00, test_additional_loss 7.5914e-01\n",
      "step 47, train_loss 4.0378e-02, additional_loss 1.4114e-02, test_loss 9.6200e-01, test_additional_loss 7.0878e-01\n",
      "step 48, train_loss 1.0278e-01, additional_loss 8.4329e-02, test_loss 7.2847e-01, test_additional_loss 5.6490e-01\n",
      "step 49, train_loss 6.4495e-02, additional_loss 4.7231e-02, test_loss 5.5139e-01, test_additional_loss 4.3640e-01\n",
      "step 50, train_loss 7.1758e-02, additional_loss 3.6597e-02, test_loss 4.9286e-01, test_additional_loss 3.8804e-01\n",
      "Val metric improved. 0.4928627610206604 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137566.569087.pt\n",
      "Final train loss 4.5618e-02 +/- 6.6405e-02\n",
      "Final test loss 1.0482e-01 +/- 1.8982e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-6_time_scale-1_t_span_min-1_t_span_max-4.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-6_time_scale-1_t_span_min-1_t_span_max-4.pkl not found.\n",
      "Creating new data...\n",
      "Trajectory 5be93ce04c9a443fac335f0e0d17aa2f: 500 steps (last t: tensor([1.0064]))\n",
      "step 0, train_loss 1.2452e+06, additional_loss 9.5398e+00, test_loss 5.6474e+01, test_additional_loss 2.4560e+01\n",
      "step 1, train_loss 1.2684e+06, additional_loss 2.3366e+04, test_loss 3.2081e+01, test_additional_loss 1.0968e+00\n",
      "step 2, train_loss 1.2455e+06, additional_loss 2.8041e+02, test_loss 3.4228e+01, test_additional_loss 3.2361e+00\n",
      "step 3, train_loss 1.2468e+06, additional_loss 1.5944e+03, test_loss 3.1959e+01, test_additional_loss 9.9893e-01\n",
      "step 4, train_loss 1.2455e+06, additional_loss 2.9630e+02, test_loss 3.1514e+01, test_additional_loss 5.6481e-01\n",
      "step 5, train_loss 1.2457e+06, additional_loss 4.8143e+02, test_loss 3.1358e+01, test_additional_loss 4.0941e-01\n",
      "step 6, train_loss 1.2455e+06, additional_loss 2.8499e+02, test_loss 3.1070e+01, test_additional_loss 1.2167e-01\n",
      "step 7, train_loss 1.2453e+06, additional_loss 7.7289e+01, test_loss 3.0953e+01, test_additional_loss 4.8399e-03\n",
      "step 8, train_loss 1.2452e+06, additional_loss 8.3374e+00, test_loss 3.0965e+01, test_additional_loss 1.7118e-02\n",
      "step 9, train_loss 1.2452e+06, additional_loss 1.5466e+01, test_loss 3.0958e+01, test_additional_loss 1.0681e-02\n",
      "step 10, train_loss 1.2452e+06, additional_loss 2.9785e+00, test_loss 3.0953e+01, test_additional_loss 5.6744e-03\n",
      "step 11, train_loss 1.2452e+06, additional_loss 5.1208e+00, test_loss 3.0949e+01, test_additional_loss 1.9312e-03\n",
      "step 12, train_loss 1.2452e+06, additional_loss 3.0579e+00, test_loss 3.0949e+01, test_additional_loss 1.6451e-03\n",
      "step 13, train_loss 1.2452e+06, additional_loss 8.5449e-01, test_loss 3.0949e+01, test_additional_loss 1.1206e-03\n",
      "step 14, train_loss 1.2452e+06, additional_loss 1.0376e+00, test_loss 3.0948e+01, test_additional_loss 4.7684e-04\n",
      "step 15, train_loss 1.2452e+06, additional_loss 1.9470e+00, test_loss 3.0948e+01, test_additional_loss 3.8147e-04\n",
      "step 16, train_loss 1.2452e+06, additional_loss 1.1963e+00, test_loss 3.0950e+01, test_additional_loss 2.7418e-03\n",
      "step 17, train_loss 1.2452e+06, additional_loss 8.9722e-01, test_loss 3.0950e+01, test_additional_loss 2.6703e-03\n",
      "step 18, train_loss 1.2452e+06, additional_loss 6.8359e-01, test_loss 3.0950e+01, test_additional_loss 2.6941e-03\n",
      "step 19, train_loss 1.2452e+06, additional_loss 4.6387e-01, test_loss 3.0950e+01, test_additional_loss 2.6703e-03\n",
      "step 20, train_loss 1.2452e+06, additional_loss 3.6621e-01, test_loss 3.0950e+01, test_additional_loss 2.6703e-03\n",
      "step 21, train_loss 1.2452e+06, additional_loss 1.1475e+00, test_loss 3.0950e+01, test_additional_loss 2.6703e-03\n",
      "step 22, train_loss 1.2452e+06, additional_loss 3.7842e-01, test_loss 3.0950e+01, test_additional_loss 2.6703e-03\n",
      "step 23, train_loss 1.2452e+06, additional_loss 3.1738e-01, test_loss 3.0950e+01, test_additional_loss 2.9802e-03\n",
      "step 24, train_loss 1.2452e+06, additional_loss 3.8452e-01, test_loss 3.0950e+01, test_additional_loss 3.0041e-03\n",
      "step 25, train_loss 1.2452e+06, additional_loss 4.6387e-01, test_loss 3.0950e+01, test_additional_loss 2.5272e-03\n",
      "step 26, train_loss 1.2452e+06, additional_loss 8.9111e-01, test_loss 3.0950e+01, test_additional_loss 2.5511e-03\n",
      "step 27, train_loss 1.2452e+06, additional_loss 1.5869e-01, test_loss 3.0950e+01, test_additional_loss 2.6226e-03\n",
      "step 28, train_loss 1.2452e+06, additional_loss 3.6011e-01, test_loss 3.0950e+01, test_additional_loss 2.6226e-03\n",
      "step 29, train_loss 1.2452e+06, additional_loss 2.9907e-01, test_loss 3.0950e+01, test_additional_loss 2.6226e-03\n",
      "step 30, train_loss 1.2452e+06, additional_loss 4.3335e-01, test_loss 3.0950e+01, test_additional_loss 2.6226e-03\n",
      "step 31, train_loss 1.2452e+06, additional_loss 6.7749e-01, test_loss 3.0950e+01, test_additional_loss 3.0518e-03\n",
      "step 32, train_loss 1.2452e+06, additional_loss 5.3101e-01, test_loss 3.0950e+01, test_additional_loss 3.0041e-03\n",
      "step 33, train_loss 1.2452e+06, additional_loss 1.9531e-01, test_loss 3.0951e+01, test_additional_loss 3.3617e-03\n",
      "step 34, train_loss 1.2452e+06, additional_loss 3.6011e-01, test_loss 3.0951e+01, test_additional_loss 3.3617e-03\n",
      "step 35, train_loss 1.2452e+06, additional_loss 2.8687e-01, test_loss 3.0950e+01, test_additional_loss 2.5272e-03\n",
      "step 36, train_loss 1.2452e+06, additional_loss 2.5635e-01, test_loss 3.0950e+01, test_additional_loss 2.5272e-03\n",
      "step 37, train_loss 1.2452e+06, additional_loss 2.8076e-01, test_loss 3.0950e+01, test_additional_loss 2.4796e-03\n",
      "step 38, train_loss 1.2452e+06, additional_loss 5.0049e-01, test_loss 3.0950e+01, test_additional_loss 2.5272e-03\n",
      "step 39, train_loss 1.2452e+06, additional_loss 1.8311e-02, test_loss 3.0950e+01, test_additional_loss 2.4796e-03\n",
      "step 40, train_loss 1.2452e+06, additional_loss 5.1880e-01, test_loss 3.0950e+01, test_additional_loss 2.5272e-03\n",
      "step 41, train_loss 1.2452e+06, additional_loss 2.8687e-01, test_loss 3.0952e+01, test_additional_loss 4.7445e-03\n",
      "step 42, train_loss 1.2452e+06, additional_loss 4.8828e-01, test_loss 3.0950e+01, test_additional_loss 2.4796e-03\n",
      "step 43, train_loss 1.2452e+06, additional_loss 1.4648e-01, test_loss 3.0950e+01, test_additional_loss 2.4557e-03\n",
      "step 44, train_loss 1.2452e+06, additional_loss 2.8076e-01, test_loss 3.0950e+01, test_additional_loss 2.5272e-03\n",
      "step 45, train_loss 1.2452e+06, additional_loss 3.1128e-01, test_loss 3.0952e+01, test_additional_loss 4.7207e-03\n",
      "step 46, train_loss 1.2452e+06, additional_loss 9.7656e-02, test_loss 3.0952e+01, test_additional_loss 4.7207e-03\n",
      "step 47, train_loss 1.2452e+06, additional_loss 9.1553e-02, test_loss 3.0950e+01, test_additional_loss 2.5272e-03\n",
      "step 48, train_loss 1.2452e+06, additional_loss 3.0518e-01, test_loss 3.0950e+01, test_additional_loss 2.4796e-03\n",
      "step 49, train_loss 1.2452e+06, additional_loss 2.8687e-01, test_loss 3.0952e+01, test_additional_loss 4.7207e-03\n",
      "step 50, train_loss 1.2452e+06, additional_loss 9.1553e-02, test_loss 3.0952e+01, test_additional_loss 4.7207e-03\n",
      "Val metric improved. 30.95214080810547 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137568.0016499.pt\n",
      "Final train loss 1.2452e+06 +/- 5.3621e+06\n",
      "Final test loss 3.0947e+01 +/- 1.7962e+02\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-12_time_scale-1_t_span_min-1_t_span_max-4.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-12_time_scale-1_t_span_min-1_t_span_max-4.pkl not found.\n",
      "Creating new data...\n",
      "Trajectory d84511c36273450cb0490d585944df60: 500 steps (last t: tensor([1.0605]))\n",
      "Trajectory d84511c36273450cb0490d585944df60: 1000 steps (last t: tensor([1.2362]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 500 steps (last t: tensor([1.0000]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 1000 steps (last t: tensor([1.0000]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 1500 steps (last t: tensor([1.0001]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 2000 steps (last t: tensor([1.0001]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 2500 steps (last t: tensor([1.0001]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 3000 steps (last t: tensor([1.0001]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 3500 steps (last t: tensor([1.0001]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 4000 steps (last t: tensor([1.0001]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 4500 steps (last t: tensor([1.0002]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 5000 steps (last t: tensor([1.0002]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 5500 steps (last t: tensor([1.0002]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 6000 steps (last t: tensor([1.0002]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 6500 steps (last t: tensor([1.0003]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 7000 steps (last t: tensor([1.0003]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 7500 steps (last t: tensor([1.0003]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 8000 steps (last t: tensor([1.0003]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 8500 steps (last t: tensor([1.0004]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 9000 steps (last t: tensor([1.0004]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 9500 steps (last t: tensor([1.0005]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 10000 steps (last t: tensor([1.0005]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 10500 steps (last t: tensor([1.0006]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 11000 steps (last t: tensor([1.0007]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 11500 steps (last t: tensor([1.0010]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 12000 steps (last t: tensor([1.0014]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 12500 steps (last t: tensor([1.0020]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 13000 steps (last t: tensor([1.0029]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 13500 steps (last t: tensor([1.0065]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 14000 steps (last t: tensor([1.0077]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 14500 steps (last t: tensor([1.0087]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 15000 steps (last t: tensor([1.0098]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 15500 steps (last t: tensor([1.1694]))\n",
      "Trajectory 249044bdb221407f9afe8c512d26e2af: 16000 steps (last t: tensor([3.8691]))\n",
      "step 0, train_loss 4.1132e+05, additional_loss 7.5479e+01, test_loss 5.1766e+10, test_additional_loss 5.2578e+04\n",
      "step 1, train_loss 4.1126e+05, additional_loss 1.2634e+01, test_loss 5.1766e+10, test_additional_loss 4.4422e+03\n",
      "step 2, train_loss 4.1127e+05, additional_loss 2.5122e+01, test_loss 5.1766e+10, test_additional_loss 1.9062e+02\n",
      "step 3, train_loss 4.1136e+05, additional_loss 1.1338e+02, test_loss 5.1766e+10, test_additional_loss 1.0156e+01\n",
      "step 4, train_loss 4.1124e+05, additional_loss 3.1433e-01, test_loss 5.1766e+10, test_additional_loss 3.2812e+01\n",
      "step 5, train_loss 4.1124e+05, additional_loss 3.1433e-01, test_loss 5.1766e+10, test_additional_loss 3.2812e+01\n",
      "step 6, train_loss 4.1124e+05, additional_loss 3.1433e-01, test_loss 5.1766e+10, test_additional_loss 3.2812e+01\n",
      "step 7, train_loss 4.1124e+05, additional_loss 3.1433e-01, test_loss 5.1766e+10, test_additional_loss 3.2812e+01\n",
      "step 8, train_loss 4.1124e+05, additional_loss 3.1433e-01, test_loss 5.1766e+10, test_additional_loss 5.2344e+01\n",
      "step 9, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 5.1562e+01\n",
      "step 10, train_loss 4.1124e+05, additional_loss 8.6365e-01, test_loss 5.1766e+10, test_additional_loss 5.9375e+01\n",
      "step 11, train_loss 4.1124e+05, additional_loss 1.2054e+00, test_loss 5.1766e+10, test_additional_loss 7.0312e+01\n",
      "step 12, train_loss 4.1124e+05, additional_loss 7.5989e-01, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 13, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 14, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 5.1562e+01\n",
      "step 15, train_loss 4.1124e+05, additional_loss 6.4392e-01, test_loss 5.1766e+10, test_additional_loss 5.1562e+01\n",
      "step 16, train_loss 4.1124e+05, additional_loss 6.4392e-01, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 17, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 18, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 5.1562e+01\n",
      "step 19, train_loss 4.1124e+05, additional_loss 6.4392e-01, test_loss 5.1766e+10, test_additional_loss 5.1562e+01\n",
      "step 20, train_loss 4.1124e+05, additional_loss 6.4392e-01, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 21, train_loss 4.1124e+05, additional_loss 1.9836e-01, test_loss 5.1766e+10, test_additional_loss 7.4219e+01\n",
      "step 22, train_loss 4.1124e+05, additional_loss 3.1433e-01, test_loss 5.1766e+10, test_additional_loss 5.2344e+01\n",
      "step 23, train_loss 4.1124e+05, additional_loss 3.1433e-01, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 24, train_loss 4.1124e+05, additional_loss 3.1433e-01, test_loss 5.1766e+10, test_additional_loss 3.2031e+01\n",
      "step 25, train_loss 4.1124e+05, additional_loss 1.9836e-01, test_loss 5.1766e+10, test_additional_loss 3.2031e+01\n",
      "step 26, train_loss 4.1124e+05, additional_loss 1.9836e-01, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 27, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 5.2344e+01\n",
      "step 28, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 1.0156e+01\n",
      "step 29, train_loss 4.1124e+05, additional_loss 6.4392e-01, test_loss 5.1766e+10, test_additional_loss 1.0156e+01\n",
      "step 30, train_loss 4.1124e+05, additional_loss 6.4392e-01, test_loss 5.1766e+10, test_additional_loss 3.2031e+01\n",
      "step 31, train_loss 4.1124e+05, additional_loss 1.9836e-01, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 32, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 33, train_loss 4.1124e+05, additional_loss 2.0447e-01, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 34, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 3.2031e+01\n",
      "step 35, train_loss 4.1124e+05, additional_loss 1.9836e-01, test_loss 5.1766e+10, test_additional_loss 3.2031e+01\n",
      "step 36, train_loss 4.1124e+05, additional_loss 3.4790e-01, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 37, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 3.2031e+01\n",
      "step 38, train_loss 4.1124e+05, additional_loss 1.9836e-01, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 39, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 40, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 5.1562e+01\n",
      "step 41, train_loss 4.1124e+05, additional_loss 6.4392e-01, test_loss 5.1766e+10, test_additional_loss 5.1562e+01\n",
      "step 42, train_loss 4.1124e+05, additional_loss 6.4392e-01, test_loss 5.1766e+10, test_additional_loss 3.2031e+01\n",
      "step 43, train_loss 4.1124e+05, additional_loss 3.4790e-01, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 44, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 7.4219e+01\n",
      "step 45, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 46, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 47, train_loss 4.1124e+05, additional_loss 1.9836e-01, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 48, train_loss 4.1124e+05, additional_loss 1.9836e-01, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 49, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "step 50, train_loss 4.1124e+05, additional_loss 2.1362e-02, test_loss 5.1766e+10, test_additional_loss 4.2969e+01\n",
      "Val metric improved. 51765817344.0 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137580.2689128.pt\n",
      "Final train loss 4.1124e+05 +/- 3.0880e+06\n",
      "Final test loss 5.1766e+10 +/- 3.7354e+11\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-4_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "step 0, train_loss 5.8022e-02, additional_loss 1.1921e-04, test_loss 1.8172e-01, test_additional_loss 4.7684e-04\n",
      "step 1, train_loss 5.7932e-02, additional_loss 2.3842e-05, test_loss 1.8209e-01, test_additional_loss 7.6294e-04\n",
      "step 2, train_loss 5.8024e-02, additional_loss 1.1921e-04, test_loss 1.8169e-01, test_additional_loss 4.7684e-04\n",
      "step 3, train_loss 5.7992e-02, additional_loss 9.5367e-05, test_loss 1.8166e-01, test_additional_loss 4.7684e-04\n",
      "step 4, train_loss 5.7976e-02, additional_loss 7.1526e-05, test_loss 1.8184e-01, test_additional_loss 6.6757e-04\n",
      "step 5, train_loss 5.7970e-02, additional_loss 4.7684e-05, test_loss 1.8186e-01, test_additional_loss 6.6757e-04\n",
      "step 6, train_loss 5.7983e-02, additional_loss 7.1526e-05, test_loss 1.8210e-01, test_additional_loss 8.5831e-04\n",
      "step 7, train_loss 5.8013e-02, additional_loss 1.4305e-04, test_loss 1.8312e-01, test_additional_loss 1.8120e-03\n",
      "step 8, train_loss 5.7935e-02, additional_loss 4.7684e-05, test_loss 1.8382e-01, test_additional_loss 2.4796e-03\n",
      "step 9, train_loss 5.7964e-02, additional_loss 1.9073e-04, test_loss 1.8590e-01, test_additional_loss 4.3869e-03\n",
      "step 10, train_loss 5.7743e-02, additional_loss 9.5367e-05, test_loss 1.9215e-01, test_additional_loss 9.9182e-03\n",
      "step 11, train_loss 5.8539e-02, additional_loss 1.1444e-03, test_loss 1.8906e-01, test_additional_loss 6.9618e-03\n",
      "step 12, train_loss 5.7839e-02, additional_loss 7.1526e-04, test_loss 1.8791e-01, test_additional_loss 5.7220e-03\n",
      "step 13, train_loss 5.7180e-02, additional_loss 3.0994e-04, test_loss 1.9206e-01, test_additional_loss 8.7738e-03\n",
      "step 14, train_loss 5.8001e-02, additional_loss 2.0981e-03, test_loss 1.9810e-01, test_additional_loss 1.3256e-02\n",
      "step 15, train_loss 5.5074e-02, additional_loss 9.7752e-04, test_loss 2.1445e-01, test_additional_loss 2.5082e-02\n",
      "step 16, train_loss 5.6894e-02, additional_loss 8.7261e-03, test_loss 2.4620e-01, test_additional_loss 4.8542e-02\n",
      "step 17, train_loss 5.0279e-02, additional_loss 9.0837e-03, test_loss 2.9566e-01, test_additional_loss 8.1253e-02\n",
      "step 18, train_loss 4.9456e-02, additional_loss 1.4162e-02, test_loss 3.2900e-01, test_additional_loss 1.0328e-01\n",
      "step 19, train_loss 2.9523e-02, additional_loss 1.4544e-03, test_loss 3.7297e-01, test_additional_loss 1.3332e-01\n",
      "step 20, train_loss 7.8571e-02, additional_loss 4.8757e-02, test_loss 3.1442e-01, test_additional_loss 9.3460e-02\n",
      "step 21, train_loss 5.2304e-02, additional_loss 2.2364e-02, test_loss 2.7489e-01, test_additional_loss 6.5613e-02\n",
      "step 22, train_loss 4.5034e-02, additional_loss 1.1826e-02, test_loss 2.6127e-01, test_additional_loss 5.6839e-02\n",
      "step 23, train_loss 4.8197e-02, additional_loss 1.1516e-02, test_loss 2.6156e-01, test_additional_loss 5.7983e-02\n",
      "step 24, train_loss 4.3820e-02, additional_loss 6.3419e-03, test_loss 2.7099e-01, test_additional_loss 6.4468e-02\n",
      "step 25, train_loss 3.8726e-02, additional_loss 3.1471e-03, test_loss 3.0406e-01, test_additional_loss 8.8215e-02\n",
      "step 26, train_loss 4.5022e-02, additional_loss 1.4472e-02, test_loss 3.2903e-01, test_additional_loss 1.0500e-01\n",
      "step 27, train_loss 3.3866e-02, additional_loss 6.6042e-03, test_loss 3.4345e-01, test_additional_loss 1.1396e-01\n",
      "step 28, train_loss 5.4105e-02, additional_loss 2.7108e-02, test_loss 3.4072e-01, test_additional_loss 1.1139e-01\n",
      "step 29, train_loss 4.5821e-02, additional_loss 1.9217e-02, test_loss 3.2065e-01, test_additional_loss 9.7370e-02\n",
      "step 30, train_loss 4.5393e-02, additional_loss 1.8144e-02, test_loss 3.0289e-01, test_additional_loss 8.5640e-02\n",
      "step 31, train_loss 4.7287e-02, additional_loss 1.7881e-02, test_loss 2.8513e-01, test_additional_loss 7.3624e-02\n",
      "step 32, train_loss 3.8528e-02, additional_loss 6.1989e-03, test_loss 3.0872e-01, test_additional_loss 8.9455e-02\n",
      "step 33, train_loss 3.9122e-02, additional_loss 9.3937e-03, test_loss 3.5378e-01, test_additional_loss 1.2016e-01\n",
      "step 34, train_loss 4.5715e-02, additional_loss 2.0409e-02, test_loss 3.9865e-01, test_additional_loss 1.5182e-01\n",
      "step 35, train_loss 2.8132e-02, additional_loss 6.1750e-03, test_loss 4.4058e-01, test_additional_loss 1.7996e-01\n",
      "step 36, train_loss 4.1264e-02, additional_loss 1.9574e-02, test_loss 4.6582e-01, test_additional_loss 1.9827e-01\n",
      "step 37, train_loss 3.1471e-02, additional_loss 1.0562e-02, test_loss 4.3745e-01, test_additional_loss 1.7986e-01\n",
      "step 38, train_loss 5.2854e-02, additional_loss 3.1090e-02, test_loss 3.8680e-01, test_additional_loss 1.4544e-01\n",
      "step 39, train_loss 3.8565e-02, additional_loss 1.4210e-02, test_loss 3.5233e-01, test_additional_loss 1.2264e-01\n",
      "step 40, train_loss 2.9536e-02, additional_loss 2.9564e-03, test_loss 3.7053e-01, test_additional_loss 1.3638e-01\n",
      "step 41, train_loss 4.4272e-02, additional_loss 1.9813e-02, test_loss 3.7116e-01, test_additional_loss 1.3742e-01\n",
      "step 42, train_loss 4.7280e-02, additional_loss 2.3222e-02, test_loss 3.5284e-01, test_additional_loss 1.2512e-01\n",
      "step 43, train_loss 3.8960e-02, additional_loss 1.2922e-02, test_loss 3.5328e-01, test_additional_loss 1.2655e-01\n",
      "step 44, train_loss 4.8307e-02, additional_loss 2.1577e-02, test_loss 3.3978e-01, test_additional_loss 1.1663e-01\n",
      "step 45, train_loss 4.4499e-02, additional_loss 1.6093e-02, test_loss 3.2134e-01, test_additional_loss 1.0214e-01\n",
      "step 46, train_loss 3.7986e-02, additional_loss 8.2493e-03, test_loss 3.2950e-01, test_additional_loss 1.0719e-01\n",
      "step 47, train_loss 3.7108e-02, additional_loss 9.0361e-03, test_loss 3.5831e-01, test_additional_loss 1.2741e-01\n",
      "step 48, train_loss 3.3390e-02, additional_loss 8.8453e-03, test_loss 3.8945e-01, test_additional_loss 1.4763e-01\n",
      "step 49, train_loss 2.9786e-02, additional_loss 7.7248e-03, test_loss 4.0860e-01, test_additional_loss 1.5888e-01\n",
      "step 50, train_loss 3.5788e-02, additional_loss 1.2493e-02, test_loss 4.1528e-01, test_additional_loss 1.6317e-01\n",
      "Val metric improved. 0.4152781367301941 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137581.365765.pt\n",
      "Final train loss 2.3487e-02 +/- 3.8617e-02\n",
      "Final test loss 2.5210e-01 +/- 5.6561e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-6.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-6.pkl not found.\n",
      "Creating new data...\n",
      "step 0, train_loss 4.0233e-01, additional_loss 3.6955e-02, test_loss 3.5541e-01, test_additional_loss 6.8736e-02\n",
      "step 1, train_loss 4.8158e-01, additional_loss 7.7772e-02, test_loss 5.8700e-01, test_additional_loss 3.3214e-01\n",
      "step 2, train_loss 7.7927e-01, additional_loss 3.4680e-01, test_loss 7.3490e-01, test_additional_loss 4.9825e-01\n",
      "step 3, train_loss 5.3576e-01, additional_loss 1.3752e-01, test_loss 5.9651e-01, test_additional_loss 3.7303e-01\n",
      "step 4, train_loss 3.9096e-01, additional_loss 1.3685e-02, test_loss 4.7545e-01, test_additional_loss 2.4531e-01\n",
      "step 5, train_loss 3.8236e-01, additional_loss 1.0729e-02, test_loss 4.6073e-01, test_additional_loss 2.1679e-01\n",
      "step 6, train_loss 3.7466e-01, additional_loss 4.2915e-03, test_loss 4.2330e-01, test_additional_loss 1.7352e-01\n",
      "step 7, train_loss 3.7729e-01, additional_loss 7.1526e-03, test_loss 3.8114e-01, test_additional_loss 1.3163e-01\n",
      "step 8, train_loss 3.7730e-01, additional_loss 6.9141e-03, test_loss 3.3404e-01, test_additional_loss 8.7500e-02\n",
      "step 9, train_loss 3.7584e-01, additional_loss 5.1022e-03, test_loss 2.9900e-01, test_additional_loss 5.5313e-02\n",
      "step 10, train_loss 3.7346e-01, additional_loss 2.4319e-03, test_loss 2.7911e-01, test_additional_loss 3.7193e-02\n",
      "step 11, train_loss 3.7192e-01, additional_loss 7.1526e-04, test_loss 2.7017e-01, test_additional_loss 2.9230e-02\n",
      "step 12, train_loss 3.7283e-01, additional_loss 1.6212e-03, test_loss 2.7879e-01, test_additional_loss 3.9029e-02\n",
      "step 13, train_loss 3.7288e-01, additional_loss 1.7643e-03, test_loss 2.8865e-01, test_additional_loss 5.0163e-02\n",
      "step 14, train_loss 3.7173e-01, additional_loss 6.1989e-04, test_loss 2.9691e-01, test_additional_loss 5.8961e-02\n",
      "step 15, train_loss 3.7192e-01, additional_loss 8.1062e-04, test_loss 3.0176e-01, test_additional_loss 6.3777e-02\n",
      "step 16, train_loss 3.7220e-01, additional_loss 1.0967e-03, test_loss 3.0761e-01, test_additional_loss 6.9380e-02\n",
      "step 17, train_loss 3.7205e-01, additional_loss 9.5367e-04, test_loss 3.1484e-01, test_additional_loss 7.5984e-02\n",
      "step 18, train_loss 3.7163e-01, additional_loss 5.7220e-04, test_loss 3.2297e-01, test_additional_loss 8.2874e-02\n",
      "step 19, train_loss 3.7154e-01, additional_loss 5.7220e-04, test_loss 3.3194e-01, test_additional_loss 9.0146e-02\n",
      "step 20, train_loss 3.7135e-01, additional_loss 5.2452e-04, test_loss 3.4167e-01, test_additional_loss 9.7799e-02\n",
      "step 21, train_loss 3.7112e-01, additional_loss 4.7684e-04, test_loss 3.7482e-01, test_additional_loss 1.2813e-01\n",
      "step 22, train_loss 3.7078e-01, additional_loss 3.8147e-04, test_loss 4.3398e-01, test_additional_loss 1.8330e-01\n",
      "step 23, train_loss 3.7045e-01, additional_loss 4.2915e-04, test_loss 5.1204e-01, test_additional_loss 2.5573e-01\n",
      "step 24, train_loss 3.7012e-01, additional_loss 6.1989e-04, test_loss 6.0108e-01, test_additional_loss 3.3801e-01\n",
      "step 25, train_loss 3.6955e-01, additional_loss 9.0599e-04, test_loss 7.0158e-01, test_additional_loss 4.3035e-01\n",
      "step 26, train_loss 3.6995e-01, additional_loss 2.6226e-03, test_loss 8.1029e-01, test_additional_loss 5.2953e-01\n",
      "step 27, train_loss 3.6768e-01, additional_loss 1.9550e-03, test_loss 9.3524e-01, test_additional_loss 6.4249e-01\n",
      "step 28, train_loss 3.6647e-01, additional_loss 3.2902e-03, test_loss 1.0765e+00, test_additional_loss 7.6895e-01\n",
      "step 29, train_loss 3.6519e-01, additional_loss 5.1498e-03, test_loss 1.1987e+00, test_additional_loss 8.7771e-01\n",
      "step 30, train_loss 3.6253e-01, additional_loss 6.9618e-03, test_loss 1.2959e+00, test_additional_loss 9.6543e-01\n",
      "step 31, train_loss 3.6336e-01, additional_loss 1.3638e-02, test_loss 1.3784e+00, test_additional_loss 1.0401e+00\n",
      "step 32, train_loss 3.5084e-01, additional_loss 6.6757e-03, test_loss 1.4684e+00, test_additional_loss 1.1202e+00\n",
      "step 33, train_loss 3.4837e-01, additional_loss 1.0586e-02, test_loss 1.5778e+00, test_additional_loss 1.2160e+00\n",
      "step 34, train_loss 3.4361e-01, additional_loss 1.3685e-02, test_loss 1.7172e+00, test_additional_loss 1.3375e+00\n",
      "step 35, train_loss 3.3743e-01, additional_loss 1.5450e-02, test_loss 1.9540e+00, test_additional_loss 1.5397e+00\n",
      "step 36, train_loss 3.3523e-01, additional_loss 2.4557e-02, test_loss 2.2200e+00, test_additional_loss 1.7626e+00\n",
      "step 37, train_loss 3.2935e-01, additional_loss 3.0565e-02, test_loss 2.4773e+00, test_additional_loss 1.9728e+00\n",
      "step 38, train_loss 3.1180e-01, additional_loss 2.5225e-02, test_loss 2.7380e+00, test_additional_loss 2.1824e+00\n",
      "step 39, train_loss 3.3387e-01, additional_loss 5.7411e-02, test_loss 3.0414e+00, test_additional_loss 2.4229e+00\n",
      "step 40, train_loss 3.3145e-01, additional_loss 6.5422e-02, test_loss 3.3682e+00, test_additional_loss 2.6768e+00\n",
      "step 41, train_loss 2.7760e-01, additional_loss 2.1124e-02, test_loss 3.6651e+00, test_additional_loss 2.9019e+00\n",
      "step 42, train_loss 3.4403e-01, additional_loss 9.7322e-02, test_loss 3.9377e+00, test_additional_loss 3.1066e+00\n",
      "step 43, train_loss 3.6138e-01, additional_loss 1.2259e-01, test_loss 4.2232e+00, test_additional_loss 3.3204e+00\n",
      "step 44, train_loss 2.8126e-01, additional_loss 4.7302e-02, test_loss 4.4062e+00, test_additional_loss 3.4551e+00\n",
      "step 45, train_loss 3.4313e-01, additional_loss 1.1234e-01, test_loss 4.5820e+00, test_additional_loss 3.5831e+00\n",
      "step 46, train_loss 3.5562e-01, additional_loss 1.2960e-01, test_loss 4.7448e+00, test_additional_loss 3.7013e+00\n",
      "step 47, train_loss 2.7296e-01, additional_loss 5.1069e-02, test_loss 4.6877e+00, test_additional_loss 3.6454e+00\n",
      "step 48, train_loss 3.3018e-01, additional_loss 1.1539e-01, test_loss 4.6223e+00, test_additional_loss 3.5872e+00\n",
      "step 49, train_loss 3.5100e-01, additional_loss 1.4253e-01, test_loss 4.5359e+00, test_additional_loss 3.5244e+00\n",
      "step 50, train_loss 2.7651e-01, additional_loss 7.5722e-02, test_loss 4.4114e+00, test_additional_loss 3.4361e+00\n",
      "Val metric improved. 4.411358833312988 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137581.98398.pt\n",
      "Final train loss 1.9130e-01 +/- 4.0582e-01\n",
      "Final test loss 9.7522e-01 +/- 1.7705e+00\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "step 0, train_loss 1.7850e-01, additional_loss 2.8789e-02, test_loss 1.2904e-01, test_additional_loss 5.9009e-03\n",
      "step 1, train_loss 1.1242e-01, additional_loss 1.6356e-02, test_loss 1.2069e-01, test_additional_loss 2.5988e-03\n",
      "step 2, train_loss 9.3309e-02, additional_loss 1.6212e-03, test_loss 1.1863e-01, test_additional_loss 1.0490e-03\n",
      "step 3, train_loss 9.4354e-02, additional_loss 3.8624e-03, test_loss 1.1840e-01, test_additional_loss 1.0610e-03\n",
      "step 4, train_loss 9.3502e-02, additional_loss 4.3154e-03, test_loss 1.1812e-01, test_additional_loss 1.5378e-03\n",
      "step 5, train_loss 8.9098e-02, additional_loss 2.4796e-03, test_loss 1.1793e-01, test_additional_loss 3.2306e-03\n",
      "step 6, train_loss 8.3003e-02, additional_loss 3.7789e-03, test_loss 1.1874e-01, test_additional_loss 7.1526e-03\n",
      "step 7, train_loss 7.3084e-02, additional_loss 1.1516e-02, test_loss 1.2538e-01, test_additional_loss 1.5116e-02\n",
      "step 8, train_loss 4.6994e-02, additional_loss 1.4424e-02, test_loss 1.5037e-01, test_additional_loss 2.5570e-02\n",
      "step 9, train_loss 9.5091e-02, additional_loss 4.3392e-02, test_loss 1.5552e-01, test_additional_loss 2.6274e-02\n",
      "step 10, train_loss 5.1671e-02, additional_loss 3.0077e-02, test_loss 1.3379e-01, test_additional_loss 1.5223e-02\n",
      "step 11, train_loss 5.7403e-02, additional_loss 3.2306e-02, test_loss 1.2699e-01, test_additional_loss 9.3818e-03\n",
      "step 12, train_loss 5.0114e-02, additional_loss 8.9288e-03, test_loss 1.3510e-01, test_additional_loss 1.1683e-02\n",
      "step 13, train_loss 4.9688e-02, additional_loss 4.8757e-03, test_loss 1.4755e-01, test_additional_loss 1.3554e-02\n",
      "step 14, train_loss 4.9366e-02, additional_loss 1.0443e-02, test_loss 1.5062e-01, test_additional_loss 1.5271e-02\n",
      "step 15, train_loss 3.3556e-02, additional_loss 6.6280e-03, test_loss 1.5365e-01, test_additional_loss 1.9109e-02\n",
      "step 16, train_loss 3.4704e-02, additional_loss 1.9538e-02, test_loss 1.5980e-01, test_additional_loss 2.1863e-02\n",
      "step 17, train_loss 3.4499e-02, additional_loss 2.1732e-02, test_loss 1.5817e-01, test_additional_loss 1.9908e-02\n",
      "step 18, train_loss 2.4195e-02, additional_loss 1.1826e-02, test_loss 1.4668e-01, test_additional_loss 1.3959e-02\n",
      "step 19, train_loss 4.5574e-02, additional_loss 3.4630e-02, test_loss 1.3370e-01, test_additional_loss 1.0288e-02\n",
      "step 20, train_loss 3.8723e-02, additional_loss 2.5177e-02, test_loss 1.2812e-01, test_additional_loss 9.7394e-03\n",
      "step 21, train_loss 3.1361e-02, additional_loss 1.2398e-02, test_loss 1.2857e-01, test_additional_loss 1.0455e-02\n",
      "step 22, train_loss 3.1878e-02, additional_loss 1.2779e-02, test_loss 1.3370e-01, test_additional_loss 1.2779e-02\n",
      "step 23, train_loss 4.1668e-02, additional_loss 2.7859e-02, test_loss 1.3804e-01, test_additional_loss 1.3864e-02\n",
      "step 24, train_loss 3.3706e-02, additional_loss 2.4974e-02, test_loss 1.3915e-01, test_additional_loss 1.2386e-02\n",
      "step 25, train_loss 1.5747e-02, additional_loss 7.8917e-03, test_loss 1.4000e-01, test_additional_loss 1.3053e-02\n",
      "step 26, train_loss 2.5356e-02, additional_loss 1.6475e-02, test_loss 1.3816e-01, test_additional_loss 1.2374e-02\n",
      "step 27, train_loss 1.9432e-02, additional_loss 1.1134e-02, test_loss 1.3714e-01, test_additional_loss 1.3816e-02\n",
      "step 28, train_loss 2.1207e-02, additional_loss 1.3733e-02, test_loss 1.3458e-01, test_additional_loss 1.3697e-02\n",
      "step 29, train_loss 2.1800e-02, additional_loss 1.2946e-02, test_loss 1.3005e-01, test_additional_loss 1.0610e-02\n",
      "step 30, train_loss 1.4790e-02, additional_loss 4.4227e-03, test_loss 1.3003e-01, test_additional_loss 1.0884e-02\n",
      "step 31, train_loss 1.9000e-02, additional_loss 9.6917e-03, test_loss 1.3215e-01, test_additional_loss 1.1373e-02\n",
      "step 32, train_loss 1.2793e-02, additional_loss 4.8876e-03, test_loss 1.3917e-01, test_additional_loss 1.5771e-02\n",
      "step 33, train_loss 1.9287e-02, additional_loss 1.2672e-02, test_loss 1.4146e-01, test_additional_loss 1.6046e-02\n",
      "step 34, train_loss 1.6880e-02, additional_loss 1.0157e-02, test_loss 1.3799e-01, test_additional_loss 1.2493e-02\n",
      "step 35, train_loss 2.9005e-02, additional_loss 2.1648e-02, test_loss 1.3524e-01, test_additional_loss 1.1849e-02\n",
      "step 36, train_loss 2.3679e-02, additional_loss 1.7273e-02, test_loss 1.3200e-01, test_additional_loss 1.1504e-02\n",
      "step 37, train_loss 1.0227e-02, additional_loss 4.1604e-03, test_loss 1.3063e-01, test_additional_loss 1.0705e-02\n",
      "step 38, train_loss 1.5372e-02, additional_loss 8.0824e-03, test_loss 1.3002e-01, test_additional_loss 9.6917e-03\n",
      "step 39, train_loss 2.4497e-02, additional_loss 1.6582e-02, test_loss 1.3013e-01, test_additional_loss 1.0824e-02\n",
      "step 40, train_loss 1.7435e-02, additional_loss 1.1504e-02, test_loss 1.3188e-01, test_additional_loss 1.3638e-02\n",
      "step 41, train_loss 1.3794e-02, additional_loss 9.7632e-03, test_loss 1.3485e-01, test_additional_loss 1.4853e-02\n",
      "step 42, train_loss 1.6347e-02, additional_loss 1.2815e-02, test_loss 1.3576e-01, test_additional_loss 1.4091e-02\n",
      "step 43, train_loss 8.6696e-03, additional_loss 5.1975e-03, test_loss 1.3690e-01, test_additional_loss 1.4997e-02\n",
      "step 44, train_loss 5.9839e-03, additional_loss 2.9683e-03, test_loss 1.3816e-01, test_additional_loss 1.4913e-02\n",
      "step 45, train_loss 1.6571e-02, additional_loss 1.3721e-02, test_loss 1.3523e-01, test_additional_loss 1.5056e-02\n",
      "step 46, train_loss 8.3105e-03, additional_loss 5.7936e-03, test_loss 1.3205e-01, test_additional_loss 1.7118e-02\n",
      "step 47, train_loss 2.2351e-02, additional_loss 2.0254e-02, test_loss 1.3055e-01, test_additional_loss 1.6534e-02\n",
      "step 48, train_loss 2.3785e-02, additional_loss 2.1434e-02, test_loss 1.2971e-01, test_additional_loss 1.4544e-02\n",
      "step 49, train_loss 1.2084e-02, additional_loss 8.4281e-03, test_loss 1.3447e-01, test_additional_loss 1.3316e-02\n",
      "step 50, train_loss 1.9137e-02, additional_loss 1.4579e-02, test_loss 1.3661e-01, test_additional_loss 1.3256e-02\n",
      "Val metric improved. 0.13661402463912964 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137582.4537349.pt\n",
      "Final train loss 4.5375e-03 +/- 8.4588e-03\n",
      "Final test loss 1.2336e-01 +/- 2.3985e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "step 0, train_loss 2.2061e-02, additional_loss 1.7524e-02, test_loss 1.6119e-01, test_additional_loss 2.5368e-02\n",
      "step 1, train_loss 1.3115e-01, additional_loss 1.2277e-01, test_loss 1.3547e-01, test_additional_loss 1.7893e-02\n",
      "step 2, train_loss 6.3816e-02, additional_loss 3.9327e-02, test_loss 1.3101e-01, test_additional_loss 1.8573e-02\n",
      "step 3, train_loss 6.3308e-02, additional_loss 9.6917e-03, test_loss 1.3021e-01, test_additional_loss 1.6451e-02\n",
      "step 4, train_loss 6.9448e-02, additional_loss 1.0157e-02, test_loss 1.2902e-01, test_additional_loss 1.4770e-02\n",
      "step 5, train_loss 6.3967e-02, additional_loss 7.2598e-03, test_loss 1.2842e-01, test_additional_loss 1.3173e-02\n",
      "step 6, train_loss 5.7933e-02, additional_loss 8.2970e-03, test_loss 1.3098e-01, test_additional_loss 1.4675e-02\n",
      "step 7, train_loss 4.8048e-02, additional_loss 8.6665e-03, test_loss 1.3920e-01, test_additional_loss 1.8609e-02\n",
      "step 8, train_loss 3.9463e-02, additional_loss 1.5116e-02, test_loss 1.5171e-01, test_additional_loss 2.3580e-02\n",
      "step 9, train_loss 2.6296e-02, additional_loss 1.3816e-02, test_loss 1.7005e-01, test_additional_loss 3.4010e-02\n",
      "step 10, train_loss 3.7983e-02, additional_loss 2.6858e-02, test_loss 1.7798e-01, test_additional_loss 3.6526e-02\n",
      "step 11, train_loss 2.4487e-02, additional_loss 1.4460e-02, test_loss 1.7136e-01, test_additional_loss 2.6917e-02\n",
      "step 12, train_loss 2.6233e-02, additional_loss 1.6916e-02, test_loss 1.6037e-01, test_additional_loss 2.0540e-02\n",
      "step 13, train_loss 2.5105e-02, additional_loss 1.1778e-02, test_loss 1.5606e-01, test_additional_loss 1.3816e-02\n",
      "step 14, train_loss 2.6463e-02, additional_loss 1.0550e-02, test_loss 1.5631e-01, test_additional_loss 1.7941e-02\n",
      "step 15, train_loss 2.0197e-02, additional_loss 8.1062e-03, test_loss 1.5339e-01, test_additional_loss 2.3389e-02\n",
      "step 16, train_loss 2.7468e-02, additional_loss 1.8907e-02, test_loss 1.4990e-01, test_additional_loss 2.4772e-02\n",
      "step 17, train_loss 3.2507e-02, additional_loss 2.6691e-02, test_loss 1.5146e-01, test_additional_loss 2.8026e-02\n",
      "step 18, train_loss 2.8846e-02, additional_loss 2.3842e-02, test_loss 1.5759e-01, test_additional_loss 3.2830e-02\n",
      "step 19, train_loss 3.2400e-02, additional_loss 2.6309e-02, test_loss 1.5893e-01, test_additional_loss 3.1936e-02\n",
      "step 20, train_loss 3.4987e-02, additional_loss 2.8098e-02, test_loss 1.5138e-01, test_additional_loss 2.7752e-02\n",
      "step 21, train_loss 2.1169e-02, additional_loss 1.3816e-02, test_loss 1.4709e-01, test_additional_loss 2.6965e-02\n",
      "step 22, train_loss 3.5239e-02, additional_loss 2.6643e-02, test_loss 1.4523e-01, test_additional_loss 2.6238e-02\n",
      "step 23, train_loss 3.8340e-02, additional_loss 2.8515e-02, test_loss 1.4463e-01, test_additional_loss 2.5308e-02\n",
      "step 24, train_loss 3.1091e-02, additional_loss 2.1029e-02, test_loss 1.4569e-01, test_additional_loss 2.4676e-02\n",
      "step 25, train_loss 2.0624e-02, additional_loss 1.1015e-02, test_loss 1.4834e-01, test_additional_loss 2.2817e-02\n",
      "step 26, train_loss 3.5664e-02, additional_loss 2.6762e-02, test_loss 1.4752e-01, test_additional_loss 2.2578e-02\n",
      "step 27, train_loss 3.4724e-02, additional_loss 2.6274e-02, test_loss 1.4537e-01, test_additional_loss 2.3746e-02\n",
      "step 28, train_loss 2.3502e-02, additional_loss 1.5855e-02, test_loss 1.4056e-01, test_additional_loss 2.4486e-02\n",
      "step 29, train_loss 2.3805e-02, additional_loss 1.7560e-02, test_loss 1.3991e-01, test_additional_loss 2.5320e-02\n",
      "step 30, train_loss 2.4808e-02, additional_loss 1.9550e-02, test_loss 1.4153e-01, test_additional_loss 2.6131e-02\n",
      "step 31, train_loss 1.9596e-02, additional_loss 1.4484e-02, test_loss 1.4309e-01, test_additional_loss 2.3866e-02\n",
      "step 32, train_loss 1.2845e-02, additional_loss 6.3777e-03, test_loss 1.4313e-01, test_additional_loss 2.3234e-02\n",
      "step 33, train_loss 1.3405e-02, additional_loss 6.9857e-03, test_loss 1.4309e-01, test_additional_loss 2.4831e-02\n",
      "step 34, train_loss 1.5301e-02, additional_loss 1.0347e-02, test_loss 1.4918e-01, test_additional_loss 2.8062e-02\n",
      "step 35, train_loss 1.1506e-02, additional_loss 7.9632e-03, test_loss 1.5681e-01, test_additional_loss 2.8026e-02\n",
      "step 36, train_loss 6.7474e-03, additional_loss 3.0994e-03, test_loss 1.5718e-01, test_additional_loss 2.7585e-02\n",
      "step 37, train_loss 1.6528e-02, additional_loss 1.2970e-02, test_loss 1.5930e-01, test_additional_loss 2.6071e-02\n",
      "step 38, train_loss 2.1438e-02, additional_loss 1.7726e-02, test_loss 1.5909e-01, test_additional_loss 2.7406e-02\n",
      "step 39, train_loss 9.8861e-03, additional_loss 6.8069e-03, test_loss 1.5548e-01, test_additional_loss 2.9802e-02\n",
      "step 40, train_loss 2.2094e-02, additional_loss 1.9801e-02, test_loss 1.5218e-01, test_additional_loss 2.8574e-02\n",
      "step 41, train_loss 2.6211e-02, additional_loss 2.3711e-02, test_loss 1.5038e-01, test_additional_loss 2.5237e-02\n",
      "step 42, train_loss 1.9576e-02, additional_loss 1.4734e-02, test_loss 1.4319e-01, test_additional_loss 2.1839e-02\n",
      "step 43, train_loss 9.8086e-03, additional_loss 2.6226e-03, test_loss 1.4306e-01, test_additional_loss 2.0337e-02\n",
      "step 44, train_loss 1.5565e-02, additional_loss 8.4877e-03, test_loss 1.4550e-01, test_additional_loss 2.2197e-02\n",
      "step 45, train_loss 1.4547e-02, additional_loss 1.0443e-02, test_loss 1.4991e-01, test_additional_loss 2.3019e-02\n",
      "step 46, train_loss 2.0419e-02, additional_loss 1.6761e-02, test_loss 1.5092e-01, test_additional_loss 2.3818e-02\n",
      "step 47, train_loss 1.8062e-02, additional_loss 1.3590e-02, test_loss 1.4440e-01, test_additional_loss 2.2125e-02\n",
      "step 48, train_loss 2.1558e-02, additional_loss 1.7321e-02, test_loss 1.3741e-01, test_additional_loss 1.8358e-02\n",
      "step 49, train_loss 1.5973e-02, additional_loss 1.3292e-02, test_loss 1.3469e-01, test_additional_loss 1.4532e-02\n",
      "step 50, train_loss 1.7758e-02, additional_loss 1.1313e-02, test_loss 1.3665e-01, test_additional_loss 1.1563e-02\n",
      "Val metric improved. 0.13664545118808746 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137582.930687.pt\n",
      "Final train loss 1.0762e-02 +/- 2.0796e-02\n",
      "Final test loss 1.2508e-01 +/- 2.3759e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-4_time_scale-3_t_span_min-0_t_span_max-4.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-4_time_scale-3_t_span_min-0_t_span_max-4.pkl not found.\n",
      "Creating new data...\n",
      "Trajectory d8e1fe3ed2d64bb5b29ca86558cd03cc: 500 steps (last t: tensor([2.8797]))\n",
      "step 0, train_loss 1.6868e+02, additional_loss 2.0548e+00, test_loss 7.0408e-01, test_additional_loss 5.7287e-01\n",
      "step 1, train_loss 1.8383e+02, additional_loss 1.7192e+01, test_loss 1.8206e-01, test_additional_loss 4.6301e-02\n",
      "step 2, train_loss 1.6944e+02, additional_loss 2.8077e+00, test_loss 1.3860e-01, test_additional_loss 2.6226e-03\n",
      "step 3, train_loss 1.6672e+02, additional_loss 8.6880e-02, test_loss 1.6489e-01, test_additional_loss 2.8968e-02\n",
      "step 4, train_loss 1.6776e+02, additional_loss 1.1321e+00, test_loss 1.4666e-01, test_additional_loss 1.0657e-02\n",
      "step 5, train_loss 1.6704e+02, additional_loss 4.1523e-01, test_loss 1.4304e-01, test_additional_loss 6.9380e-03\n",
      "step 6, train_loss 1.6688e+02, additional_loss 2.4729e-01, test_loss 1.4036e-01, test_additional_loss 4.2915e-03\n",
      "step 7, train_loss 1.6678e+02, additional_loss 1.4849e-01, test_loss 1.3785e-01, test_additional_loss 1.8120e-03\n",
      "step 8, train_loss 1.6665e+02, additional_loss 2.2602e-02, test_loss 1.3815e-01, test_additional_loss 2.1219e-03\n",
      "step 9, train_loss 1.6667e+02, additional_loss 3.5954e-02, test_loss 1.3815e-01, test_additional_loss 2.1219e-03\n",
      "step 10, train_loss 1.6665e+02, additional_loss 2.1839e-02, test_loss 1.3787e-01, test_additional_loss 1.8358e-03\n",
      "step 11, train_loss 1.6664e+02, additional_loss 9.6321e-03, test_loss 1.3801e-01, test_additional_loss 1.9789e-03\n",
      "step 12, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 13, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 14, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 15, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 16, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 17, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 18, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 19, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 20, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 21, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 22, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 23, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 24, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 25, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 26, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 27, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 28, train_loss 1.6664e+02, additional_loss 8.3923e-03, test_loss 1.3816e-01, test_additional_loss 2.1219e-03\n",
      "step 29, train_loss 1.6663e+02, additional_loss 5.5313e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 30, train_loss 1.6664e+02, additional_loss 7.2479e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 31, train_loss 1.6664e+02, additional_loss 8.3923e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 32, train_loss 1.6664e+02, additional_loss 7.2479e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 33, train_loss 1.6664e+02, additional_loss 7.4387e-03, test_loss 1.3818e-01, test_additional_loss 2.1458e-03\n",
      "step 34, train_loss 1.6664e+02, additional_loss 7.1526e-03, test_loss 1.3816e-01, test_additional_loss 2.1219e-03\n",
      "step 35, train_loss 1.6666e+02, additional_loss 3.0708e-02, test_loss 1.3823e-01, test_additional_loss 2.1935e-03\n",
      "step 36, train_loss 1.6665e+02, additional_loss 1.9836e-02, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 37, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 38, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 39, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 40, train_loss 1.6664e+02, additional_loss 8.3923e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 41, train_loss 1.6664e+02, additional_loss 7.4387e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 42, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3802e-01, test_additional_loss 1.9789e-03\n",
      "step 43, train_loss 1.6664e+02, additional_loss 7.7248e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 44, train_loss 1.6664e+02, additional_loss 8.5831e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 45, train_loss 1.6664e+02, additional_loss 7.6294e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 46, train_loss 1.6664e+02, additional_loss 7.4387e-03, test_loss 1.3816e-01, test_additional_loss 2.1219e-03\n",
      "step 47, train_loss 1.6664e+02, additional_loss 1.0300e-02, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 48, train_loss 1.6664e+02, additional_loss 7.3433e-03, test_loss 1.3804e-01, test_additional_loss 2.0027e-03\n",
      "step 49, train_loss 1.6664e+02, additional_loss 8.4877e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "step 50, train_loss 1.6664e+02, additional_loss 7.1526e-03, test_loss 1.3806e-01, test_additional_loss 2.0266e-03\n",
      "Val metric improved. 0.13806253671646118 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137584.034577.pt\n",
      "Final train loss 1.6663e+02 +/- 1.5052e+03\n",
      "Final test loss 1.3604e-01 +/- 3.3474e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "step 0, train_loss 9.6185e-02, additional_loss 1.4305e-04, test_loss 1.1933e-01, test_additional_loss 4.5300e-04\n",
      "step 1, train_loss 9.4351e-02, additional_loss 1.8835e-03, test_loss 1.1965e-01, test_additional_loss 1.5974e-03\n",
      "step 2, train_loss 8.4443e-02, additional_loss 2.4915e-03, test_loss 1.2360e-01, test_additional_loss 6.7353e-03\n",
      "step 3, train_loss 6.6313e-02, additional_loss 6.9857e-03, test_loss 1.3044e-01, test_additional_loss 1.1384e-02\n",
      "step 4, train_loss 3.8078e-02, additional_loss 1.3316e-02, test_loss 1.5228e-01, test_additional_loss 2.1946e-02\n",
      "step 5, train_loss 1.2410e-01, additional_loss 7.0846e-02, test_loss 1.4018e-01, test_additional_loss 1.9252e-02\n",
      "step 6, train_loss 3.5371e-02, additional_loss 2.6453e-02, test_loss 1.3479e-01, test_additional_loss 1.7273e-02\n",
      "step 7, train_loss 4.1907e-02, additional_loss 1.6761e-02, test_loss 1.3297e-01, test_additional_loss 1.4806e-02\n",
      "step 8, train_loss 4.8668e-02, additional_loss 1.0693e-02, test_loss 1.3336e-01, test_additional_loss 1.2445e-02\n",
      "step 9, train_loss 5.1291e-02, additional_loss 1.2362e-02, test_loss 1.3764e-01, test_additional_loss 1.4353e-02\n",
      "step 10, train_loss 4.0450e-02, additional_loss 1.1480e-02, test_loss 1.5036e-01, test_additional_loss 2.2638e-02\n",
      "step 11, train_loss 3.7405e-02, additional_loss 2.3663e-02, test_loss 1.7111e-01, test_additional_loss 3.1054e-02\n",
      "step 12, train_loss 4.1155e-02, additional_loss 3.4428e-02, test_loss 1.7595e-01, test_additional_loss 3.3474e-02\n",
      "step 13, train_loss 3.6956e-02, additional_loss 2.9600e-02, test_loss 1.6334e-01, test_additional_loss 2.8348e-02\n",
      "step 14, train_loss 2.4562e-02, additional_loss 1.6296e-02, test_loss 1.5266e-01, test_additional_loss 2.2817e-02\n",
      "step 15, train_loss 2.8020e-02, additional_loss 1.3781e-02, test_loss 1.5313e-01, test_additional_loss 2.5189e-02\n",
      "step 16, train_loss 2.3258e-02, additional_loss 5.2810e-03, test_loss 1.6174e-01, test_additional_loss 3.0184e-02\n",
      "step 17, train_loss 3.0209e-02, additional_loss 1.4758e-02, test_loss 1.6738e-01, test_additional_loss 3.0589e-02\n",
      "step 18, train_loss 1.7539e-02, additional_loss 5.9366e-03, test_loss 1.7794e-01, test_additional_loss 3.1829e-02\n",
      "step 19, train_loss 2.4920e-02, additional_loss 1.4555e-02, test_loss 1.9065e-01, test_additional_loss 3.6263e-02\n",
      "step 20, train_loss 1.8047e-02, additional_loss 7.8559e-03, test_loss 2.0554e-01, test_additional_loss 4.3631e-02\n",
      "step 21, train_loss 4.4754e-02, additional_loss 3.8326e-02, test_loss 2.0140e-01, test_additional_loss 4.2999e-02\n",
      "step 22, train_loss 4.8503e-02, additional_loss 4.3797e-02, test_loss 1.8363e-01, test_additional_loss 3.5655e-02\n",
      "step 23, train_loss 3.5302e-02, additional_loss 2.8026e-02, test_loss 1.6621e-01, test_additional_loss 2.6417e-02\n",
      "step 24, train_loss 2.0054e-02, additional_loss 8.3327e-03, test_loss 1.5787e-01, test_additional_loss 1.9264e-02\n",
      "step 25, train_loss 3.7251e-02, additional_loss 2.4211e-02, test_loss 1.5425e-01, test_additional_loss 1.7428e-02\n",
      "step 26, train_loss 4.1774e-02, additional_loss 3.0410e-02, test_loss 1.5050e-01, test_additional_loss 1.7619e-02\n",
      "step 27, train_loss 3.5284e-02, additional_loss 2.7001e-02, test_loss 1.5277e-01, test_additional_loss 1.9765e-02\n",
      "step 28, train_loss 3.5968e-02, additional_loss 2.9445e-02, test_loss 1.5660e-01, test_additional_loss 2.1017e-02\n",
      "step 29, train_loss 3.2952e-02, additional_loss 2.6667e-02, test_loss 1.6092e-01, test_additional_loss 2.1267e-02\n",
      "step 30, train_loss 2.9133e-02, additional_loss 2.1756e-02, test_loss 1.6685e-01, test_additional_loss 2.4319e-02\n",
      "step 31, train_loss 2.4458e-02, additional_loss 1.4114e-02, test_loss 1.7751e-01, test_additional_loss 2.9111e-02\n",
      "step 32, train_loss 2.5947e-02, additional_loss 1.3328e-02, test_loss 1.9125e-01, test_additional_loss 3.1674e-02\n",
      "step 33, train_loss 1.5771e-02, additional_loss 2.8253e-03, test_loss 2.1244e-01, test_additional_loss 3.6621e-02\n",
      "step 34, train_loss 2.6859e-02, additional_loss 1.4174e-02, test_loss 2.0957e-01, test_additional_loss 3.0422e-02\n",
      "step 35, train_loss 1.8374e-02, additional_loss 9.4533e-03, test_loss 2.0337e-01, test_additional_loss 2.3127e-02\n",
      "step 36, train_loss 1.6234e-02, additional_loss 9.4652e-03, test_loss 2.0306e-01, test_additional_loss 2.2864e-02\n",
      "step 37, train_loss 1.3177e-02, additional_loss 6.7472e-03, test_loss 2.0668e-01, test_additional_loss 2.4962e-02\n",
      "step 38, train_loss 2.1419e-02, additional_loss 1.4508e-02, test_loss 2.0643e-01, test_additional_loss 2.7955e-02\n",
      "step 39, train_loss 1.9675e-02, additional_loss 1.3244e-02, test_loss 2.0200e-01, test_additional_loss 2.8038e-02\n",
      "step 40, train_loss 2.0244e-02, additional_loss 1.4853e-02, test_loss 1.9885e-01, test_additional_loss 2.8110e-02\n",
      "step 41, train_loss 2.4740e-02, additional_loss 1.9670e-02, test_loss 1.9383e-01, test_additional_loss 2.6393e-02\n",
      "step 42, train_loss 1.6703e-02, additional_loss 1.1671e-02, test_loss 1.9727e-01, test_additional_loss 3.1888e-02\n",
      "step 43, train_loss 2.4178e-02, additional_loss 1.8907e-02, test_loss 1.9549e-01, test_additional_loss 3.4904e-02\n",
      "step 44, train_loss 2.8204e-02, additional_loss 2.3091e-02, test_loss 1.9212e-01, test_additional_loss 3.9661e-02\n",
      "step 45, train_loss 1.4361e-02, additional_loss 9.6202e-03, test_loss 1.8820e-01, test_additional_loss 4.5300e-02\n",
      "step 46, train_loss 2.6653e-02, additional_loss 2.2399e-02, test_loss 1.8116e-01, test_additional_loss 4.4906e-02\n",
      "step 47, train_loss 3.9763e-02, additional_loss 3.4881e-02, test_loss 1.7063e-01, test_additional_loss 3.8505e-02\n",
      "step 48, train_loss 3.2119e-02, additional_loss 2.5058e-02, test_loss 1.6296e-01, test_additional_loss 3.1376e-02\n",
      "step 49, train_loss 1.8310e-02, additional_loss 9.0361e-03, test_loss 1.6410e-01, test_additional_loss 2.7943e-02\n",
      "step 50, train_loss 2.1739e-02, additional_loss 1.2970e-02, test_loss 1.6907e-01, test_additional_loss 2.9147e-02\n",
      "Val metric improved. 0.1690673977136612 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137584.593982.pt\n",
      "Final train loss 6.4222e-03 +/- 1.2454e-02\n",
      "Final test loss 1.3992e-01 +/- 2.6654e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-2_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "step 0, train_loss 2.4697e-02, additional_loss 1.8275e-02, test_loss 1.9877e-01, test_additional_loss 5.4109e-02\n",
      "step 1, train_loss 1.2863e-01, additional_loss 1.0910e-01, test_loss 1.4704e-01, test_additional_loss 3.1602e-02\n",
      "step 2, train_loss 6.3388e-02, additional_loss 4.6217e-02, test_loss 1.2788e-01, test_additional_loss 1.5235e-02\n",
      "step 3, train_loss 6.6639e-02, additional_loss 1.9050e-02, test_loss 1.2637e-01, test_additional_loss 1.0645e-02\n",
      "step 4, train_loss 6.9546e-02, additional_loss 1.1837e-02, test_loss 1.2947e-01, test_additional_loss 9.4295e-03\n",
      "step 5, train_loss 6.6616e-02, additional_loss 9.6321e-03, test_loss 1.3479e-01, test_additional_loss 1.0312e-02\n",
      "step 6, train_loss 5.7284e-02, additional_loss 8.3089e-03, test_loss 1.4600e-01, test_additional_loss 1.5676e-02\n",
      "step 7, train_loss 4.6949e-02, additional_loss 1.2171e-02, test_loss 1.7504e-01, test_additional_loss 2.6584e-02\n",
      "step 8, train_loss 4.4916e-02, additional_loss 3.0172e-02, test_loss 1.9016e-01, test_additional_loss 3.1912e-02\n",
      "step 9, train_loss 3.2707e-02, additional_loss 2.1577e-02, test_loss 1.9134e-01, test_additional_loss 3.0041e-02\n",
      "step 10, train_loss 2.0400e-02, additional_loss 7.4029e-03, test_loss 1.9058e-01, test_additional_loss 2.4879e-02\n",
      "step 11, train_loss 2.2931e-02, additional_loss 7.8440e-03, test_loss 1.9235e-01, test_additional_loss 2.6870e-02\n",
      "step 12, train_loss 2.0418e-02, additional_loss 7.9751e-03, test_loss 1.9520e-01, test_additional_loss 2.6631e-02\n",
      "step 13, train_loss 1.4386e-02, additional_loss 3.9577e-03, test_loss 1.9745e-01, test_additional_loss 2.3723e-02\n",
      "step 14, train_loss 2.0280e-02, additional_loss 1.1158e-02, test_loss 2.0375e-01, test_additional_loss 2.7919e-02\n",
      "step 15, train_loss 1.9584e-02, additional_loss 1.2839e-02, test_loss 2.1330e-01, test_additional_loss 4.1938e-02\n",
      "step 16, train_loss 1.7402e-02, additional_loss 1.3030e-02, test_loss 2.1738e-01, test_additional_loss 4.8530e-02\n",
      "step 17, train_loss 2.6507e-02, additional_loss 2.2531e-02, test_loss 2.0134e-01, test_additional_loss 4.3714e-02\n",
      "step 18, train_loss 2.3461e-02, additional_loss 1.6415e-02, test_loss 1.9152e-01, test_additional_loss 3.5453e-02\n",
      "step 19, train_loss 2.8708e-02, additional_loss 1.8311e-02, test_loss 1.9184e-01, test_additional_loss 3.6502e-02\n",
      "step 20, train_loss 1.8888e-02, additional_loss 9.5129e-03, test_loss 2.1574e-01, test_additional_loss 4.9949e-02\n",
      "step 21, train_loss 2.6465e-02, additional_loss 2.1756e-02, test_loss 2.3948e-01, test_additional_loss 5.4967e-02\n",
      "step 22, train_loss 2.9674e-02, additional_loss 2.6488e-02, test_loss 2.4146e-01, test_additional_loss 4.6909e-02\n",
      "step 23, train_loss 1.1691e-02, additional_loss 7.9632e-03, test_loss 2.3729e-01, test_additional_loss 3.2723e-02\n",
      "step 24, train_loss 3.3598e-02, additional_loss 2.9516e-02, test_loss 2.0903e-01, test_additional_loss 2.7871e-02\n",
      "step 25, train_loss 3.7166e-02, additional_loss 3.2830e-02, test_loss 1.7688e-01, test_additional_loss 2.7585e-02\n",
      "step 26, train_loss 2.5392e-02, additional_loss 1.5485e-02, test_loss 1.6311e-01, test_additional_loss 3.1590e-02\n",
      "step 27, train_loss 2.8602e-02, additional_loss 1.4341e-02, test_loss 1.5973e-01, test_additional_loss 3.4010e-02\n",
      "step 28, train_loss 3.0667e-02, additional_loss 1.6689e-02, test_loss 1.6325e-01, test_additional_loss 3.6061e-02\n",
      "step 29, train_loss 3.2785e-02, additional_loss 2.2984e-02, test_loss 1.7082e-01, test_additional_loss 3.6204e-02\n",
      "step 30, train_loss 2.5520e-02, additional_loss 1.9693e-02, test_loss 1.7675e-01, test_additional_loss 3.1316e-02\n",
      "step 31, train_loss 1.6254e-02, additional_loss 1.0777e-02, test_loss 1.7858e-01, test_additional_loss 2.3043e-02\n",
      "step 32, train_loss 2.9064e-02, additional_loss 2.2972e-02, test_loss 1.7781e-01, test_additional_loss 2.0587e-02\n",
      "step 33, train_loss 2.5345e-02, additional_loss 2.0432e-02, test_loss 1.7299e-01, test_additional_loss 2.0385e-02\n",
      "step 34, train_loss 1.5217e-02, additional_loss 1.0598e-02, test_loss 1.7155e-01, test_additional_loss 2.3222e-02\n",
      "step 35, train_loss 2.0962e-02, additional_loss 1.5128e-02, test_loss 1.7230e-01, test_additional_loss 2.5213e-02\n",
      "step 36, train_loss 2.9688e-02, additional_loss 2.2686e-02, test_loss 1.7246e-01, test_additional_loss 2.3806e-02\n",
      "step 37, train_loss 2.9189e-02, additional_loss 2.1911e-02, test_loss 1.7392e-01, test_additional_loss 2.0874e-02\n",
      "step 38, train_loss 2.4342e-02, additional_loss 1.7774e-02, test_loss 1.8836e-01, test_additional_loss 2.6560e-02\n",
      "step 39, train_loss 1.2142e-02, additional_loss 6.7592e-03, test_loss 2.1241e-01, test_additional_loss 3.3808e-02\n",
      "step 40, train_loss 2.5856e-02, additional_loss 1.9908e-02, test_loss 2.0983e-01, test_additional_loss 3.4392e-02\n",
      "step 41, train_loss 2.5722e-02, additional_loss 2.0492e-02, test_loss 1.8879e-01, test_additional_loss 2.9385e-02\n",
      "step 42, train_loss 1.4620e-02, additional_loss 1.0705e-02, test_loss 1.6983e-01, test_additional_loss 2.4629e-02\n",
      "step 43, train_loss 9.9768e-03, additional_loss 5.8174e-03, test_loss 1.5914e-01, test_additional_loss 2.2209e-02\n",
      "step 44, train_loss 9.9454e-03, additional_loss 3.6240e-03, test_loss 1.5827e-01, test_additional_loss 2.2006e-02\n",
      "step 45, train_loss 1.4694e-02, additional_loss 8.9049e-03, test_loss 1.6450e-01, test_additional_loss 2.4390e-02\n",
      "step 46, train_loss 8.1854e-03, additional_loss 4.0531e-03, test_loss 1.7305e-01, test_additional_loss 2.7013e-02\n",
      "step 47, train_loss 1.6275e-02, additional_loss 1.3101e-02, test_loss 1.7588e-01, test_additional_loss 2.7514e-02\n",
      "step 48, train_loss 1.5006e-02, additional_loss 1.2422e-02, test_loss 1.7297e-01, test_additional_loss 2.6441e-02\n",
      "step 49, train_loss 1.3424e-02, additional_loss 1.1408e-02, test_loss 1.6746e-01, test_additional_loss 2.4462e-02\n",
      "step 50, train_loss 1.8473e-02, additional_loss 1.4913e-02, test_loss 1.6329e-01, test_additional_loss 2.3806e-02\n",
      "Val metric improved. 0.1632944494485855 < inf - 0.1\n",
      "Saving model to ../../../../models/dynnn-1718137585.0913.pt\n",
      "Final train loss 4.9009e-03 +/- 9.9394e-03\n",
      "Final test loss 1.3949e-01 +/- 2.7492e-01\n",
      "Loading data from ../../../../data/mve_data-n_samples-2-n_bodies-28_time_scale-1_t_span_min-0_t_span_max-4.pkl\n",
      "Data file mve_data-n_samples-2-n_bodies-28_time_scale-1_t_span_min-0_t_span_max-4.pkl not found.\n",
      "Creating new data...\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 500 steps (last t: tensor([7.6833e-10], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1000 steps (last t: tensor([1.9034e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1500 steps (last t: tensor([3.3333e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 2000 steps (last t: tensor([4.0973e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 2500 steps (last t: tensor([4.6917e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 3000 steps (last t: tensor([5.2265e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 3500 steps (last t: tensor([5.6935e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 4000 steps (last t: tensor([6.1070e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 4500 steps (last t: tensor([6.5234e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 5000 steps (last t: tensor([6.8621e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 5500 steps (last t: tensor([7.1771e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 6000 steps (last t: tensor([7.4913e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 6500 steps (last t: tensor([7.8012e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 7000 steps (last t: tensor([8.1059e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 7500 steps (last t: tensor([8.4120e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 8000 steps (last t: tensor([8.6980e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 8500 steps (last t: tensor([8.9790e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 9000 steps (last t: tensor([9.2348e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 9500 steps (last t: tensor([9.5142e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 10000 steps (last t: tensor([9.7505e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 10500 steps (last t: tensor([9.9688e-09], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 11000 steps (last t: tensor([1.0163e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 11500 steps (last t: tensor([1.0358e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 12000 steps (last t: tensor([1.0549e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 12500 steps (last t: tensor([1.0740e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 13000 steps (last t: tensor([1.0935e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 13500 steps (last t: tensor([1.1119e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 14000 steps (last t: tensor([1.1286e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 14500 steps (last t: tensor([1.1458e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 15000 steps (last t: tensor([1.1634e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 15500 steps (last t: tensor([1.1817e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 16000 steps (last t: tensor([1.1994e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 16500 steps (last t: tensor([1.2173e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 17000 steps (last t: tensor([1.2341e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 17500 steps (last t: tensor([1.2508e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 18000 steps (last t: tensor([1.2681e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 18500 steps (last t: tensor([1.2838e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 19000 steps (last t: tensor([1.2997e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 19500 steps (last t: tensor([1.3160e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 20000 steps (last t: tensor([1.3331e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 20500 steps (last t: tensor([1.3488e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 21000 steps (last t: tensor([1.3645e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 21500 steps (last t: tensor([1.3802e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 22000 steps (last t: tensor([1.3958e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 22500 steps (last t: tensor([1.4114e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 23000 steps (last t: tensor([1.4254e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 23500 steps (last t: tensor([1.4399e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 24000 steps (last t: tensor([1.4546e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 24500 steps (last t: tensor([1.4701e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 25000 steps (last t: tensor([1.4851e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 25500 steps (last t: tensor([1.5014e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 26000 steps (last t: tensor([1.5167e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 26500 steps (last t: tensor([1.5321e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 27000 steps (last t: tensor([1.5480e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 27500 steps (last t: tensor([1.5629e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 28000 steps (last t: tensor([1.5779e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 28500 steps (last t: tensor([1.5925e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 29000 steps (last t: tensor([1.6078e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 29500 steps (last t: tensor([1.6224e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 30000 steps (last t: tensor([1.6373e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 30500 steps (last t: tensor([1.6522e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 31000 steps (last t: tensor([1.6666e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 31500 steps (last t: tensor([1.6815e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 32000 steps (last t: tensor([1.6943e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 32500 steps (last t: tensor([1.7077e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 33000 steps (last t: tensor([1.7198e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 33500 steps (last t: tensor([1.7306e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 34000 steps (last t: tensor([1.7423e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 34500 steps (last t: tensor([1.7556e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 35000 steps (last t: tensor([1.7683e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 35500 steps (last t: tensor([1.7815e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 36000 steps (last t: tensor([1.7949e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 36500 steps (last t: tensor([1.8090e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 37000 steps (last t: tensor([1.8222e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 37500 steps (last t: tensor([1.8346e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 38000 steps (last t: tensor([1.8457e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 38500 steps (last t: tensor([1.8557e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 39000 steps (last t: tensor([1.8664e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 39500 steps (last t: tensor([1.8765e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 40000 steps (last t: tensor([1.8860e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 40500 steps (last t: tensor([1.8959e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 41000 steps (last t: tensor([1.9048e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 41500 steps (last t: tensor([1.9133e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 42000 steps (last t: tensor([1.9223e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 42500 steps (last t: tensor([1.9313e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 43000 steps (last t: tensor([1.9399e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 43500 steps (last t: tensor([1.9490e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 44000 steps (last t: tensor([1.9581e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 44500 steps (last t: tensor([1.9668e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 45000 steps (last t: tensor([1.9759e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 45500 steps (last t: tensor([1.9859e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 46000 steps (last t: tensor([1.9968e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 46500 steps (last t: tensor([2.0083e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 47000 steps (last t: tensor([2.0199e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 47500 steps (last t: tensor([2.0306e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 48000 steps (last t: tensor([2.0391e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 48500 steps (last t: tensor([2.0467e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 49000 steps (last t: tensor([2.0545e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 49500 steps (last t: tensor([2.0628e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 50000 steps (last t: tensor([2.0704e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 50500 steps (last t: tensor([2.0783e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 51000 steps (last t: tensor([2.0867e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 51500 steps (last t: tensor([2.0956e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 52000 steps (last t: tensor([2.1050e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 52500 steps (last t: tensor([2.1139e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 53000 steps (last t: tensor([2.1230e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 53500 steps (last t: tensor([2.1319e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 54000 steps (last t: tensor([2.1409e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 54500 steps (last t: tensor([2.1496e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 55000 steps (last t: tensor([2.1573e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 55500 steps (last t: tensor([2.1653e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 56000 steps (last t: tensor([2.1732e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 56500 steps (last t: tensor([2.1810e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 57000 steps (last t: tensor([2.1891e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 57500 steps (last t: tensor([2.1971e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 58000 steps (last t: tensor([2.2049e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 58500 steps (last t: tensor([2.2131e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 59000 steps (last t: tensor([2.2212e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 59500 steps (last t: tensor([2.2291e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 60000 steps (last t: tensor([2.2373e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 60500 steps (last t: tensor([2.2455e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 61000 steps (last t: tensor([2.2537e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 61500 steps (last t: tensor([2.2615e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 62000 steps (last t: tensor([2.2691e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 62500 steps (last t: tensor([2.2764e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 63000 steps (last t: tensor([2.2838e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 63500 steps (last t: tensor([2.2910e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 64000 steps (last t: tensor([2.2980e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 64500 steps (last t: tensor([2.3052e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 65000 steps (last t: tensor([2.3125e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 65500 steps (last t: tensor([2.3190e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 66000 steps (last t: tensor([2.3264e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 66500 steps (last t: tensor([2.3326e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 67000 steps (last t: tensor([2.3391e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 67500 steps (last t: tensor([2.3454e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 68000 steps (last t: tensor([2.3507e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 68500 steps (last t: tensor([2.3562e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 69000 steps (last t: tensor([2.3621e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 69500 steps (last t: tensor([2.3674e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 70000 steps (last t: tensor([2.3729e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 70500 steps (last t: tensor([2.3788e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 71000 steps (last t: tensor([2.3842e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 71500 steps (last t: tensor([2.3897e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 72000 steps (last t: tensor([2.3957e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 72500 steps (last t: tensor([2.4011e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 73000 steps (last t: tensor([2.4067e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 73500 steps (last t: tensor([2.4126e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 74000 steps (last t: tensor([2.4180e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 74500 steps (last t: tensor([2.4237e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 75000 steps (last t: tensor([2.4297e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 75500 steps (last t: tensor([2.4351e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 76000 steps (last t: tensor([2.4408e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 76500 steps (last t: tensor([2.4468e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 77000 steps (last t: tensor([2.4523e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 77500 steps (last t: tensor([2.4580e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 78000 steps (last t: tensor([2.4641e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 78500 steps (last t: tensor([2.4696e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 79000 steps (last t: tensor([2.4753e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 79500 steps (last t: tensor([2.4814e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 80000 steps (last t: tensor([2.4870e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 80500 steps (last t: tensor([2.4928e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 81000 steps (last t: tensor([2.4989e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 81500 steps (last t: tensor([2.5045e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 82000 steps (last t: tensor([2.5103e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 82500 steps (last t: tensor([2.5165e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 83000 steps (last t: tensor([2.5221e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 83500 steps (last t: tensor([2.5279e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 84000 steps (last t: tensor([2.5342e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 84500 steps (last t: tensor([2.5398e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 85000 steps (last t: tensor([2.5457e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 85500 steps (last t: tensor([2.5519e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 86000 steps (last t: tensor([2.5576e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 86500 steps (last t: tensor([2.5635e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 87000 steps (last t: tensor([2.5698e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 87500 steps (last t: tensor([2.5753e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 88000 steps (last t: tensor([2.5810e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 88500 steps (last t: tensor([2.5869e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 89000 steps (last t: tensor([2.5922e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 89500 steps (last t: tensor([2.5978e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 90000 steps (last t: tensor([2.6036e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 90500 steps (last t: tensor([2.6089e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 91000 steps (last t: tensor([2.6143e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 91500 steps (last t: tensor([2.6201e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 92000 steps (last t: tensor([2.6253e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 92500 steps (last t: tensor([2.6307e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 93000 steps (last t: tensor([2.6366e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 93500 steps (last t: tensor([2.6417e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 94000 steps (last t: tensor([2.6470e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 94500 steps (last t: tensor([2.6526e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 95000 steps (last t: tensor([2.6578e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 95500 steps (last t: tensor([2.6631e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 96000 steps (last t: tensor([2.6688e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 96500 steps (last t: tensor([2.6740e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 97000 steps (last t: tensor([2.6793e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 97500 steps (last t: tensor([2.6850e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 98000 steps (last t: tensor([2.6901e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 98500 steps (last t: tensor([2.6953e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 99000 steps (last t: tensor([2.7008e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 99500 steps (last t: tensor([2.7058e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 100000 steps (last t: tensor([2.7110e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 100500 steps (last t: tensor([2.7165e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 101000 steps (last t: tensor([2.7215e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 101500 steps (last t: tensor([2.7267e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 102000 steps (last t: tensor([2.7323e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 102500 steps (last t: tensor([2.7373e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 103000 steps (last t: tensor([2.7425e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 103500 steps (last t: tensor([2.7481e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 104000 steps (last t: tensor([2.7532e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 104500 steps (last t: tensor([2.7584e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 105000 steps (last t: tensor([2.7641e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 105500 steps (last t: tensor([2.7691e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 106000 steps (last t: tensor([2.7742e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 106500 steps (last t: tensor([2.7797e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 107000 steps (last t: tensor([2.7846e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 107500 steps (last t: tensor([2.7897e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 108000 steps (last t: tensor([2.7952e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 108500 steps (last t: tensor([2.8001e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 109000 steps (last t: tensor([2.8052e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 109500 steps (last t: tensor([2.8106e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 110000 steps (last t: tensor([2.8155e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 110500 steps (last t: tensor([2.8205e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 111000 steps (last t: tensor([2.8257e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 111500 steps (last t: tensor([2.8304e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 112000 steps (last t: tensor([2.8353e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 112500 steps (last t: tensor([2.8406e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 113000 steps (last t: tensor([2.8453e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 113500 steps (last t: tensor([2.8502e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 114000 steps (last t: tensor([2.8555e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 114500 steps (last t: tensor([2.8603e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 115000 steps (last t: tensor([2.8652e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 115500 steps (last t: tensor([2.8706e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 116000 steps (last t: tensor([2.8753e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 116500 steps (last t: tensor([2.8803e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 117000 steps (last t: tensor([2.8856e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 117500 steps (last t: tensor([2.8904e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 118000 steps (last t: tensor([2.8954e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 118500 steps (last t: tensor([2.9008e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 119000 steps (last t: tensor([2.9056e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 119500 steps (last t: tensor([2.9106e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 120000 steps (last t: tensor([2.9160e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 120500 steps (last t: tensor([2.9208e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 121000 steps (last t: tensor([2.9259e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 121500 steps (last t: tensor([2.9313e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 122000 steps (last t: tensor([2.9362e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 122500 steps (last t: tensor([2.9412e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 123000 steps (last t: tensor([2.9466e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 123500 steps (last t: tensor([2.9515e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 124000 steps (last t: tensor([2.9566e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 124500 steps (last t: tensor([2.9621e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 125000 steps (last t: tensor([2.9670e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 125500 steps (last t: tensor([2.9720e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 126000 steps (last t: tensor([2.9774e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 126500 steps (last t: tensor([2.9822e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 127000 steps (last t: tensor([2.9872e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 127500 steps (last t: tensor([2.9925e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 128000 steps (last t: tensor([2.9973e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 128500 steps (last t: tensor([3.0022e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 129000 steps (last t: tensor([3.0075e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 129500 steps (last t: tensor([3.0122e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 130000 steps (last t: tensor([3.0172e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 130500 steps (last t: tensor([3.0226e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 131000 steps (last t: tensor([3.0274e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 131500 steps (last t: tensor([3.0324e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 132000 steps (last t: tensor([3.0377e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 132500 steps (last t: tensor([3.0423e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 133000 steps (last t: tensor([3.0471e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 133500 steps (last t: tensor([3.0522e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 134000 steps (last t: tensor([3.0568e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 134500 steps (last t: tensor([3.0616e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 135000 steps (last t: tensor([3.0667e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 135500 steps (last t: tensor([3.0713e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 136000 steps (last t: tensor([3.0761e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 136500 steps (last t: tensor([3.0812e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 137000 steps (last t: tensor([3.0858e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 137500 steps (last t: tensor([3.0906e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 138000 steps (last t: tensor([3.0957e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 138500 steps (last t: tensor([3.1004e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 139000 steps (last t: tensor([3.1052e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 139500 steps (last t: tensor([3.1104e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 140000 steps (last t: tensor([3.1151e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 140500 steps (last t: tensor([3.1199e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 141000 steps (last t: tensor([3.1251e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 141500 steps (last t: tensor([3.1297e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 142000 steps (last t: tensor([3.1346e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 142500 steps (last t: tensor([3.1398e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 143000 steps (last t: tensor([3.1444e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 143500 steps (last t: tensor([3.1492e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 144000 steps (last t: tensor([3.1543e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 144500 steps (last t: tensor([3.1589e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 145000 steps (last t: tensor([3.1637e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 145500 steps (last t: tensor([3.1688e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 146000 steps (last t: tensor([3.1734e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 146500 steps (last t: tensor([3.1782e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 147000 steps (last t: tensor([3.1833e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 147500 steps (last t: tensor([3.1879e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 148000 steps (last t: tensor([3.1928e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 148500 steps (last t: tensor([3.1980e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 149000 steps (last t: tensor([3.2027e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 149500 steps (last t: tensor([3.2076e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 150000 steps (last t: tensor([3.2128e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 150500 steps (last t: tensor([3.2175e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 151000 steps (last t: tensor([3.2225e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 151500 steps (last t: tensor([3.2277e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 152000 steps (last t: tensor([3.2324e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 152500 steps (last t: tensor([3.2374e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 153000 steps (last t: tensor([3.2426e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 153500 steps (last t: tensor([3.2474e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 154000 steps (last t: tensor([3.2523e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 154500 steps (last t: tensor([3.2576e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 155000 steps (last t: tensor([3.2624e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 155500 steps (last t: tensor([3.2674e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 156000 steps (last t: tensor([3.2727e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 156500 steps (last t: tensor([3.2775e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 157000 steps (last t: tensor([3.2825e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 157500 steps (last t: tensor([3.2878e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 158000 steps (last t: tensor([3.2926e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 158500 steps (last t: tensor([3.2976e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 159000 steps (last t: tensor([3.3030e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 159500 steps (last t: tensor([3.3078e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 160000 steps (last t: tensor([3.3128e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 160500 steps (last t: tensor([3.3182e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 161000 steps (last t: tensor([3.3231e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 161500 steps (last t: tensor([3.3281e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 162000 steps (last t: tensor([3.3335e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 162500 steps (last t: tensor([3.3384e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 163000 steps (last t: tensor([3.3435e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 163500 steps (last t: tensor([3.3489e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 164000 steps (last t: tensor([3.3538e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 164500 steps (last t: tensor([3.3589e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 165000 steps (last t: tensor([3.3636e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 165500 steps (last t: tensor([3.3678e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 166000 steps (last t: tensor([3.3721e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 166500 steps (last t: tensor([3.3768e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 167000 steps (last t: tensor([3.3809e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 167500 steps (last t: tensor([3.3853e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 168000 steps (last t: tensor([3.3900e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 168500 steps (last t: tensor([3.3942e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 169000 steps (last t: tensor([3.3985e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 169500 steps (last t: tensor([3.4032e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 170000 steps (last t: tensor([3.4074e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 170500 steps (last t: tensor([3.4118e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 171000 steps (last t: tensor([3.4165e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 171500 steps (last t: tensor([3.4208e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 172000 steps (last t: tensor([3.4252e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 172500 steps (last t: tensor([3.4300e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 173000 steps (last t: tensor([3.4343e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 173500 steps (last t: tensor([3.4387e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 174000 steps (last t: tensor([3.4435e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 174500 steps (last t: tensor([3.4478e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 175000 steps (last t: tensor([3.4523e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 175500 steps (last t: tensor([3.4571e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 176000 steps (last t: tensor([3.4614e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 176500 steps (last t: tensor([3.4659e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 177000 steps (last t: tensor([3.4708e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 177500 steps (last t: tensor([3.4751e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 178000 steps (last t: tensor([3.4796e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 178500 steps (last t: tensor([3.4843e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 179000 steps (last t: tensor([3.4885e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 179500 steps (last t: tensor([3.4929e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 180000 steps (last t: tensor([3.4976e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 180500 steps (last t: tensor([3.5019e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 181000 steps (last t: tensor([3.5063e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 181500 steps (last t: tensor([3.5110e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 182000 steps (last t: tensor([3.5153e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 182500 steps (last t: tensor([3.5197e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 183000 steps (last t: tensor([3.5244e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 183500 steps (last t: tensor([3.5287e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 184000 steps (last t: tensor([3.5331e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 184500 steps (last t: tensor([3.5379e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 185000 steps (last t: tensor([3.5421e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 185500 steps (last t: tensor([3.5466e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 186000 steps (last t: tensor([3.5514e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 186500 steps (last t: tensor([3.5556e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 187000 steps (last t: tensor([3.5601e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 187500 steps (last t: tensor([3.5649e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 188000 steps (last t: tensor([3.5692e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 188500 steps (last t: tensor([3.5737e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 189000 steps (last t: tensor([3.5785e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 189500 steps (last t: tensor([3.5827e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 190000 steps (last t: tensor([3.5872e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 190500 steps (last t: tensor([3.5919e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 191000 steps (last t: tensor([3.5961e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 191500 steps (last t: tensor([3.6006e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 192000 steps (last t: tensor([3.6053e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 192500 steps (last t: tensor([3.6097e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 193000 steps (last t: tensor([3.6142e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 193500 steps (last t: tensor([3.6190e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 194000 steps (last t: tensor([3.6233e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 194500 steps (last t: tensor([3.6278e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 195000 steps (last t: tensor([3.6324e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 195500 steps (last t: tensor([3.6365e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 196000 steps (last t: tensor([3.6407e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 196500 steps (last t: tensor([3.6453e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 197000 steps (last t: tensor([3.6495e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 197500 steps (last t: tensor([3.6538e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 198000 steps (last t: tensor([3.6585e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 198500 steps (last t: tensor([3.6626e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 199000 steps (last t: tensor([3.6669e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 199500 steps (last t: tensor([3.6714e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 200000 steps (last t: tensor([3.6755e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 200500 steps (last t: tensor([3.6798e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 201000 steps (last t: tensor([3.6843e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 201500 steps (last t: tensor([3.6884e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 202000 steps (last t: tensor([3.6926e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 202500 steps (last t: tensor([3.6972e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 203000 steps (last t: tensor([3.7012e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 203500 steps (last t: tensor([3.7054e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 204000 steps (last t: tensor([3.7099e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 204500 steps (last t: tensor([3.7139e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 205000 steps (last t: tensor([3.7181e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 205500 steps (last t: tensor([3.7226e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 206000 steps (last t: tensor([3.7266e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 206500 steps (last t: tensor([3.7308e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 207000 steps (last t: tensor([3.7353e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 207500 steps (last t: tensor([3.7393e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 208000 steps (last t: tensor([3.7435e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 208500 steps (last t: tensor([3.7480e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 209000 steps (last t: tensor([3.7521e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 209500 steps (last t: tensor([3.7563e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 210000 steps (last t: tensor([3.7608e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 210500 steps (last t: tensor([3.7649e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 211000 steps (last t: tensor([3.7691e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 211500 steps (last t: tensor([3.7736e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 212000 steps (last t: tensor([3.7777e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 212500 steps (last t: tensor([3.7819e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 213000 steps (last t: tensor([3.7865e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 213500 steps (last t: tensor([3.7906e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 214000 steps (last t: tensor([3.7948e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 214500 steps (last t: tensor([3.7994e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 215000 steps (last t: tensor([3.8035e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 215500 steps (last t: tensor([3.8077e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 216000 steps (last t: tensor([3.8123e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 216500 steps (last t: tensor([3.8164e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 217000 steps (last t: tensor([3.8207e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 217500 steps (last t: tensor([3.8253e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 218000 steps (last t: tensor([3.8294e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 218500 steps (last t: tensor([3.8337e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 219000 steps (last t: tensor([3.8383e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 219500 steps (last t: tensor([3.8424e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 220000 steps (last t: tensor([3.8467e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 220500 steps (last t: tensor([3.8514e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 221000 steps (last t: tensor([3.8555e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 221500 steps (last t: tensor([3.8598e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 222000 steps (last t: tensor([3.8645e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 222500 steps (last t: tensor([3.8688e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 223000 steps (last t: tensor([3.8729e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 223500 steps (last t: tensor([3.8771e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 224000 steps (last t: tensor([3.8813e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 224500 steps (last t: tensor([3.8855e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 225000 steps (last t: tensor([3.8897e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 225500 steps (last t: tensor([3.8945e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 226000 steps (last t: tensor([3.8995e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 226500 steps (last t: tensor([3.9044e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 227000 steps (last t: tensor([3.9094e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 227500 steps (last t: tensor([3.9140e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 228000 steps (last t: tensor([3.9188e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 228500 steps (last t: tensor([3.9232e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 229000 steps (last t: tensor([3.9280e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 229500 steps (last t: tensor([3.9326e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 230000 steps (last t: tensor([3.9375e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 230500 steps (last t: tensor([3.9419e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 231000 steps (last t: tensor([3.9470e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 231500 steps (last t: tensor([3.9518e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 232000 steps (last t: tensor([3.9564e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 232500 steps (last t: tensor([3.9615e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 233000 steps (last t: tensor([3.9663e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 233500 steps (last t: tensor([3.9713e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 234000 steps (last t: tensor([3.9769e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 234500 steps (last t: tensor([3.9823e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 235000 steps (last t: tensor([3.9879e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 235500 steps (last t: tensor([3.9940e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 236000 steps (last t: tensor([3.9994e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 236500 steps (last t: tensor([4.0051e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 237000 steps (last t: tensor([4.0112e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 237500 steps (last t: tensor([4.0167e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 238000 steps (last t: tensor([4.0224e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 238500 steps (last t: tensor([4.0284e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 239000 steps (last t: tensor([4.0339e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 239500 steps (last t: tensor([4.0397e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 240000 steps (last t: tensor([4.0458e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 240500 steps (last t: tensor([4.0513e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 241000 steps (last t: tensor([4.0570e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 241500 steps (last t: tensor([4.0632e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 242000 steps (last t: tensor([4.0687e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 242500 steps (last t: tensor([4.0745e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 243000 steps (last t: tensor([4.0807e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 243500 steps (last t: tensor([4.0858e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 244000 steps (last t: tensor([4.0902e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 244500 steps (last t: tensor([4.0951e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 245000 steps (last t: tensor([4.0994e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 245500 steps (last t: tensor([4.1034e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 246000 steps (last t: tensor([4.1078e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 246500 steps (last t: tensor([4.1121e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 247000 steps (last t: tensor([4.1160e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 247500 steps (last t: tensor([4.1202e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 248000 steps (last t: tensor([4.1247e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 248500 steps (last t: tensor([4.1284e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 249000 steps (last t: tensor([4.1329e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 249500 steps (last t: tensor([4.1370e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 250000 steps (last t: tensor([4.1409e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 250500 steps (last t: tensor([4.1454e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 251000 steps (last t: tensor([4.1491e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 251500 steps (last t: tensor([4.1532e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 252000 steps (last t: tensor([4.1573e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 252500 steps (last t: tensor([4.1613e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 253000 steps (last t: tensor([4.1654e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 253500 steps (last t: tensor([4.1694e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 254000 steps (last t: tensor([4.1734e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 254500 steps (last t: tensor([4.1776e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 255000 steps (last t: tensor([4.1816e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 255500 steps (last t: tensor([4.1856e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 256000 steps (last t: tensor([4.1898e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 256500 steps (last t: tensor([4.1938e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 257000 steps (last t: tensor([4.1996e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 257500 steps (last t: tensor([4.2049e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 258000 steps (last t: tensor([4.2103e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 258500 steps (last t: tensor([4.2160e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 259000 steps (last t: tensor([4.2214e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 259500 steps (last t: tensor([4.2264e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 260000 steps (last t: tensor([4.2304e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 260500 steps (last t: tensor([4.2344e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 261000 steps (last t: tensor([4.2387e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 261500 steps (last t: tensor([4.2427e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 262000 steps (last t: tensor([4.2466e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 262500 steps (last t: tensor([4.2509e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 263000 steps (last t: tensor([4.2546e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 263500 steps (last t: tensor([4.2586e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 264000 steps (last t: tensor([4.2627e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 264500 steps (last t: tensor([4.2667e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 265000 steps (last t: tensor([4.2705e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 265500 steps (last t: tensor([4.2746e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 266000 steps (last t: tensor([4.2784e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 266500 steps (last t: tensor([4.2824e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 267000 steps (last t: tensor([4.2869e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 267500 steps (last t: tensor([4.2911e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 268000 steps (last t: tensor([4.2946e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 268500 steps (last t: tensor([4.2982e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 269000 steps (last t: tensor([4.3019e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 269500 steps (last t: tensor([4.3054e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 270000 steps (last t: tensor([4.3089e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 270500 steps (last t: tensor([4.3127e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 271000 steps (last t: tensor([4.3162e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 271500 steps (last t: tensor([4.3198e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 272000 steps (last t: tensor([4.3236e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 272500 steps (last t: tensor([4.3270e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 273000 steps (last t: tensor([4.3306e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 273500 steps (last t: tensor([4.3344e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 274000 steps (last t: tensor([4.3379e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 274500 steps (last t: tensor([4.3415e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 275000 steps (last t: tensor([4.3453e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 275500 steps (last t: tensor([4.3488e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 276000 steps (last t: tensor([4.3523e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 276500 steps (last t: tensor([4.3562e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 277000 steps (last t: tensor([4.3597e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 277500 steps (last t: tensor([4.3633e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 278000 steps (last t: tensor([4.3671e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 278500 steps (last t: tensor([4.3706e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 279000 steps (last t: tensor([4.3742e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 279500 steps (last t: tensor([4.3780e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 280000 steps (last t: tensor([4.3816e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 280500 steps (last t: tensor([4.3852e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 281000 steps (last t: tensor([4.3890e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 281500 steps (last t: tensor([4.3925e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 282000 steps (last t: tensor([4.3962e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 282500 steps (last t: tensor([4.4000e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 283000 steps (last t: tensor([4.4035e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 283500 steps (last t: tensor([4.4072e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 284000 steps (last t: tensor([4.4110e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 284500 steps (last t: tensor([4.4146e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 285000 steps (last t: tensor([4.4182e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 285500 steps (last t: tensor([4.4221e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 286000 steps (last t: tensor([4.4256e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 286500 steps (last t: tensor([4.4293e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 287000 steps (last t: tensor([4.4331e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 287500 steps (last t: tensor([4.4367e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 288000 steps (last t: tensor([4.4404e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 288500 steps (last t: tensor([4.4442e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 289000 steps (last t: tensor([4.4478e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 289500 steps (last t: tensor([4.4515e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 290000 steps (last t: tensor([4.4554e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 290500 steps (last t: tensor([4.4589e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 291000 steps (last t: tensor([4.4626e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 291500 steps (last t: tensor([4.4665e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 292000 steps (last t: tensor([4.4701e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 292500 steps (last t: tensor([4.4738e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 293000 steps (last t: tensor([4.4777e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 293500 steps (last t: tensor([4.4813e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 294000 steps (last t: tensor([4.4850e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 294500 steps (last t: tensor([4.4889e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 295000 steps (last t: tensor([4.4936e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 295500 steps (last t: tensor([4.4984e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 296000 steps (last t: tensor([4.5035e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 296500 steps (last t: tensor([4.5082e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 297000 steps (last t: tensor([4.5131e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 297500 steps (last t: tensor([4.5182e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 298000 steps (last t: tensor([4.5229e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 298500 steps (last t: tensor([4.5278e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 299000 steps (last t: tensor([4.5329e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 299500 steps (last t: tensor([4.5377e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 300000 steps (last t: tensor([4.5425e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 300500 steps (last t: tensor([4.5477e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 301000 steps (last t: tensor([4.5524e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 301500 steps (last t: tensor([4.5573e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 302000 steps (last t: tensor([4.5625e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 302500 steps (last t: tensor([4.5673e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 303000 steps (last t: tensor([4.5718e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 303500 steps (last t: tensor([4.5764e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 304000 steps (last t: tensor([4.5805e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 304500 steps (last t: tensor([4.5848e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 305000 steps (last t: tensor([4.5890e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 305500 steps (last t: tensor([4.5929e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 306000 steps (last t: tensor([4.5972e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 306500 steps (last t: tensor([4.6014e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 307000 steps (last t: tensor([4.6052e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 307500 steps (last t: tensor([4.6093e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 308000 steps (last t: tensor([4.6130e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 308500 steps (last t: tensor([4.6171e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 309000 steps (last t: tensor([4.6212e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 309500 steps (last t: tensor([4.6253e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 310000 steps (last t: tensor([4.6290e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 310500 steps (last t: tensor([4.6333e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 311000 steps (last t: tensor([4.6369e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 311500 steps (last t: tensor([4.6409e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 312000 steps (last t: tensor([4.6450e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 312500 steps (last t: tensor([4.6488e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 313000 steps (last t: tensor([4.6527e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 313500 steps (last t: tensor([4.6567e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 314000 steps (last t: tensor([4.6602e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 314500 steps (last t: tensor([4.6640e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 315000 steps (last t: tensor([4.6681e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 315500 steps (last t: tensor([4.6719e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 316000 steps (last t: tensor([4.6754e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 316500 steps (last t: tensor([4.6794e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 317000 steps (last t: tensor([4.6833e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 317500 steps (last t: tensor([4.6869e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 318000 steps (last t: tensor([4.6909e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 318500 steps (last t: tensor([4.6947e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 319000 steps (last t: tensor([4.6983e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 319500 steps (last t: tensor([4.7022e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 320000 steps (last t: tensor([4.7062e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 320500 steps (last t: tensor([4.7103e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 321000 steps (last t: tensor([4.7144e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 321500 steps (last t: tensor([4.7188e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 322000 steps (last t: tensor([4.7225e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 322500 steps (last t: tensor([4.7270e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 323000 steps (last t: tensor([4.7307e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 323500 steps (last t: tensor([4.7348e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 324000 steps (last t: tensor([4.7386e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 324500 steps (last t: tensor([4.7426e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 325000 steps (last t: tensor([4.7464e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 325500 steps (last t: tensor([4.7507e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 326000 steps (last t: tensor([4.7551e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 326500 steps (last t: tensor([4.7597e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 327000 steps (last t: tensor([4.7643e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 327500 steps (last t: tensor([4.7692e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 328000 steps (last t: tensor([4.7738e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 328500 steps (last t: tensor([4.7785e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 329000 steps (last t: tensor([4.7828e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 329500 steps (last t: tensor([4.7869e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 330000 steps (last t: tensor([4.7910e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 330500 steps (last t: tensor([4.7950e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 331000 steps (last t: tensor([4.7988e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 331500 steps (last t: tensor([4.8030e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 332000 steps (last t: tensor([4.8070e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 332500 steps (last t: tensor([4.8108e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 333000 steps (last t: tensor([4.8149e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 333500 steps (last t: tensor([4.8190e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 334000 steps (last t: tensor([4.8228e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 334500 steps (last t: tensor([4.8269e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 335000 steps (last t: tensor([4.8310e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 335500 steps (last t: tensor([4.8347e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 336000 steps (last t: tensor([4.8387e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 336500 steps (last t: tensor([4.8424e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 337000 steps (last t: tensor([4.8458e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 337500 steps (last t: tensor([4.8499e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 338000 steps (last t: tensor([4.8537e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 338500 steps (last t: tensor([4.8572e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 339000 steps (last t: tensor([4.8613e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 339500 steps (last t: tensor([4.8650e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 340000 steps (last t: tensor([4.8687e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 340500 steps (last t: tensor([4.8726e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 341000 steps (last t: tensor([4.8765e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 341500 steps (last t: tensor([4.8800e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 342000 steps (last t: tensor([4.8835e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 342500 steps (last t: tensor([4.8869e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 343000 steps (last t: tensor([4.8905e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 343500 steps (last t: tensor([4.8940e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 344000 steps (last t: tensor([4.8974e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 344500 steps (last t: tensor([4.9009e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 345000 steps (last t: tensor([4.9045e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 345500 steps (last t: tensor([4.9079e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 346000 steps (last t: tensor([4.9114e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 346500 steps (last t: tensor([4.9153e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 347000 steps (last t: tensor([4.9192e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 347500 steps (last t: tensor([4.9224e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 348000 steps (last t: tensor([4.9258e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 348500 steps (last t: tensor([4.9292e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 349000 steps (last t: tensor([4.9327e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 349500 steps (last t: tensor([4.9361e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 350000 steps (last t: tensor([4.9395e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 350500 steps (last t: tensor([4.9429e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 351000 steps (last t: tensor([4.9465e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 351500 steps (last t: tensor([4.9497e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 352000 steps (last t: tensor([4.9531e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 352500 steps (last t: tensor([4.9569e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 353000 steps (last t: tensor([4.9602e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 353500 steps (last t: tensor([4.9634e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 354000 steps (last t: tensor([4.9669e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 354500 steps (last t: tensor([4.9700e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 355000 steps (last t: tensor([4.9732e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 355500 steps (last t: tensor([4.9768e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 356000 steps (last t: tensor([4.9802e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 356500 steps (last t: tensor([4.9834e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 357000 steps (last t: tensor([4.9866e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 357500 steps (last t: tensor([4.9901e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 358000 steps (last t: tensor([4.9933e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 358500 steps (last t: tensor([4.9969e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 359000 steps (last t: tensor([4.9999e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 359500 steps (last t: tensor([5.0032e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 360000 steps (last t: tensor([5.0067e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 360500 steps (last t: tensor([5.0102e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 361000 steps (last t: tensor([5.0134e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 361500 steps (last t: tensor([5.0166e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 362000 steps (last t: tensor([5.0201e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 362500 steps (last t: tensor([5.0233e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 363000 steps (last t: tensor([5.0269e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 363500 steps (last t: tensor([5.0300e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 364000 steps (last t: tensor([5.0333e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 364500 steps (last t: tensor([5.0369e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 365000 steps (last t: tensor([5.0404e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 365500 steps (last t: tensor([5.0435e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 366000 steps (last t: tensor([5.0468e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 366500 steps (last t: tensor([5.0503e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 367000 steps (last t: tensor([5.0536e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 367500 steps (last t: tensor([5.0572e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 368000 steps (last t: tensor([5.0603e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 368500 steps (last t: tensor([5.0636e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 369000 steps (last t: tensor([5.0672e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 369500 steps (last t: tensor([5.0707e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 370000 steps (last t: tensor([5.0739e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 370500 steps (last t: tensor([5.0772e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 371000 steps (last t: tensor([5.0807e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 371500 steps (last t: tensor([5.0839e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 372000 steps (last t: tensor([5.0876e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 372500 steps (last t: tensor([5.0907e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 373000 steps (last t: tensor([5.0940e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 373500 steps (last t: tensor([5.0976e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 374000 steps (last t: tensor([5.1012e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 374500 steps (last t: tensor([5.1044e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 375000 steps (last t: tensor([5.1077e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 375500 steps (last t: tensor([5.1112e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 376000 steps (last t: tensor([5.1145e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 376500 steps (last t: tensor([5.1182e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 377000 steps (last t: tensor([5.1213e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 377500 steps (last t: tensor([5.1247e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 378000 steps (last t: tensor([5.1283e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 378500 steps (last t: tensor([5.1318e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 379000 steps (last t: tensor([5.1351e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 379500 steps (last t: tensor([5.1384e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 380000 steps (last t: tensor([5.1420e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 380500 steps (last t: tensor([5.1452e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 381000 steps (last t: tensor([5.1489e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 381500 steps (last t: tensor([5.1521e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 382000 steps (last t: tensor([5.1554e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 382500 steps (last t: tensor([5.1591e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 383000 steps (last t: tensor([5.1627e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 383500 steps (last t: tensor([5.1659e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 384000 steps (last t: tensor([5.1693e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 384500 steps (last t: tensor([5.1728e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 385000 steps (last t: tensor([5.1761e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 385500 steps (last t: tensor([5.1799e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 386000 steps (last t: tensor([5.1830e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 386500 steps (last t: tensor([5.1864e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 387000 steps (last t: tensor([5.1901e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 387500 steps (last t: tensor([5.1939e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 388000 steps (last t: tensor([5.1971e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 388500 steps (last t: tensor([5.2010e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 389000 steps (last t: tensor([5.2043e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 389500 steps (last t: tensor([5.2079e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 390000 steps (last t: tensor([5.2117e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 390500 steps (last t: tensor([5.2149e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 391000 steps (last t: tensor([5.2184e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 391500 steps (last t: tensor([5.2222e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 392000 steps (last t: tensor([5.2253e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 392500 steps (last t: tensor([5.2289e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 393000 steps (last t: tensor([5.2326e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 393500 steps (last t: tensor([5.2358e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 394000 steps (last t: tensor([5.2391e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 394500 steps (last t: tensor([5.2428e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 395000 steps (last t: tensor([5.2464e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 395500 steps (last t: tensor([5.2496e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 396000 steps (last t: tensor([5.2527e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 396500 steps (last t: tensor([5.2560e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 397000 steps (last t: tensor([5.2590e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 397500 steps (last t: tensor([5.2625e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 398000 steps (last t: tensor([5.2654e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 398500 steps (last t: tensor([5.2686e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 399000 steps (last t: tensor([5.2721e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 399500 steps (last t: tensor([5.2756e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 400000 steps (last t: tensor([5.2792e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 400500 steps (last t: tensor([5.2829e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 401000 steps (last t: tensor([5.2864e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 401500 steps (last t: tensor([5.2900e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 402000 steps (last t: tensor([5.2938e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 402500 steps (last t: tensor([5.2971e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 403000 steps (last t: tensor([5.3006e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 403500 steps (last t: tensor([5.3043e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 404000 steps (last t: tensor([5.3077e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 404500 steps (last t: tensor([5.3112e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 405000 steps (last t: tensor([5.3145e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 405500 steps (last t: tensor([5.3180e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 406000 steps (last t: tensor([5.3212e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 406500 steps (last t: tensor([5.3245e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 407000 steps (last t: tensor([5.3274e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 407500 steps (last t: tensor([5.3302e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 408000 steps (last t: tensor([5.3334e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 408500 steps (last t: tensor([5.3362e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 409000 steps (last t: tensor([5.3392e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 409500 steps (last t: tensor([5.3425e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 410000 steps (last t: tensor([5.3455e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 410500 steps (last t: tensor([5.3483e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 411000 steps (last t: tensor([5.3515e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 411500 steps (last t: tensor([5.3544e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 412000 steps (last t: tensor([5.3574e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 412500 steps (last t: tensor([5.3604e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 413000 steps (last t: tensor([5.3635e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 413500 steps (last t: tensor([5.3664e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 414000 steps (last t: tensor([5.3698e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 414500 steps (last t: tensor([5.3726e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 415000 steps (last t: tensor([5.3757e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 415500 steps (last t: tensor([5.3790e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 416000 steps (last t: tensor([5.3817e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 416500 steps (last t: tensor([5.3848e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 417000 steps (last t: tensor([5.3880e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 417500 steps (last t: tensor([5.3918e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 418000 steps (last t: tensor([5.3950e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 418500 steps (last t: tensor([5.3985e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 419000 steps (last t: tensor([5.4022e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 419500 steps (last t: tensor([5.4054e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 420000 steps (last t: tensor([5.4089e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 420500 steps (last t: tensor([5.4127e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 421000 steps (last t: tensor([5.4159e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 421500 steps (last t: tensor([5.4192e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 422000 steps (last t: tensor([5.4224e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 422500 steps (last t: tensor([5.4252e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 423000 steps (last t: tensor([5.4278e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 423500 steps (last t: tensor([5.4308e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 424000 steps (last t: tensor([5.4333e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 424500 steps (last t: tensor([5.4365e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 425000 steps (last t: tensor([5.4391e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 425500 steps (last t: tensor([5.4420e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 426000 steps (last t: tensor([5.4453e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 426500 steps (last t: tensor([5.4485e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 427000 steps (last t: tensor([5.4517e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 427500 steps (last t: tensor([5.4550e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 428000 steps (last t: tensor([5.4581e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 428500 steps (last t: tensor([5.4614e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 429000 steps (last t: tensor([5.4647e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 429500 steps (last t: tensor([5.4679e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 430000 steps (last t: tensor([5.4709e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 430500 steps (last t: tensor([5.4745e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 431000 steps (last t: tensor([5.4777e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 431500 steps (last t: tensor([5.4806e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 432000 steps (last t: tensor([5.4839e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 432500 steps (last t: tensor([5.4871e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 433000 steps (last t: tensor([5.4903e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 433500 steps (last t: tensor([5.4937e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 434000 steps (last t: tensor([5.4968e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 434500 steps (last t: tensor([5.5001e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 435000 steps (last t: tensor([5.5035e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 435500 steps (last t: tensor([5.5066e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 436000 steps (last t: tensor([5.5097e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 436500 steps (last t: tensor([5.5132e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 437000 steps (last t: tensor([5.5165e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 437500 steps (last t: tensor([5.5194e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 438000 steps (last t: tensor([5.5225e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 438500 steps (last t: tensor([5.5254e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 439000 steps (last t: tensor([5.5284e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 439500 steps (last t: tensor([5.5313e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 440000 steps (last t: tensor([5.5341e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 440500 steps (last t: tensor([5.5371e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 441000 steps (last t: tensor([5.5402e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 441500 steps (last t: tensor([5.5429e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 442000 steps (last t: tensor([5.5454e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 442500 steps (last t: tensor([5.5483e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 443000 steps (last t: tensor([5.5505e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 443500 steps (last t: tensor([5.5531e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 444000 steps (last t: tensor([5.5558e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 444500 steps (last t: tensor([5.5583e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 445000 steps (last t: tensor([5.5609e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 445500 steps (last t: tensor([5.5635e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 446000 steps (last t: tensor([5.5660e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 446500 steps (last t: tensor([5.5685e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 447000 steps (last t: tensor([5.5714e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 447500 steps (last t: tensor([5.5739e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 448000 steps (last t: tensor([5.5763e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 448500 steps (last t: tensor([5.5792e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 449000 steps (last t: tensor([5.5815e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 449500 steps (last t: tensor([5.5841e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 450000 steps (last t: tensor([5.5867e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 450500 steps (last t: tensor([5.5892e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 451000 steps (last t: tensor([5.5919e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 451500 steps (last t: tensor([5.5945e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 452000 steps (last t: tensor([5.5971e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 452500 steps (last t: tensor([5.5996e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 453000 steps (last t: tensor([5.6023e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 453500 steps (last t: tensor([5.6047e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 454000 steps (last t: tensor([5.6071e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 454500 steps (last t: tensor([5.6097e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 455000 steps (last t: tensor([5.6120e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 455500 steps (last t: tensor([5.6144e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 456000 steps (last t: tensor([5.6169e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 456500 steps (last t: tensor([5.6195e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 457000 steps (last t: tensor([5.6220e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 457500 steps (last t: tensor([5.6247e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 458000 steps (last t: tensor([5.6272e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 458500 steps (last t: tensor([5.6298e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 459000 steps (last t: tensor([5.6326e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 459500 steps (last t: tensor([5.6348e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 460000 steps (last t: tensor([5.6373e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 460500 steps (last t: tensor([5.6398e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 461000 steps (last t: tensor([5.6423e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 461500 steps (last t: tensor([5.6446e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 462000 steps (last t: tensor([5.6473e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 462500 steps (last t: tensor([5.6498e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 463000 steps (last t: tensor([5.6522e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 463500 steps (last t: tensor([5.6549e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 464000 steps (last t: tensor([5.6578e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 464500 steps (last t: tensor([5.6604e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 465000 steps (last t: tensor([5.6633e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 465500 steps (last t: tensor([5.6659e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 466000 steps (last t: tensor([5.6686e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 466500 steps (last t: tensor([5.6715e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 467000 steps (last t: tensor([5.6744e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 467500 steps (last t: tensor([5.6770e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 468000 steps (last t: tensor([5.6796e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 468500 steps (last t: tensor([5.6825e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 469000 steps (last t: tensor([5.6852e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 469500 steps (last t: tensor([5.6881e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 470000 steps (last t: tensor([5.6907e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 470500 steps (last t: tensor([5.6934e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 471000 steps (last t: tensor([5.6961e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 471500 steps (last t: tensor([5.6982e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 472000 steps (last t: tensor([5.7001e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 472500 steps (last t: tensor([5.7025e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 473000 steps (last t: tensor([5.7046e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 473500 steps (last t: tensor([5.7066e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 474000 steps (last t: tensor([5.7090e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 474500 steps (last t: tensor([5.7111e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 475000 steps (last t: tensor([5.7131e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 475500 steps (last t: tensor([5.7155e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 476000 steps (last t: tensor([5.7176e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 476500 steps (last t: tensor([5.7196e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 477000 steps (last t: tensor([5.7220e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 477500 steps (last t: tensor([5.7241e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 478000 steps (last t: tensor([5.7261e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 478500 steps (last t: tensor([5.7285e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 479000 steps (last t: tensor([5.7307e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 479500 steps (last t: tensor([5.7326e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 480000 steps (last t: tensor([5.7351e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 480500 steps (last t: tensor([5.7372e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 481000 steps (last t: tensor([5.7392e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 481500 steps (last t: tensor([5.7416e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 482000 steps (last t: tensor([5.7437e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 482500 steps (last t: tensor([5.7457e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 483000 steps (last t: tensor([5.7481e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 483500 steps (last t: tensor([5.7502e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 484000 steps (last t: tensor([5.7522e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 484500 steps (last t: tensor([5.7547e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 485000 steps (last t: tensor([5.7568e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 485500 steps (last t: tensor([5.7588e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 486000 steps (last t: tensor([5.7612e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 486500 steps (last t: tensor([5.7633e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 487000 steps (last t: tensor([5.7653e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 487500 steps (last t: tensor([5.7678e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 488000 steps (last t: tensor([5.7699e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 488500 steps (last t: tensor([5.7719e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 489000 steps (last t: tensor([5.7743e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 489500 steps (last t: tensor([5.7764e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 490000 steps (last t: tensor([5.7785e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 490500 steps (last t: tensor([5.7809e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 491000 steps (last t: tensor([5.7830e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 491500 steps (last t: tensor([5.7850e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 492000 steps (last t: tensor([5.7875e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 492500 steps (last t: tensor([5.7896e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 493000 steps (last t: tensor([5.7916e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 493500 steps (last t: tensor([5.7940e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 494000 steps (last t: tensor([5.7962e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 494500 steps (last t: tensor([5.7982e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 495000 steps (last t: tensor([5.8006e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 495500 steps (last t: tensor([5.8028e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 496000 steps (last t: tensor([5.8048e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 496500 steps (last t: tensor([5.8072e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 497000 steps (last t: tensor([5.8094e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 497500 steps (last t: tensor([5.8114e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 498000 steps (last t: tensor([5.8138e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 498500 steps (last t: tensor([5.8160e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 499000 steps (last t: tensor([5.8180e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 499500 steps (last t: tensor([5.8204e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 500000 steps (last t: tensor([5.8225e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 500500 steps (last t: tensor([5.8246e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 501000 steps (last t: tensor([5.8269e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 501500 steps (last t: tensor([5.8290e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 502000 steps (last t: tensor([5.8309e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 502500 steps (last t: tensor([5.8333e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 503000 steps (last t: tensor([5.8355e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 503500 steps (last t: tensor([5.8374e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 504000 steps (last t: tensor([5.8395e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 504500 steps (last t: tensor([5.8418e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 505000 steps (last t: tensor([5.8437e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 505500 steps (last t: tensor([5.8459e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 506000 steps (last t: tensor([5.8482e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 506500 steps (last t: tensor([5.8501e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 507000 steps (last t: tensor([5.8522e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 507500 steps (last t: tensor([5.8545e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 508000 steps (last t: tensor([5.8564e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 508500 steps (last t: tensor([5.8586e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 509000 steps (last t: tensor([5.8606e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 509500 steps (last t: tensor([5.8628e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 510000 steps (last t: tensor([5.8649e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 510500 steps (last t: tensor([5.8670e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 511000 steps (last t: tensor([5.8691e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 511500 steps (last t: tensor([5.8713e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 512000 steps (last t: tensor([5.8734e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 512500 steps (last t: tensor([5.8755e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 513000 steps (last t: tensor([5.8778e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 513500 steps (last t: tensor([5.8800e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 514000 steps (last t: tensor([5.8822e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 514500 steps (last t: tensor([5.8845e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 515000 steps (last t: tensor([5.8867e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 515500 steps (last t: tensor([5.8888e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 516000 steps (last t: tensor([5.8911e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 516500 steps (last t: tensor([5.8931e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 517000 steps (last t: tensor([5.8952e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 517500 steps (last t: tensor([5.8975e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 518000 steps (last t: tensor([5.8995e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 518500 steps (last t: tensor([5.9015e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 519000 steps (last t: tensor([5.9036e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 519500 steps (last t: tensor([5.9060e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 520000 steps (last t: tensor([5.9079e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 520500 steps (last t: tensor([5.9100e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 521000 steps (last t: tensor([5.9122e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 521500 steps (last t: tensor([5.9145e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 522000 steps (last t: tensor([5.9168e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 522500 steps (last t: tensor([5.9191e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 523000 steps (last t: tensor([5.9213e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 523500 steps (last t: tensor([5.9237e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 524000 steps (last t: tensor([5.9259e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 524500 steps (last t: tensor([5.9282e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 525000 steps (last t: tensor([5.9306e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 525500 steps (last t: tensor([5.9327e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 526000 steps (last t: tensor([5.9349e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 526500 steps (last t: tensor([5.9374e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 527000 steps (last t: tensor([5.9396e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 527500 steps (last t: tensor([5.9417e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 528000 steps (last t: tensor([5.9441e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 528500 steps (last t: tensor([5.9464e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 529000 steps (last t: tensor([5.9485e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 529500 steps (last t: tensor([5.9506e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 530000 steps (last t: tensor([5.9530e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 530500 steps (last t: tensor([5.9551e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 531000 steps (last t: tensor([5.9573e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 531500 steps (last t: tensor([5.9595e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 532000 steps (last t: tensor([5.9617e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 532500 steps (last t: tensor([5.9641e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 533000 steps (last t: tensor([5.9664e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 533500 steps (last t: tensor([5.9685e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 534000 steps (last t: tensor([5.9706e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 534500 steps (last t: tensor([5.9730e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 535000 steps (last t: tensor([5.9751e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 535500 steps (last t: tensor([5.9772e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 536000 steps (last t: tensor([5.9795e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 536500 steps (last t: tensor([5.9817e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 537000 steps (last t: tensor([5.9841e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 537500 steps (last t: tensor([5.9861e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 538000 steps (last t: tensor([5.9883e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 538500 steps (last t: tensor([5.9907e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 539000 steps (last t: tensor([5.9930e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 539500 steps (last t: tensor([5.9949e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 540000 steps (last t: tensor([5.9973e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 540500 steps (last t: tensor([5.9995e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 541000 steps (last t: tensor([6.0016e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 541500 steps (last t: tensor([6.0037e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 542000 steps (last t: tensor([6.0060e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 542500 steps (last t: tensor([6.0083e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 543000 steps (last t: tensor([6.0104e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 543500 steps (last t: tensor([6.0127e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 544000 steps (last t: tensor([6.0150e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 544500 steps (last t: tensor([6.0173e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 545000 steps (last t: tensor([6.0199e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 545500 steps (last t: tensor([6.0220e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 546000 steps (last t: tensor([6.0243e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 546500 steps (last t: tensor([6.0267e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 547000 steps (last t: tensor([6.0290e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 547500 steps (last t: tensor([6.0315e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 548000 steps (last t: tensor([6.0338e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 548500 steps (last t: tensor([6.0361e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 549000 steps (last t: tensor([6.0384e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 549500 steps (last t: tensor([6.0409e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 550000 steps (last t: tensor([6.0431e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 550500 steps (last t: tensor([6.0454e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 551000 steps (last t: tensor([6.0480e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 551500 steps (last t: tensor([6.0501e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 552000 steps (last t: tensor([6.0525e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 552500 steps (last t: tensor([6.0549e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 553000 steps (last t: tensor([6.0572e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 553500 steps (last t: tensor([6.0597e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 554000 steps (last t: tensor([6.0620e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 554500 steps (last t: tensor([6.0644e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 555000 steps (last t: tensor([6.0666e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 555500 steps (last t: tensor([6.0692e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 556000 steps (last t: tensor([6.0713e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 556500 steps (last t: tensor([6.0737e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 557000 steps (last t: tensor([6.0763e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 557500 steps (last t: tensor([6.0784e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 558000 steps (last t: tensor([6.0810e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 558500 steps (last t: tensor([6.0834e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 559000 steps (last t: tensor([6.0856e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 559500 steps (last t: tensor([6.0879e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 560000 steps (last t: tensor([6.0904e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 560500 steps (last t: tensor([6.0926e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 561000 steps (last t: tensor([6.0949e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 561500 steps (last t: tensor([6.0973e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 562000 steps (last t: tensor([6.0996e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 562500 steps (last t: tensor([6.1022e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 563000 steps (last t: tensor([6.1046e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 563500 steps (last t: tensor([6.1068e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 564000 steps (last t: tensor([6.1091e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 564500 steps (last t: tensor([6.1117e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 565000 steps (last t: tensor([6.1139e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 565500 steps (last t: tensor([6.1162e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 566000 steps (last t: tensor([6.1186e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 566500 steps (last t: tensor([6.1209e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 567000 steps (last t: tensor([6.1235e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 567500 steps (last t: tensor([6.1260e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 568000 steps (last t: tensor([6.1282e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 568500 steps (last t: tensor([6.1305e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 569000 steps (last t: tensor([6.1330e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 569500 steps (last t: tensor([6.1352e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 570000 steps (last t: tensor([6.1375e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 570500 steps (last t: tensor([6.1400e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 571000 steps (last t: tensor([6.1423e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 571500 steps (last t: tensor([6.1449e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 572000 steps (last t: tensor([6.1470e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 572500 steps (last t: tensor([6.1493e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 573000 steps (last t: tensor([6.1520e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 573500 steps (last t: tensor([6.1543e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 574000 steps (last t: tensor([6.1565e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 574500 steps (last t: tensor([6.1590e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 575000 steps (last t: tensor([6.1613e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 575500 steps (last t: tensor([6.1637e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 576000 steps (last t: tensor([6.1663e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 576500 steps (last t: tensor([6.1685e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 577000 steps (last t: tensor([6.1709e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 577500 steps (last t: tensor([6.1734e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 578000 steps (last t: tensor([6.1759e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 578500 steps (last t: tensor([6.1782e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 579000 steps (last t: tensor([6.1809e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 579500 steps (last t: tensor([6.1830e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 580000 steps (last t: tensor([6.1854e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 580500 steps (last t: tensor([6.1880e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 581000 steps (last t: tensor([6.1903e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 581500 steps (last t: tensor([6.1926e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 582000 steps (last t: tensor([6.1952e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 582500 steps (last t: tensor([6.1977e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 583000 steps (last t: tensor([6.2000e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 583500 steps (last t: tensor([6.2026e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 584000 steps (last t: tensor([6.2051e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 584500 steps (last t: tensor([6.2074e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 585000 steps (last t: tensor([6.2100e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 585500 steps (last t: tensor([6.2127e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 586000 steps (last t: tensor([6.2150e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 586500 steps (last t: tensor([6.2178e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 587000 steps (last t: tensor([6.2204e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 587500 steps (last t: tensor([6.2226e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 588000 steps (last t: tensor([6.2252e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 588500 steps (last t: tensor([6.2277e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 589000 steps (last t: tensor([6.2302e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 589500 steps (last t: tensor([6.2328e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 590000 steps (last t: tensor([6.2356e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 590500 steps (last t: tensor([6.2379e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 591000 steps (last t: tensor([6.2405e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 591500 steps (last t: tensor([6.2430e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 592000 steps (last t: tensor([6.2455e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 592500 steps (last t: tensor([6.2481e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 593000 steps (last t: tensor([6.2506e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 593500 steps (last t: tensor([6.2532e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 594000 steps (last t: tensor([6.2559e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 594500 steps (last t: tensor([6.2585e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 595000 steps (last t: tensor([6.2609e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 595500 steps (last t: tensor([6.2635e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 596000 steps (last t: tensor([6.2664e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 596500 steps (last t: tensor([6.2687e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 597000 steps (last t: tensor([6.2714e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 597500 steps (last t: tensor([6.2739e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 598000 steps (last t: tensor([6.2766e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 598500 steps (last t: tensor([6.2792e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 599000 steps (last t: tensor([6.2818e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 599500 steps (last t: tensor([6.2843e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 600000 steps (last t: tensor([6.2872e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 600500 steps (last t: tensor([6.2896e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 601000 steps (last t: tensor([6.2923e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 601500 steps (last t: tensor([6.2949e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 602000 steps (last t: tensor([6.2976e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 602500 steps (last t: tensor([6.3003e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 603000 steps (last t: tensor([6.3031e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 603500 steps (last t: tensor([6.3057e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 604000 steps (last t: tensor([6.3085e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 604500 steps (last t: tensor([6.3112e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 605000 steps (last t: tensor([6.3139e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 605500 steps (last t: tensor([6.3166e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 606000 steps (last t: tensor([6.3194e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 606500 steps (last t: tensor([6.3221e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 607000 steps (last t: tensor([6.3248e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 607500 steps (last t: tensor([6.3275e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 608000 steps (last t: tensor([6.3302e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 608500 steps (last t: tensor([6.3330e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 609000 steps (last t: tensor([6.3357e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 609500 steps (last t: tensor([6.3384e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 610000 steps (last t: tensor([6.3412e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 610500 steps (last t: tensor([6.3439e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 611000 steps (last t: tensor([6.3466e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 611500 steps (last t: tensor([6.3493e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 612000 steps (last t: tensor([6.3521e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 612500 steps (last t: tensor([6.3548e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 613000 steps (last t: tensor([6.3575e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 613500 steps (last t: tensor([6.3603e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 614000 steps (last t: tensor([6.3630e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 614500 steps (last t: tensor([6.3657e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 615000 steps (last t: tensor([6.3685e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 615500 steps (last t: tensor([6.3712e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 616000 steps (last t: tensor([6.3739e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 616500 steps (last t: tensor([6.3767e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 617000 steps (last t: tensor([6.3794e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 617500 steps (last t: tensor([6.3822e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 618000 steps (last t: tensor([6.3849e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 618500 steps (last t: tensor([6.3876e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 619000 steps (last t: tensor([6.3904e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 619500 steps (last t: tensor([6.3931e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 620000 steps (last t: tensor([6.3959e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 620500 steps (last t: tensor([6.3986e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 621000 steps (last t: tensor([6.4014e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 621500 steps (last t: tensor([6.4041e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 622000 steps (last t: tensor([6.4069e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 622500 steps (last t: tensor([6.4097e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 623000 steps (last t: tensor([6.4124e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 623500 steps (last t: tensor([6.4152e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 624000 steps (last t: tensor([6.4179e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 624500 steps (last t: tensor([6.4207e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 625000 steps (last t: tensor([6.4235e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 625500 steps (last t: tensor([6.4262e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 626000 steps (last t: tensor([6.4289e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 626500 steps (last t: tensor([6.4317e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 627000 steps (last t: tensor([6.4345e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 627500 steps (last t: tensor([6.4372e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 628000 steps (last t: tensor([6.4400e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 628500 steps (last t: tensor([6.4428e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 629000 steps (last t: tensor([6.4455e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 629500 steps (last t: tensor([6.4483e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 630000 steps (last t: tensor([6.4511e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 630500 steps (last t: tensor([6.4538e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 631000 steps (last t: tensor([6.4566e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 631500 steps (last t: tensor([6.4594e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 632000 steps (last t: tensor([6.4621e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 632500 steps (last t: tensor([6.4650e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 633000 steps (last t: tensor([6.4678e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 633500 steps (last t: tensor([6.4705e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 634000 steps (last t: tensor([6.4733e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 634500 steps (last t: tensor([6.4761e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 635000 steps (last t: tensor([6.4783e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 635500 steps (last t: tensor([6.4803e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 636000 steps (last t: tensor([6.4824e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 636500 steps (last t: tensor([6.4841e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 637000 steps (last t: tensor([6.4856e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 637500 steps (last t: tensor([6.4874e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 638000 steps (last t: tensor([6.4889e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 638500 steps (last t: tensor([6.4904e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 639000 steps (last t: tensor([6.4922e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 639500 steps (last t: tensor([6.4939e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 640000 steps (last t: tensor([6.4953e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 640500 steps (last t: tensor([6.4970e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 641000 steps (last t: tensor([6.4987e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 641500 steps (last t: tensor([6.5002e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 642000 steps (last t: tensor([6.5018e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 642500 steps (last t: tensor([6.5034e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 643000 steps (last t: tensor([6.5050e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 643500 steps (last t: tensor([6.5068e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 644000 steps (last t: tensor([6.5082e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 644500 steps (last t: tensor([6.5098e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 645000 steps (last t: tensor([6.5115e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 645500 steps (last t: tensor([6.5133e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 646000 steps (last t: tensor([6.5148e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 646500 steps (last t: tensor([6.5164e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 647000 steps (last t: tensor([6.5180e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 647500 steps (last t: tensor([6.5196e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 648000 steps (last t: tensor([6.5214e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 648500 steps (last t: tensor([6.5229e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 649000 steps (last t: tensor([6.5245e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 649500 steps (last t: tensor([6.5262e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 650000 steps (last t: tensor([6.5278e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 650500 steps (last t: tensor([6.5293e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 651000 steps (last t: tensor([6.5311e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 651500 steps (last t: tensor([6.5324e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 652000 steps (last t: tensor([6.5340e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 652500 steps (last t: tensor([6.5357e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 653000 steps (last t: tensor([6.5371e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 653500 steps (last t: tensor([6.5387e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 654000 steps (last t: tensor([6.5404e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 654500 steps (last t: tensor([6.5420e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 655000 steps (last t: tensor([6.5435e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 655500 steps (last t: tensor([6.5450e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 656000 steps (last t: tensor([6.5467e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 656500 steps (last t: tensor([6.5482e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 657000 steps (last t: tensor([6.5499e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 657500 steps (last t: tensor([6.5513e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 658000 steps (last t: tensor([6.5529e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 658500 steps (last t: tensor([6.5546e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 659000 steps (last t: tensor([6.5562e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 659500 steps (last t: tensor([6.5577e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 660000 steps (last t: tensor([6.5595e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 660500 steps (last t: tensor([6.5608e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 661000 steps (last t: tensor([6.5624e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 661500 steps (last t: tensor([6.5641e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 662000 steps (last t: tensor([6.5655e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 662500 steps (last t: tensor([6.5670e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 663000 steps (last t: tensor([6.5687e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 663500 steps (last t: tensor([6.5703e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 664000 steps (last t: tensor([6.5718e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 664500 steps (last t: tensor([6.5735e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 665000 steps (last t: tensor([6.5749e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 665500 steps (last t: tensor([6.5764e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 666000 steps (last t: tensor([6.5780e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 666500 steps (last t: tensor([6.5794e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 667000 steps (last t: tensor([6.5810e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 667500 steps (last t: tensor([6.5826e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 668000 steps (last t: tensor([6.5842e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 668500 steps (last t: tensor([6.5856e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 669000 steps (last t: tensor([6.5871e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 669500 steps (last t: tensor([6.5887e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 670000 steps (last t: tensor([6.5901e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 670500 steps (last t: tensor([6.5918e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 671000 steps (last t: tensor([6.5934e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 671500 steps (last t: tensor([6.5948e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 672000 steps (last t: tensor([6.5962e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 672500 steps (last t: tensor([6.5978e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 673000 steps (last t: tensor([6.5992e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 673500 steps (last t: tensor([6.6005e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 674000 steps (last t: tensor([6.6020e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 674500 steps (last t: tensor([6.6034e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 675000 steps (last t: tensor([6.6049e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 675500 steps (last t: tensor([6.6062e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 676000 steps (last t: tensor([6.6075e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 676500 steps (last t: tensor([6.6090e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 677000 steps (last t: tensor([6.6105e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 677500 steps (last t: tensor([6.6119e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 678000 steps (last t: tensor([6.6132e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 678500 steps (last t: tensor([6.6147e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 679000 steps (last t: tensor([6.6161e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 679500 steps (last t: tensor([6.6177e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 680000 steps (last t: tensor([6.6189e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 680500 steps (last t: tensor([6.6203e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 681000 steps (last t: tensor([6.6218e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 681500 steps (last t: tensor([6.6233e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 682000 steps (last t: tensor([6.6247e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 682500 steps (last t: tensor([6.6260e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 683000 steps (last t: tensor([6.6275e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 683500 steps (last t: tensor([6.6289e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 684000 steps (last t: tensor([6.6304e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 684500 steps (last t: tensor([6.6317e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 685000 steps (last t: tensor([6.6331e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 685500 steps (last t: tensor([6.6346e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 686000 steps (last t: tensor([6.6361e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 686500 steps (last t: tensor([6.6374e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 687000 steps (last t: tensor([6.6388e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 687500 steps (last t: tensor([6.6403e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 688000 steps (last t: tensor([6.6417e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 688500 steps (last t: tensor([6.6432e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 689000 steps (last t: tensor([6.6445e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 689500 steps (last t: tensor([6.6459e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 690000 steps (last t: tensor([6.6474e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 690500 steps (last t: tensor([6.6489e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 691000 steps (last t: tensor([6.6502e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 691500 steps (last t: tensor([6.6516e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 692000 steps (last t: tensor([6.6531e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 692500 steps (last t: tensor([6.6545e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 693000 steps (last t: tensor([6.6560e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 693500 steps (last t: tensor([6.6573e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 694000 steps (last t: tensor([6.6587e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 694500 steps (last t: tensor([6.6602e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 695000 steps (last t: tensor([6.6617e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 695500 steps (last t: tensor([6.6630e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 696000 steps (last t: tensor([6.6644e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 696500 steps (last t: tensor([6.6659e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 697000 steps (last t: tensor([6.6672e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 697500 steps (last t: tensor([6.6688e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 698000 steps (last t: tensor([6.6701e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 698500 steps (last t: tensor([6.6715e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 699000 steps (last t: tensor([6.6730e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 699500 steps (last t: tensor([6.6745e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 700000 steps (last t: tensor([6.6758e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 700500 steps (last t: tensor([6.6772e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 701000 steps (last t: tensor([6.6787e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 701500 steps (last t: tensor([6.6800e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 702000 steps (last t: tensor([6.6816e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 702500 steps (last t: tensor([6.6829e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 703000 steps (last t: tensor([6.6843e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 703500 steps (last t: tensor([6.6858e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 704000 steps (last t: tensor([6.6873e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 704500 steps (last t: tensor([6.6886e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 705000 steps (last t: tensor([6.6900e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 705500 steps (last t: tensor([6.6915e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 706000 steps (last t: tensor([6.6928e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 706500 steps (last t: tensor([6.6944e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 707000 steps (last t: tensor([6.6957e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 707500 steps (last t: tensor([6.6971e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 708000 steps (last t: tensor([6.6986e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 708500 steps (last t: tensor([6.7001e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 709000 steps (last t: tensor([6.7014e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 709500 steps (last t: tensor([6.7028e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 710000 steps (last t: tensor([6.7042e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 710500 steps (last t: tensor([6.7056e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 711000 steps (last t: tensor([6.7072e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 711500 steps (last t: tensor([6.7085e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 712000 steps (last t: tensor([6.7099e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 712500 steps (last t: tensor([6.7114e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 713000 steps (last t: tensor([6.7129e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 713500 steps (last t: tensor([6.7143e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 714000 steps (last t: tensor([6.7157e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 714500 steps (last t: tensor([6.7172e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 715000 steps (last t: tensor([6.7186e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 715500 steps (last t: tensor([6.7202e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 716000 steps (last t: tensor([6.7214e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 716500 steps (last t: tensor([6.7229e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 717000 steps (last t: tensor([6.7244e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 717500 steps (last t: tensor([6.7259e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 718000 steps (last t: tensor([6.7273e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 718500 steps (last t: tensor([6.7286e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 719000 steps (last t: tensor([6.7302e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 719500 steps (last t: tensor([6.7315e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 720000 steps (last t: tensor([6.7331e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 720500 steps (last t: tensor([6.7344e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 721000 steps (last t: tensor([6.7358e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 721500 steps (last t: tensor([6.7374e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 722000 steps (last t: tensor([6.7389e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 722500 steps (last t: tensor([6.7402e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 723000 steps (last t: tensor([6.7416e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 723500 steps (last t: tensor([6.7431e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 724000 steps (last t: tensor([6.7445e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 724500 steps (last t: tensor([6.7461e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 725000 steps (last t: tensor([6.7474e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 725500 steps (last t: tensor([6.7488e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 726000 steps (last t: tensor([6.7503e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 726500 steps (last t: tensor([6.7519e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 727000 steps (last t: tensor([6.7532e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 727500 steps (last t: tensor([6.7546e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 728000 steps (last t: tensor([6.7561e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 728500 steps (last t: tensor([6.7575e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 729000 steps (last t: tensor([6.7591e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 729500 steps (last t: tensor([6.7603e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 730000 steps (last t: tensor([6.7618e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 730500 steps (last t: tensor([6.7633e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 731000 steps (last t: tensor([6.7648e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 731500 steps (last t: tensor([6.7662e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 732000 steps (last t: tensor([6.7676e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 732500 steps (last t: tensor([6.7691e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 733000 steps (last t: tensor([6.7704e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 733500 steps (last t: tensor([6.7720e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 734000 steps (last t: tensor([6.7733e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 734500 steps (last t: tensor([6.7747e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 735000 steps (last t: tensor([6.7763e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 735500 steps (last t: tensor([6.7778e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 736000 steps (last t: tensor([6.7791e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 736500 steps (last t: tensor([6.7805e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 737000 steps (last t: tensor([6.7820e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 737500 steps (last t: tensor([6.7834e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 738000 steps (last t: tensor([6.7850e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 738500 steps (last t: tensor([6.7863e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 739000 steps (last t: tensor([6.7877e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 739500 steps (last t: tensor([6.7892e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 740000 steps (last t: tensor([6.7908e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 740500 steps (last t: tensor([6.7921e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 741000 steps (last t: tensor([6.7935e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 741500 steps (last t: tensor([6.7950e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 742000 steps (last t: tensor([6.7964e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 742500 steps (last t: tensor([6.7980e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 743000 steps (last t: tensor([6.7992e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 743500 steps (last t: tensor([6.8007e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 744000 steps (last t: tensor([6.8022e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 744500 steps (last t: tensor([6.8037e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 745000 steps (last t: tensor([6.8051e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 745500 steps (last t: tensor([6.8065e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 746000 steps (last t: tensor([6.8080e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 746500 steps (last t: tensor([6.8094e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 747000 steps (last t: tensor([6.8110e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 747500 steps (last t: tensor([6.8123e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 748000 steps (last t: tensor([6.8137e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 748500 steps (last t: tensor([6.8153e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 749000 steps (last t: tensor([6.8168e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 749500 steps (last t: tensor([6.8182e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 750000 steps (last t: tensor([6.8196e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 750500 steps (last t: tensor([6.8211e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 751000 steps (last t: tensor([6.8225e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 751500 steps (last t: tensor([6.8241e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 752000 steps (last t: tensor([6.8254e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 752500 steps (last t: tensor([6.8269e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 753000 steps (last t: tensor([6.8284e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 753500 steps (last t: tensor([6.8300e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 754000 steps (last t: tensor([6.8313e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 754500 steps (last t: tensor([6.8328e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 755000 steps (last t: tensor([6.8343e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 755500 steps (last t: tensor([6.8357e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 756000 steps (last t: tensor([6.8373e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 756500 steps (last t: tensor([6.8386e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 757000 steps (last t: tensor([6.8400e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 757500 steps (last t: tensor([6.8416e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 758000 steps (last t: tensor([6.8431e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 758500 steps (last t: tensor([6.8445e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 759000 steps (last t: tensor([6.8459e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 759500 steps (last t: tensor([6.8474e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 760000 steps (last t: tensor([6.8488e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 760500 steps (last t: tensor([6.8504e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 761000 steps (last t: tensor([6.8517e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 761500 steps (last t: tensor([6.8532e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 762000 steps (last t: tensor([6.8547e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 762500 steps (last t: tensor([6.8563e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 763000 steps (last t: tensor([6.8576e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 763500 steps (last t: tensor([6.8594e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 764000 steps (last t: tensor([6.8617e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 764500 steps (last t: tensor([6.8642e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 765000 steps (last t: tensor([6.8669e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 765500 steps (last t: tensor([6.8695e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 766000 steps (last t: tensor([6.8720e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 766500 steps (last t: tensor([6.8749e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 767000 steps (last t: tensor([6.8775e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 767500 steps (last t: tensor([6.8800e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 768000 steps (last t: tensor([6.8830e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 768500 steps (last t: tensor([6.8856e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 769000 steps (last t: tensor([6.8881e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 769500 steps (last t: tensor([6.8911e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 770000 steps (last t: tensor([6.8937e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 770500 steps (last t: tensor([6.8961e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 771000 steps (last t: tensor([6.8991e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 771500 steps (last t: tensor([6.9017e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 772000 steps (last t: tensor([6.9042e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 772500 steps (last t: tensor([6.9072e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 773000 steps (last t: tensor([6.9098e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 773500 steps (last t: tensor([6.9123e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 774000 steps (last t: tensor([6.9153e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 774500 steps (last t: tensor([6.9179e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 775000 steps (last t: tensor([6.9204e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 775500 steps (last t: tensor([6.9234e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 776000 steps (last t: tensor([6.9260e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 776500 steps (last t: tensor([6.9285e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 777000 steps (last t: tensor([6.9315e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 777500 steps (last t: tensor([6.9341e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 778000 steps (last t: tensor([6.9366e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 778500 steps (last t: tensor([6.9396e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 779000 steps (last t: tensor([6.9422e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 779500 steps (last t: tensor([6.9447e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 780000 steps (last t: tensor([6.9477e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 780500 steps (last t: tensor([6.9503e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 781000 steps (last t: tensor([6.9528e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 781500 steps (last t: tensor([6.9559e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 782000 steps (last t: tensor([6.9585e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 782500 steps (last t: tensor([6.9610e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 783000 steps (last t: tensor([6.9640e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 783500 steps (last t: tensor([6.9664e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 784000 steps (last t: tensor([6.9685e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 784500 steps (last t: tensor([6.9707e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 785000 steps (last t: tensor([6.9729e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 785500 steps (last t: tensor([6.9751e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 786000 steps (last t: tensor([6.9774e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 786500 steps (last t: tensor([6.9795e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 787000 steps (last t: tensor([6.9818e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 787500 steps (last t: tensor([6.9839e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 788000 steps (last t: tensor([6.9862e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 788500 steps (last t: tensor([6.9885e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 789000 steps (last t: tensor([6.9907e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 789500 steps (last t: tensor([6.9926e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 790000 steps (last t: tensor([6.9947e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 790500 steps (last t: tensor([6.9971e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 791000 steps (last t: tensor([6.9989e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 791500 steps (last t: tensor([7.0010e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 792000 steps (last t: tensor([7.0030e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 792500 steps (last t: tensor([7.0051e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 793000 steps (last t: tensor([7.0068e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 793500 steps (last t: tensor([7.0090e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 794000 steps (last t: tensor([7.0110e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 794500 steps (last t: tensor([7.0127e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 795000 steps (last t: tensor([7.0148e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 795500 steps (last t: tensor([7.0167e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 796000 steps (last t: tensor([7.0186e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 796500 steps (last t: tensor([7.0208e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 797000 steps (last t: tensor([7.0227e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 797500 steps (last t: tensor([7.0246e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 798000 steps (last t: tensor([7.0267e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 798500 steps (last t: tensor([7.0287e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 799000 steps (last t: tensor([7.0305e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 799500 steps (last t: tensor([7.0327e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 800000 steps (last t: tensor([7.0344e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 800500 steps (last t: tensor([7.0364e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 801000 steps (last t: tensor([7.0383e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 801500 steps (last t: tensor([7.0404e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 802000 steps (last t: tensor([7.0422e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 802500 steps (last t: tensor([7.0441e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 803000 steps (last t: tensor([7.0461e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 803500 steps (last t: tensor([7.0480e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 804000 steps (last t: tensor([7.0501e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 804500 steps (last t: tensor([7.0519e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 805000 steps (last t: tensor([7.0539e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 805500 steps (last t: tensor([7.0559e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 806000 steps (last t: tensor([7.0579e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 806500 steps (last t: tensor([7.0594e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 807000 steps (last t: tensor([7.0614e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 807500 steps (last t: tensor([7.0633e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 808000 steps (last t: tensor([7.0650e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 808500 steps (last t: tensor([7.0667e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 809000 steps (last t: tensor([7.0684e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 809500 steps (last t: tensor([7.0700e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 810000 steps (last t: tensor([7.0716e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 810500 steps (last t: tensor([7.0731e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 811000 steps (last t: tensor([7.0745e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 811500 steps (last t: tensor([7.0761e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 812000 steps (last t: tensor([7.0776e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 812500 steps (last t: tensor([7.0790e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 813000 steps (last t: tensor([7.0804e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 813500 steps (last t: tensor([7.0819e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 814000 steps (last t: tensor([7.0833e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 814500 steps (last t: tensor([7.0849e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 815000 steps (last t: tensor([7.0864e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 815500 steps (last t: tensor([7.0878e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 816000 steps (last t: tensor([7.0892e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 816500 steps (last t: tensor([7.0907e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 817000 steps (last t: tensor([7.0921e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 817500 steps (last t: tensor([7.0937e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 818000 steps (last t: tensor([7.0952e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 818500 steps (last t: tensor([7.0966e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 819000 steps (last t: tensor([7.0980e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 819500 steps (last t: tensor([7.0995e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 820000 steps (last t: tensor([7.1009e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 820500 steps (last t: tensor([7.1025e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 821000 steps (last t: tensor([7.1040e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 821500 steps (last t: tensor([7.1053e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 822000 steps (last t: tensor([7.1068e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 822500 steps (last t: tensor([7.1083e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 823000 steps (last t: tensor([7.1097e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 823500 steps (last t: tensor([7.1113e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 824000 steps (last t: tensor([7.1128e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 824500 steps (last t: tensor([7.1141e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 825000 steps (last t: tensor([7.1155e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 825500 steps (last t: tensor([7.1171e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 826000 steps (last t: tensor([7.1185e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 826500 steps (last t: tensor([7.1201e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 827000 steps (last t: tensor([7.1216e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 827500 steps (last t: tensor([7.1230e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 828000 steps (last t: tensor([7.1244e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 828500 steps (last t: tensor([7.1259e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 829000 steps (last t: tensor([7.1273e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 829500 steps (last t: tensor([7.1290e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 830000 steps (last t: tensor([7.1305e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 830500 steps (last t: tensor([7.1318e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 831000 steps (last t: tensor([7.1333e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 831500 steps (last t: tensor([7.1348e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 832000 steps (last t: tensor([7.1362e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 832500 steps (last t: tensor([7.1378e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 833000 steps (last t: tensor([7.1394e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 833500 steps (last t: tensor([7.1407e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 834000 steps (last t: tensor([7.1421e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 834500 steps (last t: tensor([7.1437e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 835000 steps (last t: tensor([7.1451e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 835500 steps (last t: tensor([7.1467e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 836000 steps (last t: tensor([7.1483e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 836500 steps (last t: tensor([7.1496e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 837000 steps (last t: tensor([7.1510e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 837500 steps (last t: tensor([7.1525e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 838000 steps (last t: tensor([7.1540e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 838500 steps (last t: tensor([7.1556e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 839000 steps (last t: tensor([7.1571e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 839500 steps (last t: tensor([7.1585e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 840000 steps (last t: tensor([7.1599e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 840500 steps (last t: tensor([7.1614e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 841000 steps (last t: tensor([7.1629e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 841500 steps (last t: tensor([7.1645e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 842000 steps (last t: tensor([7.1660e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 842500 steps (last t: tensor([7.1674e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 843000 steps (last t: tensor([7.1688e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 843500 steps (last t: tensor([7.1703e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 844000 steps (last t: tensor([7.1717e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 844500 steps (last t: tensor([7.1734e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 845000 steps (last t: tensor([7.1749e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 845500 steps (last t: tensor([7.1762e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 846000 steps (last t: tensor([7.1777e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 846500 steps (last t: tensor([7.1792e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 847000 steps (last t: tensor([7.1806e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 847500 steps (last t: tensor([7.1822e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 848000 steps (last t: tensor([7.1838e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 848500 steps (last t: tensor([7.1851e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 849000 steps (last t: tensor([7.1865e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 849500 steps (last t: tensor([7.1882e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 850000 steps (last t: tensor([7.1894e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 850500 steps (last t: tensor([7.1909e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 851000 steps (last t: tensor([7.1924e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 851500 steps (last t: tensor([7.1937e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 852000 steps (last t: tensor([7.1954e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 852500 steps (last t: tensor([7.1968e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 853000 steps (last t: tensor([7.1982e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 853500 steps (last t: tensor([7.2003e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 854000 steps (last t: tensor([7.2020e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 854500 steps (last t: tensor([7.2036e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 855000 steps (last t: tensor([7.2055e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 855500 steps (last t: tensor([7.2073e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 856000 steps (last t: tensor([7.2090e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 856500 steps (last t: tensor([7.2109e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 857000 steps (last t: tensor([7.2128e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 857500 steps (last t: tensor([7.2145e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 858000 steps (last t: tensor([7.2165e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 858500 steps (last t: tensor([7.2182e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 859000 steps (last t: tensor([7.2200e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 859500 steps (last t: tensor([7.2218e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 860000 steps (last t: tensor([7.2239e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 860500 steps (last t: tensor([7.2256e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 861000 steps (last t: tensor([7.2277e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 861500 steps (last t: tensor([7.2295e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 862000 steps (last t: tensor([7.2312e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 862500 steps (last t: tensor([7.2330e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 863000 steps (last t: tensor([7.2344e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 863500 steps (last t: tensor([7.2357e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 864000 steps (last t: tensor([7.2372e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 864500 steps (last t: tensor([7.2386e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 865000 steps (last t: tensor([7.2398e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 865500 steps (last t: tensor([7.2413e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 866000 steps (last t: tensor([7.2425e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 866500 steps (last t: tensor([7.2437e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 867000 steps (last t: tensor([7.2451e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 867500 steps (last t: tensor([7.2465e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 868000 steps (last t: tensor([7.2477e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 868500 steps (last t: tensor([7.2492e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 869000 steps (last t: tensor([7.2503e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 869500 steps (last t: tensor([7.2516e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 870000 steps (last t: tensor([7.2530e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 870500 steps (last t: tensor([7.2544e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 871000 steps (last t: tensor([7.2556e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 871500 steps (last t: tensor([7.2568e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 872000 steps (last t: tensor([7.2582e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 872500 steps (last t: tensor([7.2594e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 873000 steps (last t: tensor([7.2609e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 873500 steps (last t: tensor([7.2622e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 874000 steps (last t: tensor([7.2634e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 874500 steps (last t: tensor([7.2649e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 875000 steps (last t: tensor([7.2660e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 875500 steps (last t: tensor([7.2673e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 876000 steps (last t: tensor([7.2687e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 876500 steps (last t: tensor([7.2701e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 877000 steps (last t: tensor([7.2713e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 877500 steps (last t: tensor([7.2727e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 878000 steps (last t: tensor([7.2738e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 878500 steps (last t: tensor([7.2751e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 879000 steps (last t: tensor([7.2765e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 879500 steps (last t: tensor([7.2779e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 880000 steps (last t: tensor([7.2791e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 880500 steps (last t: tensor([7.2804e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 881000 steps (last t: tensor([7.2817e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 881500 steps (last t: tensor([7.2830e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 882000 steps (last t: tensor([7.2844e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 882500 steps (last t: tensor([7.2858e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 883000 steps (last t: tensor([7.2870e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 883500 steps (last t: tensor([7.2884e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 884000 steps (last t: tensor([7.2895e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 884500 steps (last t: tensor([7.2908e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 885000 steps (last t: tensor([7.2922e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 885500 steps (last t: tensor([7.2936e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 886000 steps (last t: tensor([7.2948e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 886500 steps (last t: tensor([7.2963e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 887000 steps (last t: tensor([7.2974e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 887500 steps (last t: tensor([7.2987e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 888000 steps (last t: tensor([7.3001e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 888500 steps (last t: tensor([7.3014e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 889000 steps (last t: tensor([7.3027e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 889500 steps (last t: tensor([7.3039e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 890000 steps (last t: tensor([7.3053e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 890500 steps (last t: tensor([7.3066e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 891000 steps (last t: tensor([7.3080e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 891500 steps (last t: tensor([7.3093e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 892000 steps (last t: tensor([7.3105e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 892500 steps (last t: tensor([7.3123e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 893000 steps (last t: tensor([7.3137e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 893500 steps (last t: tensor([7.3151e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 894000 steps (last t: tensor([7.3168e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 894500 steps (last t: tensor([7.3184e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 895000 steps (last t: tensor([7.3200e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 895500 steps (last t: tensor([7.3217e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 896000 steps (last t: tensor([7.3232e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 896500 steps (last t: tensor([7.3247e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 897000 steps (last t: tensor([7.3263e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 897500 steps (last t: tensor([7.3279e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 898000 steps (last t: tensor([7.3294e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 898500 steps (last t: tensor([7.3310e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 899000 steps (last t: tensor([7.3326e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 899500 steps (last t: tensor([7.3339e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 900000 steps (last t: tensor([7.3354e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 900500 steps (last t: tensor([7.3370e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 901000 steps (last t: tensor([7.3383e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 901500 steps (last t: tensor([7.3397e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 902000 steps (last t: tensor([7.3409e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 902500 steps (last t: tensor([7.3421e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 903000 steps (last t: tensor([7.3432e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 903500 steps (last t: tensor([7.3445e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 904000 steps (last t: tensor([7.3457e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 904500 steps (last t: tensor([7.3470e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 905000 steps (last t: tensor([7.3483e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 905500 steps (last t: tensor([7.3494e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 906000 steps (last t: tensor([7.3508e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 906500 steps (last t: tensor([7.3519e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 907000 steps (last t: tensor([7.3530e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 907500 steps (last t: tensor([7.3544e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 908000 steps (last t: tensor([7.3557e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 908500 steps (last t: tensor([7.3568e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 909000 steps (last t: tensor([7.3580e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 909500 steps (last t: tensor([7.3592e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 910000 steps (last t: tensor([7.3604e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 910500 steps (last t: tensor([7.3617e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 911000 steps (last t: tensor([7.3631e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 911500 steps (last t: tensor([7.3642e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 912000 steps (last t: tensor([7.3656e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 912500 steps (last t: tensor([7.3666e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 913000 steps (last t: tensor([7.3678e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 913500 steps (last t: tensor([7.3692e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 914000 steps (last t: tensor([7.3704e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 914500 steps (last t: tensor([7.3716e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 915000 steps (last t: tensor([7.3727e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 915500 steps (last t: tensor([7.3740e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 916000 steps (last t: tensor([7.3752e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 916500 steps (last t: tensor([7.3765e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 917000 steps (last t: tensor([7.3778e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 917500 steps (last t: tensor([7.3789e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 918000 steps (last t: tensor([7.3804e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 918500 steps (last t: tensor([7.3814e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 919000 steps (last t: tensor([7.3826e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 919500 steps (last t: tensor([7.3840e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 920000 steps (last t: tensor([7.3852e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 920500 steps (last t: tensor([7.3864e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 921000 steps (last t: tensor([7.3876e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 921500 steps (last t: tensor([7.3888e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 922000 steps (last t: tensor([7.3900e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 922500 steps (last t: tensor([7.3913e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 923000 steps (last t: tensor([7.3927e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 923500 steps (last t: tensor([7.3938e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 924000 steps (last t: tensor([7.3952e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 924500 steps (last t: tensor([7.3963e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 925000 steps (last t: tensor([7.3974e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 925500 steps (last t: tensor([7.3988e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 926000 steps (last t: tensor([7.4001e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 926500 steps (last t: tensor([7.4012e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 927000 steps (last t: tensor([7.4024e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 927500 steps (last t: tensor([7.4036e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 928000 steps (last t: tensor([7.4049e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 928500 steps (last t: tensor([7.4062e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 929000 steps (last t: tensor([7.4075e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 929500 steps (last t: tensor([7.4092e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 930000 steps (last t: tensor([7.4111e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 930500 steps (last t: tensor([7.4129e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 931000 steps (last t: tensor([7.4145e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 931500 steps (last t: tensor([7.4164e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 932000 steps (last t: tensor([7.4180e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 932500 steps (last t: tensor([7.4196e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 933000 steps (last t: tensor([7.4213e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 933500 steps (last t: tensor([7.4231e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 934000 steps (last t: tensor([7.4246e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 934500 steps (last t: tensor([7.4264e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 935000 steps (last t: tensor([7.4281e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 935500 steps (last t: tensor([7.4295e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 936000 steps (last t: tensor([7.4312e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 936500 steps (last t: tensor([7.4330e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 937000 steps (last t: tensor([7.4345e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 937500 steps (last t: tensor([7.4361e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 938000 steps (last t: tensor([7.4378e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 938500 steps (last t: tensor([7.4395e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 939000 steps (last t: tensor([7.4411e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 939500 steps (last t: tensor([7.4430e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 940000 steps (last t: tensor([7.4444e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 940500 steps (last t: tensor([7.4461e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 941000 steps (last t: tensor([7.4477e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 941500 steps (last t: tensor([7.4494e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 942000 steps (last t: tensor([7.4510e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 942500 steps (last t: tensor([7.4527e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 943000 steps (last t: tensor([7.4542e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 943500 steps (last t: tensor([7.4561e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 944000 steps (last t: tensor([7.4577e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 944500 steps (last t: tensor([7.4592e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 945000 steps (last t: tensor([7.4609e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 945500 steps (last t: tensor([7.4625e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 946000 steps (last t: tensor([7.4642e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 946500 steps (last t: tensor([7.4657e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 947000 steps (last t: tensor([7.4676e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 947500 steps (last t: tensor([7.4690e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 948000 steps (last t: tensor([7.4709e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 948500 steps (last t: tensor([7.4725e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 949000 steps (last t: tensor([7.4741e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 949500 steps (last t: tensor([7.4758e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 950000 steps (last t: tensor([7.4774e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 950500 steps (last t: tensor([7.4788e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 951000 steps (last t: tensor([7.4803e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 951500 steps (last t: tensor([7.4818e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 952000 steps (last t: tensor([7.4832e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 952500 steps (last t: tensor([7.4849e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 953000 steps (last t: tensor([7.4863e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 953500 steps (last t: tensor([7.4876e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 954000 steps (last t: tensor([7.4891e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 954500 steps (last t: tensor([7.4905e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 955000 steps (last t: tensor([7.4921e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 955500 steps (last t: tensor([7.4934e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 956000 steps (last t: tensor([7.4951e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 956500 steps (last t: tensor([7.4964e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 957000 steps (last t: tensor([7.4980e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 957500 steps (last t: tensor([7.4995e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 958000 steps (last t: tensor([7.5008e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 958500 steps (last t: tensor([7.5027e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 959000 steps (last t: tensor([7.5045e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 959500 steps (last t: tensor([7.5061e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 960000 steps (last t: tensor([7.5080e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 960500 steps (last t: tensor([7.5101e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 961000 steps (last t: tensor([7.5117e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 961500 steps (last t: tensor([7.5136e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 962000 steps (last t: tensor([7.5157e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 962500 steps (last t: tensor([7.5173e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 963000 steps (last t: tensor([7.5192e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 963500 steps (last t: tensor([7.5213e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 964000 steps (last t: tensor([7.5229e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 964500 steps (last t: tensor([7.5249e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 965000 steps (last t: tensor([7.5267e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 965500 steps (last t: tensor([7.5283e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 966000 steps (last t: tensor([7.5304e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 966500 steps (last t: tensor([7.5319e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 967000 steps (last t: tensor([7.5335e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 967500 steps (last t: tensor([7.5353e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 968000 steps (last t: tensor([7.5368e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 968500 steps (last t: tensor([7.5384e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 969000 steps (last t: tensor([7.5402e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 969500 steps (last t: tensor([7.5418e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 970000 steps (last t: tensor([7.5433e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 970500 steps (last t: tensor([7.5451e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 971000 steps (last t: tensor([7.5467e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 971500 steps (last t: tensor([7.5482e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 972000 steps (last t: tensor([7.5501e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 972500 steps (last t: tensor([7.5516e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 973000 steps (last t: tensor([7.5532e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 973500 steps (last t: tensor([7.5550e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 974000 steps (last t: tensor([7.5566e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 974500 steps (last t: tensor([7.5581e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 975000 steps (last t: tensor([7.5600e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 975500 steps (last t: tensor([7.5616e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 976000 steps (last t: tensor([7.5631e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 976500 steps (last t: tensor([7.5649e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 977000 steps (last t: tensor([7.5665e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 977500 steps (last t: tensor([7.5681e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 978000 steps (last t: tensor([7.5699e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 978500 steps (last t: tensor([7.5715e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 979000 steps (last t: tensor([7.5730e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 979500 steps (last t: tensor([7.5748e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 980000 steps (last t: tensor([7.5764e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 980500 steps (last t: tensor([7.5780e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 981000 steps (last t: tensor([7.5798e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 981500 steps (last t: tensor([7.5814e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 982000 steps (last t: tensor([7.5829e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 982500 steps (last t: tensor([7.5847e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 983000 steps (last t: tensor([7.5863e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 983500 steps (last t: tensor([7.5879e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 984000 steps (last t: tensor([7.5897e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 984500 steps (last t: tensor([7.5913e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 985000 steps (last t: tensor([7.5928e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 985500 steps (last t: tensor([7.5947e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 986000 steps (last t: tensor([7.5962e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 986500 steps (last t: tensor([7.5978e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 987000 steps (last t: tensor([7.5996e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 987500 steps (last t: tensor([7.6012e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 988000 steps (last t: tensor([7.6028e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 988500 steps (last t: tensor([7.6046e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 989000 steps (last t: tensor([7.6062e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 989500 steps (last t: tensor([7.6076e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 990000 steps (last t: tensor([7.6092e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 990500 steps (last t: tensor([7.6109e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 991000 steps (last t: tensor([7.6123e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 991500 steps (last t: tensor([7.6138e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 992000 steps (last t: tensor([7.6155e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 992500 steps (last t: tensor([7.6170e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 993000 steps (last t: tensor([7.6185e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 993500 steps (last t: tensor([7.6202e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 994000 steps (last t: tensor([7.6212e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 994500 steps (last t: tensor([7.6225e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 995000 steps (last t: tensor([7.6234e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 995500 steps (last t: tensor([7.6244e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 996000 steps (last t: tensor([7.6257e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 996500 steps (last t: tensor([7.6266e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 997000 steps (last t: tensor([7.6277e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 997500 steps (last t: tensor([7.6289e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 998000 steps (last t: tensor([7.6298e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 998500 steps (last t: tensor([7.6309e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 999000 steps (last t: tensor([7.6323e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 999500 steps (last t: tensor([7.6336e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1000000 steps (last t: tensor([7.6349e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1000500 steps (last t: tensor([7.6364e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1001000 steps (last t: tensor([7.6377e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1001500 steps (last t: tensor([7.6391e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1002000 steps (last t: tensor([7.6406e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1002500 steps (last t: tensor([7.6419e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1003000 steps (last t: tensor([7.6434e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1003500 steps (last t: tensor([7.6448e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1004000 steps (last t: tensor([7.6462e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1004500 steps (last t: tensor([7.6475e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1005000 steps (last t: tensor([7.6491e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1005500 steps (last t: tensor([7.6505e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1006000 steps (last t: tensor([7.6518e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1006500 steps (last t: tensor([7.6534e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1007000 steps (last t: tensor([7.6548e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1007500 steps (last t: tensor([7.6564e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1008000 steps (last t: tensor([7.6580e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1008500 steps (last t: tensor([7.6594e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1009000 steps (last t: tensor([7.6609e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1009500 steps (last t: tensor([7.6626e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1010000 steps (last t: tensor([7.6640e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1010500 steps (last t: tensor([7.6653e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1011000 steps (last t: tensor([7.6669e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1011500 steps (last t: tensor([7.6683e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1012000 steps (last t: tensor([7.6697e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1012500 steps (last t: tensor([7.6713e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1013000 steps (last t: tensor([7.6727e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1013500 steps (last t: tensor([7.6741e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1014000 steps (last t: tensor([7.6756e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1014500 steps (last t: tensor([7.6772e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1015000 steps (last t: tensor([7.6785e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1015500 steps (last t: tensor([7.6802e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1016000 steps (last t: tensor([7.6814e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1016500 steps (last t: tensor([7.6829e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1017000 steps (last t: tensor([7.6844e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1017500 steps (last t: tensor([7.6859e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1018000 steps (last t: tensor([7.6872e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1018500 steps (last t: tensor([7.6888e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1019000 steps (last t: tensor([7.6901e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1019500 steps (last t: tensor([7.6912e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1020000 steps (last t: tensor([7.6928e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1020500 steps (last t: tensor([7.6942e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1021000 steps (last t: tensor([7.6954e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1021500 steps (last t: tensor([7.6967e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1022000 steps (last t: tensor([7.6982e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1022500 steps (last t: tensor([7.6995e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1023000 steps (last t: tensor([7.7009e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1023500 steps (last t: tensor([7.7021e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1024000 steps (last t: tensor([7.7034e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1024500 steps (last t: tensor([7.7050e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1025000 steps (last t: tensor([7.7063e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1025500 steps (last t: tensor([7.7076e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1026000 steps (last t: tensor([7.7089e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1026500 steps (last t: tensor([7.7104e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1027000 steps (last t: tensor([7.7116e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1027500 steps (last t: tensor([7.7132e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1028000 steps (last t: tensor([7.7144e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1028500 steps (last t: tensor([7.7157e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1029000 steps (last t: tensor([7.7171e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1029500 steps (last t: tensor([7.7186e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1030000 steps (last t: tensor([7.7199e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1030500 steps (last t: tensor([7.7213e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1031000 steps (last t: tensor([7.7225e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1031500 steps (last t: tensor([7.7239e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1032000 steps (last t: tensor([7.7255e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1032500 steps (last t: tensor([7.7267e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1033000 steps (last t: tensor([7.7279e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1033500 steps (last t: tensor([7.7294e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1034000 steps (last t: tensor([7.7309e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1034500 steps (last t: tensor([7.7321e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1035000 steps (last t: tensor([7.7334e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1035500 steps (last t: tensor([7.7349e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1036000 steps (last t: tensor([7.7362e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1036500 steps (last t: tensor([7.7376e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1037000 steps (last t: tensor([7.7389e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1037500 steps (last t: tensor([7.7402e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1038000 steps (last t: tensor([7.7418e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1038500 steps (last t: tensor([7.7431e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1039000 steps (last t: tensor([7.7444e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1039500 steps (last t: tensor([7.7458e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1040000 steps (last t: tensor([7.7473e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1040500 steps (last t: tensor([7.7484e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1041000 steps (last t: tensor([7.7500e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1041500 steps (last t: tensor([7.7512e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1042000 steps (last t: tensor([7.7526e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1042500 steps (last t: tensor([7.7540e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1043000 steps (last t: tensor([7.7555e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1043500 steps (last t: tensor([7.7568e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1044000 steps (last t: tensor([7.7584e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1044500 steps (last t: tensor([7.7596e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1045000 steps (last t: tensor([7.7611e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1045500 steps (last t: tensor([7.7627e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1046000 steps (last t: tensor([7.7641e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1046500 steps (last t: tensor([7.7654e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1047000 steps (last t: tensor([7.7669e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1047500 steps (last t: tensor([7.7686e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1048000 steps (last t: tensor([7.7699e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1048500 steps (last t: tensor([7.7714e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1049000 steps (last t: tensor([7.7728e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1049500 steps (last t: tensor([7.7742e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1050000 steps (last t: tensor([7.7759e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1050500 steps (last t: tensor([7.7773e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1051000 steps (last t: tensor([7.7786e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1051500 steps (last t: tensor([7.7804e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1052000 steps (last t: tensor([7.7816e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1052500 steps (last t: tensor([7.7831e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1053000 steps (last t: tensor([7.7846e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1053500 steps (last t: tensor([7.7860e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1054000 steps (last t: tensor([7.7875e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1054500 steps (last t: tensor([7.7890e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1055000 steps (last t: tensor([7.7904e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1055500 steps (last t: tensor([7.7916e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1056000 steps (last t: tensor([7.7929e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1056500 steps (last t: tensor([7.7943e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1057000 steps (last t: tensor([7.7956e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1057500 steps (last t: tensor([7.7971e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1058000 steps (last t: tensor([7.7983e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1058500 steps (last t: tensor([7.7996e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1059000 steps (last t: tensor([7.8010e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1059500 steps (last t: tensor([7.8025e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1060000 steps (last t: tensor([7.8037e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1060500 steps (last t: tensor([7.8053e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1061000 steps (last t: tensor([7.8064e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1061500 steps (last t: tensor([7.8077e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1062000 steps (last t: tensor([7.8092e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1062500 steps (last t: tensor([7.8106e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1063000 steps (last t: tensor([7.8119e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1063500 steps (last t: tensor([7.8132e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1064000 steps (last t: tensor([7.8146e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1064500 steps (last t: tensor([7.8160e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1065000 steps (last t: tensor([7.8181e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1065500 steps (last t: tensor([7.8199e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1066000 steps (last t: tensor([7.8218e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1066500 steps (last t: tensor([7.8238e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1067000 steps (last t: tensor([7.8259e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1067500 steps (last t: tensor([7.8277e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1068000 steps (last t: tensor([7.8295e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1068500 steps (last t: tensor([7.8315e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1069000 steps (last t: tensor([7.8334e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1069500 steps (last t: tensor([7.8355e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1070000 steps (last t: tensor([7.8373e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1070500 steps (last t: tensor([7.8392e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1071000 steps (last t: tensor([7.8412e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1071500 steps (last t: tensor([7.8433e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1072000 steps (last t: tensor([7.8451e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1072500 steps (last t: tensor([7.8470e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1073000 steps (last t: tensor([7.8490e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1073500 steps (last t: tensor([7.8508e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1074000 steps (last t: tensor([7.8530e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1074500 steps (last t: tensor([7.8547e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1075000 steps (last t: tensor([7.8566e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1075500 steps (last t: tensor([7.8586e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1076000 steps (last t: tensor([7.8607e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1076500 steps (last t: tensor([7.8625e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1077000 steps (last t: tensor([7.8644e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1077500 steps (last t: tensor([7.8664e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1078000 steps (last t: tensor([7.8683e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1078500 steps (last t: tensor([7.8705e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1079000 steps (last t: tensor([7.8722e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1079500 steps (last t: tensor([7.8741e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1080000 steps (last t: tensor([7.8762e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1080500 steps (last t: tensor([7.8783e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1081000 steps (last t: tensor([7.8801e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1081500 steps (last t: tensor([7.8820e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1082000 steps (last t: tensor([7.8840e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1082500 steps (last t: tensor([7.8859e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1083000 steps (last t: tensor([7.8880e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1083500 steps (last t: tensor([7.8898e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1084000 steps (last t: tensor([7.8917e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1084500 steps (last t: tensor([7.8938e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1085000 steps (last t: tensor([7.8959e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1085500 steps (last t: tensor([7.8977e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1086000 steps (last t: tensor([7.8996e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1086500 steps (last t: tensor([7.9016e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1087000 steps (last t: tensor([7.9035e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1087500 steps (last t: tensor([7.9056e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1088000 steps (last t: tensor([7.9074e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1088500 steps (last t: tensor([7.9093e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1089000 steps (last t: tensor([7.9114e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1089500 steps (last t: tensor([7.9134e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1090000 steps (last t: tensor([7.9153e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1090500 steps (last t: tensor([7.9172e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1091000 steps (last t: tensor([7.9192e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1091500 steps (last t: tensor([7.9211e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1092000 steps (last t: tensor([7.9232e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1092500 steps (last t: tensor([7.9250e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1093000 steps (last t: tensor([7.9269e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1093500 steps (last t: tensor([7.9290e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1094000 steps (last t: tensor([7.9310e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1094500 steps (last t: tensor([7.9328e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1095000 steps (last t: tensor([7.9347e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1095500 steps (last t: tensor([7.9368e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1096000 steps (last t: tensor([7.9387e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1096500 steps (last t: tensor([7.9408e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1097000 steps (last t: tensor([7.9426e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1097500 steps (last t: tensor([7.9445e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1098000 steps (last t: tensor([7.9466e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1098500 steps (last t: tensor([7.9487e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1099000 steps (last t: tensor([7.9505e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1099500 steps (last t: tensor([7.9524e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1100000 steps (last t: tensor([7.9544e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1100500 steps (last t: tensor([7.9564e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1101000 steps (last t: tensor([7.9585e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1101500 steps (last t: tensor([7.9603e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1102000 steps (last t: tensor([7.9622e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1102500 steps (last t: tensor([7.9643e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1103000 steps (last t: tensor([7.9664e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1103500 steps (last t: tensor([7.9683e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1104000 steps (last t: tensor([7.9702e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1104500 steps (last t: tensor([7.9722e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1105000 steps (last t: tensor([7.9741e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1105500 steps (last t: tensor([7.9763e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1106000 steps (last t: tensor([7.9781e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1106500 steps (last t: tensor([7.9800e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1107000 steps (last t: tensor([7.9821e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1107500 steps (last t: tensor([7.9842e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1108000 steps (last t: tensor([7.9860e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1108500 steps (last t: tensor([7.9879e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1109000 steps (last t: tensor([7.9900e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1109500 steps (last t: tensor([7.9919e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1110000 steps (last t: tensor([7.9941e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1110500 steps (last t: tensor([7.9958e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1111000 steps (last t: tensor([7.9978e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1111500 steps (last t: tensor([7.9998e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1112000 steps (last t: tensor([8.0019e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1112500 steps (last t: tensor([8.0038e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1113000 steps (last t: tensor([8.0057e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1113500 steps (last t: tensor([8.0077e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1114000 steps (last t: tensor([8.0096e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1114500 steps (last t: tensor([8.0118e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1115000 steps (last t: tensor([8.0136e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1115500 steps (last t: tensor([8.0155e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1116000 steps (last t: tensor([8.0176e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1116500 steps (last t: tensor([8.0197e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1117000 steps (last t: tensor([8.0215e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1117500 steps (last t: tensor([8.0235e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1118000 steps (last t: tensor([8.0255e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1118500 steps (last t: tensor([8.0274e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1119000 steps (last t: tensor([8.0296e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1119500 steps (last t: tensor([8.0314e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1120000 steps (last t: tensor([8.0333e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1120500 steps (last t: tensor([8.0354e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1121000 steps (last t: tensor([8.0375e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1121500 steps (last t: tensor([8.0394e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1122000 steps (last t: tensor([8.0413e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1122500 steps (last t: tensor([8.0434e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1123000 steps (last t: tensor([8.0453e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1123500 steps (last t: tensor([8.0475e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1124000 steps (last t: tensor([8.0493e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1124500 steps (last t: tensor([8.0513e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1125000 steps (last t: tensor([8.0534e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1125500 steps (last t: tensor([8.0555e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1126000 steps (last t: tensor([8.0573e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1126500 steps (last t: tensor([8.0593e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1127000 steps (last t: tensor([8.0613e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1127500 steps (last t: tensor([8.0632e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1128000 steps (last t: tensor([8.0654e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1128500 steps (last t: tensor([8.0671e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1129000 steps (last t: tensor([8.0690e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1129500 steps (last t: tensor([8.0711e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1130000 steps (last t: tensor([8.0732e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1130500 steps (last t: tensor([8.0750e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1131000 steps (last t: tensor([8.0769e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1131500 steps (last t: tensor([8.0789e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1132000 steps (last t: tensor([8.0807e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1132500 steps (last t: tensor([8.0829e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1133000 steps (last t: tensor([8.0846e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1133500 steps (last t: tensor([8.0865e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1134000 steps (last t: tensor([8.0886e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1134500 steps (last t: tensor([8.0906e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1135000 steps (last t: tensor([8.0924e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1135500 steps (last t: tensor([8.0943e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1136000 steps (last t: tensor([8.0963e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1136500 steps (last t: tensor([8.0982e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1137000 steps (last t: tensor([8.1003e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1137500 steps (last t: tensor([8.1020e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1138000 steps (last t: tensor([8.1039e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1138500 steps (last t: tensor([8.1059e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1139000 steps (last t: tensor([8.1080e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1139500 steps (last t: tensor([8.1098e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1140000 steps (last t: tensor([8.1116e-08], grad_fn=<AddBackward0>))\n",
      "Trajectory 1b8eb0f543c644428950473794aba0f8: 1140500 steps (last t: tensor([8.1136e-08], grad_fn=<AddBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# load or train model\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_loss(stats: dict, zoom_length: int = 500, key_sets: list[list[str]] | None = None):\n",
    "    if key_sets is None:\n",
    "        key_sets = [stats.keys()]\n",
    "\n",
    "    if not 'fig' in vars():\n",
    "        fig, axes = plt.subplots(len(key_sets), 2, figsize=(10, 4))\n",
    "\n",
    "    for i, keys in enumerate(key_sets):\n",
    "        axes[i][0].clear()\n",
    "        axes[i][0].set_title(\"Loss\")\n",
    "        axes[i][0].set_xlabel(\"time\")\n",
    "        for key in keys:\n",
    "            axes[i][0].plot(getattr(stats, key), label=key)\n",
    "        axes[i][0].legend(fontsize=8)\n",
    "        axes[i][0].set_yscale(\"log\")\n",
    "\n",
    "        axes[i][1].clear()\n",
    "        axes[i][1].set_title(f\"Last {zoom_length} steps loss\")\n",
    "        axes[i][1].set_xlabel(\"time\")\n",
    "        for key in keys:\n",
    "            axes[i][1].plot(getattr(stats, key)[-zoom_length:], label=key)\n",
    "        axes[i][1].legend(fontsize=8)\n",
    "        axes[i][1].set_yscale(\"log\")\n",
    "        fig.tight_layout()\n",
    "    display(fig, clear=True)\n",
    "\n",
    "# model = load_model(args.model)\n",
    "def loss_fn(dxdt, dxdt_hat, s, masses):\n",
    "    \"\"\"\n",
    "    Calculate the loss\n",
    "    \"\"\"\n",
    "    loss = F.mse_loss(dxdt, dxdt_hat)\n",
    "\n",
    "    energy_loss = energy_conservation_loss(s, s + dxdt_hat * 0.01, masses).sum()\n",
    "    loss += energy_loss\n",
    "\n",
    "    return loss, energy_loss\n",
    "\n",
    "model, stats = train(\n",
    "    args,\n",
    "    pinn_loss_fn=loss_fn,\n",
    "    plot_loss_callback=partial(plot_loss, key_sets=[[\"train_loss\", \"test_loss\"], [\"train_additional_loss\", \"test_additional_loss\"]])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model output\n",
    "\n",
    "test_y0, test_masses = get_initial_conditions(5)\n",
    "initial_state = test_y0.clone().detach().requires_grad_()\n",
    "r, v, dr, dv, time = mechanics.get_trajectory({\"y0\": initial_state, \"masses\": test_masses, \"model\": model}).dict().values()\n",
    "plot_energy_from_coords(r, v, time, test_masses)\n",
    "\n",
    "ani_model = visualize_trajectory(r, len(time), (mechanics.domain_min, mechanics.domain_max))\n",
    "HTML(ani_model.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
